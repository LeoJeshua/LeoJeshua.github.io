<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="keywords" content="Hexo Theme Redefine">
    
    <meta name="author" content="LeoJeshua">
    <!-- preconnect -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>

    
        
        
        
            <link rel="preconnect" href="https://registry.npmmirror.com" crossorigin>
        
    
    <!--- Seo Part-->
    
    <link rel="canonical" href="https://leojeshua.github.io/nlp/llm/"/>
    <meta name="robots" content="index,follow">
    <meta name="googlebot" content="index,follow">
    <meta name="revisit-after" content="1 days">
    
    
    
        
        <meta name="description" content="Hexo Theme Redefine, Redefine Your Hexo Journey.">
<meta property="og:type" content="article">
<meta property="og:title" content="LLM(Large Language Model) 学习笔记">
<meta property="og:url" content="https://leojeshua.github.io/NLP/LLM/index.html">
<meta property="og:site_name" content="The Blog of LeoJeshua">
<meta property="og:description" content="Hexo Theme Redefine, Redefine Your Hexo Journey.">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://leojeshua.github.io/images/redefine-og.webp">
<meta property="article:published_time" content="2025-03-08T02:32:00.000Z">
<meta property="article:modified_time" content="2025-06-09T05:47:55.340Z">
<meta property="article:author" content="LeoJeshua">
<meta property="article:tag" content="NLP">
<meta property="article:tag" content="LLMs">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://leojeshua.github.io/images/redefine-og.webp">
    
    
    <!--- Icon Part-->
    <link rel="icon" type="image/png" href="/images/avatar.png" sizes="192x192">
    <link rel="apple-touch-icon" sizes="180x180" href="/images/avatar.png">
    <meta name="theme-color" content="#A31F34">
    <link rel="shortcut icon" href="/images/avatar.png">
    <!--- Page Info-->
    
    <title>
        
            LLM(Large Language Model) 学习笔记 | Academic Blog of LeoJeshua
        
    </title>

    <link rel="stylesheet" href="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/fonts/Chillax/chillax.css">

    <!--- Inject Part-->
    
        
            
    
            
    

    
<link rel="stylesheet" href="/css/style.css">


    
        <link rel="stylesheet" href="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/css/build/tailwind.css">
    

    <link rel="stylesheet" href="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/fonts/GeistMono/geist-mono.css">
    <link rel="stylesheet" href="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/fonts/Geist/geist.css">
    <!--- Font Part-->
    
    
    
    
    
    

    <script id="hexo-configurations">
    window.config = {"hostname":"leojeshua.github.io","root":"/","language":"en"};
    window.theme = {"articles":{"style":{"font_size":"16px","line_height":1.5,"image_border_radius":"2px","image_alignment":"center","image_caption":false,"link_icon":true,"delete_mask":false,"title_alignment":"left","headings_top_spacing":{"h1":"3.2rem","h2":"2.5rem","h3":"1.8rem","h4":"1.3rem","h5":"1.2rem","h6":"1.1rem"}},"word_count":{"enable":true,"count":true,"min2read":true},"author_label":{"enable":true,"auto":false,"list":[]},"code_block":{"copy":true,"style":"mac","highlight_theme":{"light":"github","dark":"vs2015"},"font":{"enable":false,"family":null,"url":null}},"toc":{"enable":true,"max_depth":4,"number":false,"expand":true,"init_open":true},"copyright":{"enable":true,"default":"cc_by_nc_sa"},"lazyload":true,"pangu_js":false,"recommendation":{"enable":false,"title":"推荐阅读","limit":3,"mobile_limit":2,"placeholder":"/images/wallhaven-wqery6-light.webp","skip_dirs":[]}},"colors":{"primary":"#A31F34","secondary":null,"default_mode":"light"},"global":{"fonts":{"chinese":{"enable":false,"family":null,"url":null},"english":{"enable":false,"family":null,"url":null},"title":{"enable":false,"family":null,"url":null}},"content_max_width":"1200px","sidebar_width":"30%","hover":{"shadow":true,"scale":false},"scroll_progress":{"bar":false,"percentage":true},"website_counter":{"url":"https://cn.vercount.one/js","enable":true,"site_pv":true,"site_uv":true,"post_pv":true},"single_page":true,"preloader":{"enable":false,"custom_message":null},"open_graph":{"enable":true,"image":"/images/redefine-og.webp","description":"Hexo Theme Redefine, Redefine Your Hexo Journey."},"google_analytics":{"enable":false,"id":null}},"home_banner":{"enable":true,"style":"static","image":{"light":"/images/wallhaven-wqery6-light.webp","dark":"/images/wallhaven-wqery6-dark.webp"},"title":"从-1开始的科研训练之路","subtitle":{"text":["If you shed tears when you miss the sun, you also miss the stars.","Reading maketh a full man; conference a ready man; and writing an exact man. (Francis Bacon)","Who drives me forward like fate? The Myself striding on my back."],"hitokoto":{"enable":false,"show_author":false,"api":"https://v1.hitokoto.cn"},"typing_speed":100,"backing_speed":80,"starting_delay":500,"backing_delay":1500,"loop":true,"smart_backspace":true},"text_color":{"light":"#fff","dark":"#d1d1b6"},"text_style":{"title_size":"2.8rem","subtitle_size":"1.5rem","line_height":1.2},"custom_font":{"enable":false,"family":null,"url":null},"social_links":{"enable":true,"style":"default","links":{"github":"https://github.com/LeoJeshua","instagram":null,"zhihu":null,"twitter":null,"email":"jiaxu.liu.ai@gmail.com"},"qrs":{"weixin":null}}},"plugins":{"feed":{"enable":false},"aplayer":{"enable":false,"type":"fixed","audios":[{"name":null,"artist":null,"url":null,"cover":null,"lrc":null}]},"mermaid":{"enable":false,"version":"11.4.1"}},"version":"2.8.2","navbar":{"auto_hide":true,"color":{"left":"#f78736","right":"#367df7","transparency":35},"width":{"home":"1200px","pages":"1000px"},"links":{"Home":{"path":"/","icon":"fa-regular fa-house"},"Archives":{"path":"/archives","icon":"fa-regular fa-archive"},"Categories":{"path":"/categories/","icon":"fa-regular fa-folder"},"Tags":{"icon":"fa-regular fa-tags","path":"/tags/"}},"search":{"enable":false,"preload":true}},"page_templates":{"friends_column":2,"tags_style":"cloud"},"home":{"sidebar":{"enable":true,"position":"right","first_item":"menu","announcement":"Aspiring to contribute to cutting-edge AI security research with a focus on offensive strategies to uncover and mitigate AI vulnerabilities.","show_on_mobile":true,"links":null},"article_date_format":"auto","excerpt_length":200,"categories":{"enable":true,"limit":3},"tags":{"enable":true,"limit":3}},"footerStart":"2024/12/20 21:33:00"};
    window.lang_ago = {"second":"%s seconds ago","minute":"%s minutes ago","hour":"%s hours ago","day":"%s days ago","week":"%s weeks ago","month":"%s months ago","year":"%s years ago"};
    window.data = {"masonry":false};
  </script>
    
    <!--- Fontawesome Part-->
    <link rel="stylesheet" href="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/fontawesome/fontawesome.min.css">
    <link rel="stylesheet" href="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/fontawesome/brands.min.css">
    <link rel="stylesheet" href="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/fontawesome/solid.min.css">
    <link rel="stylesheet" href="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/fontawesome/regular.min.css">
    
    
    
    
<meta name="generator" content="Hexo 7.3.0"><style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}
</style></head>



<body>
	<div class="progress-bar-container">
	

	
	<span class="pjax-progress-bar"></span>
	<!--        <span class="swup-progress-icon">-->
	<!--            <i class="fa-solid fa-circle-notch fa-spin"></i>-->
	<!--        </span>-->
	
</div>

<main class="page-container" id="swup">

	

	<div class="main-content-container flex flex-col justify-between min-h-dvh">
		<div class="main-content-header">
			<header class="navbar-container px-6 md:px-12">
    <div class="navbar-content transition-navbar ">
        <div class="left">
            
            <a class="logo-title" href="/">
                
                Academic Blog of LeoJeshua
                
            </a>
        </div>

        <div class="right">
            <!-- PC -->
            <div class="desktop">
                <ul class="navbar-list">
                    
                        
                            

                            <li class="navbar-item">
                                <!-- Menu -->
                                <a class=""
                                   href="/"
                                        >
                                    <i class="fa-regular fa-house fa-fw"></i>
                                    HOME
                                    
                                </a>

                                <!-- Submenu -->
                                
                            </li>
                    
                        
                            

                            <li class="navbar-item">
                                <!-- Menu -->
                                <a class=""
                                   href="/archives"
                                        >
                                    <i class="fa-regular fa-archive fa-fw"></i>
                                    ARCHIVES
                                    
                                </a>

                                <!-- Submenu -->
                                
                            </li>
                    
                        
                            

                            <li class="navbar-item">
                                <!-- Menu -->
                                <a class=""
                                   href="/categories/"
                                        >
                                    <i class="fa-regular fa-folder fa-fw"></i>
                                    CATEGORIES
                                    
                                </a>

                                <!-- Submenu -->
                                
                            </li>
                    
                        
                            

                            <li class="navbar-item">
                                <!-- Menu -->
                                <a class=""
                                   href="/tags/"
                                        >
                                    <i class="fa-regular fa-tags fa-fw"></i>
                                    TAGS
                                    
                                </a>

                                <!-- Submenu -->
                                
                            </li>
                    
                    
                </ul>
            </div>
            <!-- Mobile -->
            <div class="mobile">
                
                <div class="icon-item navbar-bar">
                    <div class="navbar-bar-middle"></div>
                </div>
            </div>
        </div>
    </div>

    <!-- Mobile sheet -->
    <div class="navbar-drawer h-dvh w-full absolute top-0 left-0 bg-background-color flex flex-col justify-between">
        <ul class="drawer-navbar-list flex flex-col px-4 justify-center items-start">
            
                
                    

                    <li class="drawer-navbar-item text-base my-1.5 flex flex-col w-full">
                        
                        <a class="py-1.5 px-2 flex flex-row items-center justify-between gap-1 hover:!text-primary active:!text-primary text-2xl font-semibold group border-b border-border-color hover:border-primary w-full "
                           href="/"
                        >
                            <span>
                                HOME
                            </span>
                            
                                <i class="fa-regular fa-house fa-sm fa-fw"></i>
                            
                        </a>
                        

                        
                    </li>
            
                
                    

                    <li class="drawer-navbar-item text-base my-1.5 flex flex-col w-full">
                        
                        <a class="py-1.5 px-2 flex flex-row items-center justify-between gap-1 hover:!text-primary active:!text-primary text-2xl font-semibold group border-b border-border-color hover:border-primary w-full "
                           href="/archives"
                        >
                            <span>
                                ARCHIVES
                            </span>
                            
                                <i class="fa-regular fa-archive fa-sm fa-fw"></i>
                            
                        </a>
                        

                        
                    </li>
            
                
                    

                    <li class="drawer-navbar-item text-base my-1.5 flex flex-col w-full">
                        
                        <a class="py-1.5 px-2 flex flex-row items-center justify-between gap-1 hover:!text-primary active:!text-primary text-2xl font-semibold group border-b border-border-color hover:border-primary w-full "
                           href="/categories/"
                        >
                            <span>
                                CATEGORIES
                            </span>
                            
                                <i class="fa-regular fa-folder fa-sm fa-fw"></i>
                            
                        </a>
                        

                        
                    </li>
            
                
                    

                    <li class="drawer-navbar-item text-base my-1.5 flex flex-col w-full">
                        
                        <a class="py-1.5 px-2 flex flex-row items-center justify-between gap-1 hover:!text-primary active:!text-primary text-2xl font-semibold group border-b border-border-color hover:border-primary w-full "
                           href="/tags/"
                        >
                            <span>
                                TAGS
                            </span>
                            
                                <i class="fa-regular fa-tags fa-sm fa-fw"></i>
                            
                        </a>
                        

                        
                    </li>
            

            
            
        </ul>

        <div class="statistics flex justify-around my-2.5">
    <a class="item tag-count-item flex flex-col justify-center items-center w-20" href="/tags">
        <div class="number text-2xl sm:text-xl text-second-text-color font-semibold">19</div>
        <div class="label text-third-text-color text-sm">Tags</div>
    </a>
    <a class="item tag-count-item flex flex-col justify-center items-center w-20" href="/categories">
        <div class="number text-2xl sm:text-xl text-second-text-color font-semibold">11</div>
        <div class="label text-third-text-color text-sm">Categories</div>
    </a>
    <a class="item tag-count-item flex flex-col justify-center items-center w-20" href="/archives">
        <div class="number text-2xl sm:text-xl text-second-text-color font-semibold">15</div>
        <div class="label text-third-text-color text-sm">Posts</div>
    </a>
</div>
    </div>

    <div class="window-mask"></div>

</header>


		</div>

		<div class="main-content-body transition-fade-up">
			

			<div class="main-content">
				<div class="post-page-container flex relative justify-between box-border w-full h-full">
	<div class="article-content-container">

		<div class="article-title relative w-full">
			
			
			
			<img src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20250308104519438.png" alt="LLM(Large Language Model) 学习笔记" class="w-full h-60 sm:h-72 md:h-80 object-cover sm:rounded-t-large dark:brightness-75" />
			
			<div class="w-full flex items-center absolute bottom-0 justify-start">
				<h1 class="article-title-cover text-center mx-6 my-6 text-second-text-color bg-background-color-transparent px-4 py-3 text-3xl sm:text-4xl md:text-5xl font-semibold backdrop-blur-lg rounded-xl border border-border-color ">LLM(Large Language Model) 学习笔记</h1>
			</div>
			
		</div>

		
		<div class="article-header flex flex-row gap-2 items-center px-2 sm:px-6 md:px-8">
			<div class="avatar w-[46px] h-[46px] flex-shrink-0 rounded-medium border border-border-color p-[1px]">
				<img src="/images/avatar.png">
			</div>
			<div class="info flex flex-col justify-between">
				<div class="author flex items-center">
					<span class="name text-default-text-color text-lg font-semibold">LeoJeshua</span>
					
					<span class="author-label ml-1.5 text-xs px-2 py-0.5 rounded-small text-third-text-color border border-shadow-color-1">Lv2</span>
					
				</div>
				<div class="meta-info">
					<div class="article-meta-info">
    <span class="article-date article-meta-item">
        <i class="fa-regular fa-pen-fancy"></i>&nbsp;
        <span class="desktop">2025-03-08 10:32</span>
        <span class="mobile">2025-03-08 10:32</span>
        <span class="hover-info">Created</span>
    </span>
    
        <span class="article-date article-meta-item">
            <i class="fa-regular fa-wrench"></i>&nbsp;
            <span class="desktop">2025-06-09 13:47:55</span>
            <span class="mobile">2025-06-09 13:47:55</span>
            <span class="hover-info">Updated</span>
        </span>
    

    
        <span class="article-categories article-meta-item">
            <i class="fa-regular fa-folders"></i>&nbsp;
            <ul>
                
                
                    
                        
                        <li>
                            <a href="/categories/AI/">AI</a>&nbsp;
                        </li>
                    
                    
                
                    
                        
                            <li>></li>
                        
                        <li>
                            <a href="/categories/AI/Foundations/">Foundations</a>&nbsp;
                        </li>
                    
                    
                
                    
                        
                            <li>></li>
                        
                        <li>
                            <a href="/categories/AI/Foundations/NLP/">NLP</a>&nbsp;
                        </li>
                    
                    
                
            </ul>
        </span>
    
    
        <span class="article-tags article-meta-item">
            <i class="fa-regular fa-tags"></i>&nbsp;
            <ul>
                
                    <li>
                        <a href="/tags/NLP/">NLP</a>&nbsp;
                    </li>
                
                    <li>
                        | <a href="/tags/LLMs/">LLMs</a>&nbsp;
                    </li>
                
            </ul>
        </span>
    

    
    
        <span class="article-wordcount article-meta-item">
            <i class="fa-regular fa-typewriter"></i>&nbsp;<span>2.7k Words</span>
        </span>
    
    
        <span class="article-min2read article-meta-item">
            <i class="fa-regular fa-clock"></i>&nbsp;<span>11 Mins</span>
        </span>
    
    
        <span class="article-pv article-meta-item">
            <i class="fa-regular fa-eye"></i>&nbsp;<span id="busuanzi_value_page_pv"></span>
        </span>
    
</div>

				</div>
			</div>
		</div>
		

		


		<div class="article-content markdown-body px-2 sm:px-6 md:px-8 pb-8">
			<h1 id="信息收集"><a href="#信息收集" class="headerlink" title="信息收集"></a>信息收集</h1><h2 id="参考推文"><a href="#参考推文" class="headerlink" title="参考推文"></a>参考推文</h2><ul>
<li><a class="link" target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/m8DeXxf10WtWhDmz8HbkgA">公众号：全球名校LLM大语言模型经典课程自学指南<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li><a class="link" target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/H__t-b130oymNly2Fn1TUw">公众号：GitHub上41.3k颗星的2025年最新免费LLM课程<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li><a class="link" target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/qw4CNN4z4-T_HUcezdkU0A">公众号：大神Karpathy亲授！最新LLM入门视频课！<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li><a class="link" target="_blank" rel="noopener" href="https://online.stanford.edu/programs/artificial-intelligence-graduate-certificate">斯坦福在线课程：人工智能研究生课程清单<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><ul>
<li>各课程详细介绍：<a class="link" target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=DzpHeXVSC5I">https://www.youtube.com/watch?v=DzpHeXVSC5I<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
</ul>
</li>
</ul>
<h2 id="资料总结"><a href="#资料总结" class="headerlink" title="资料总结"></a>资料总结</h2><h3 id="LLM全栈（课程视频）"><a href="#LLM全栈（课程视频）" class="headerlink" title="LLM全栈（课程视频）"></a>LLM全栈（课程视频）</h3><ol>
<li><p>斯坦福 <strong>CS224n: NLP with DL</strong></p>
<ul>
<li>page: <a class="link" target="_blank" rel="noopener" href="https://web.stanford.edu/class/cs224n/">https://web.stanford.edu/class/cs224n/<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li>vdeio: <a class="link" target="_blank" rel="noopener" href="https://www.youtube.com/playlist?list=PLoROMvodv4rMFqRtEuo6SGjY4XbRIVRd4">https://www.youtube.com/playlist?list=PLoROMvodv4rMFqRtEuo6SGjY4XbRIVRd4<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
</ul>
</li>
<li><p>CMU <strong>11-711: Advanced NLP</strong></p>
<ul>
<li>page: <a class="link" target="_blank" rel="noopener" href="https://phontron.com/class/anlp2024/">https://phontron.com/class/anlp2024/<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li>vedio: <a class="link" target="_blank" rel="noopener" href="https://www.youtube.com/@neubig/playlists">https://www.youtube.com/@neubig/playlists<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
</ul>
</li>
<li><p>普林斯顿 <strong>COS 597R：Deep Dive into LLM</strong></p>
<ul>
<li>page: <a class="link" target="_blank" rel="noopener" href="https://princeton-cos597r.github.io/">https://princeton-cos597r.github.io/<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li>vedio: 未公开</li>
</ul>
</li>
<li><p><strong>Andrej Karpathy</strong> (ps: 师从李飞飞，斯坦福cs231n设计者，openai联创，特斯拉自动驾驶系统高级总监)</p>
<ul>
<li>课程计划（未上线）：<a class="link" target="_blank" rel="noopener" href="https://github.com/karpathy/LLM101n">LLM101n<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li>youtube主页：<a class="link" target="_blank" rel="noopener" href="https://www.youtube.com/@AndrejKarpathy">https://www.youtube.com/@AndrejKarpathy<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><ul>
<li>2025/02/06 <a class="link" target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=7xTGNNLPyMI">Deep Dive into LLMs like ChatGPT<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><blockquote>
<p>This is a general audience deep dive into the Large Language Model (LLM) AI technology that powers ChatGPT and related products. It is covers the full training stack of how the models are developed, along with mental models of how to think about their “psychology”, and how to get the best use them in practical applications. I have one “Intro to LLMs” video already from ~year ago, but that is just a re-recording of a random talk, so I wanted to loop around and do a lot more comprehensive version.</p>
</blockquote>
<ul>
<li>时长：3h31min</li>
<li>全面覆盖了 <strong>LLM 的完整训练堆栈</strong>，从模型的开发过程，到如何建立理解其 “心理学” 的心智模型，再到如何在实际应用中最大化其效用，都进行了细致的讲解。</li>
<li>本次的新视频是一次更为全面和深入的尝试，旨在更完整地呈现 LLM 技术的全貌。（一年前发布的 “LLMs 导论” 仅为一次随机演讲的重新录制，之前的导论视频仍可作为补充，因为它更深入地探讨了其他主题，例如 LLM 操作系统和 LLM 安全。）</li>
</ul>
</li>
<li>2025/02/28 <a class="link" target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=EWvNQjAaOHw">How I use LLMs<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><blockquote>
<p>The example-driven, practical walkthrough of Large Language Models and their growing list of related features, as a new entry to my general audience series on LLMs. In this more practical followup, I take you through the many ways I use LLMs in my own life.</p>
</blockquote>
<ul>
<li>时长：2h21min</li>
<li>笔记：<a class="link" target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/UOXI2Pg4SBvZiWY9e2nxuA">「听课 - Andrej Karpathy」 我如何使用大语言模型<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>Jay Alammar</strong> (Co-authors of “Hands-On Large Language Models” | 《动手学LLMs》的合著者)</p>
</li>
</ol>
<ul>
<li><a class="link" target="_blank" rel="noopener" href="https://jalammar.github.io/illustrated-transformer/">The Illustrated Transformer<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li><a class="link" target="_blank" rel="noopener" href="https://www.deeplearning.ai/short-courses/how-transformer-llms-work/">deeplearning.ai: How Transformer LLMs Work<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><ul>
<li>1 Hour 35 Minutes (短期课程)</li>
<li>13 Video Lessons</li>
<li>3 Code Examples</li>
<li>Instructors: Jay Alammar, Maarten Grootendorst</li>
<li>基础知识，包括Bag-of-Words, (word) embedding, attention, transformers, tokenizers, self-attention, MoE等知识点</li>
</ul>
</li>
</ul>
<h3 id="LLM全栈（文本资料）"><a href="#LLM全栈（文本资料）" class="headerlink" title="LLM全栈（文本资料）"></a>LLM全栈（文本资料）</h3><ol>
<li>Paper: <strong>“A Comprehensive Overview of Large Language Models”</strong><ul>
<li>pdf: <a class="link" target="_blank" rel="noopener" href="https://arxiv.org/pdf/2307.06435">https://arxiv.org/pdf/2307.06435<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li>Submitted on 12 Jul 2023 (v1), last revised <strong>17 Oct 2024 (this version, v10)</strong></li>
<li>包括 <code>Deepseek</code>/<code>Deepseek-V2</code>/<code>Grok-1</code>/<code>Grok-1.5</code>/<code>Gemini-1.5</code>/<code>OpenAI-o1</code> 等近期模型</li>
<li>正文35页，带引用47页<br><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20250308124551728.png"><br><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20250308124615157.png"></li>
</ul>
</li>
<li>Github: <a class="link" target="_blank" rel="noopener" href="https://github.com/mlabonne/llm-course">mlabonne/llm-course<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><br> <img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20250308104519438.png"><ul>
<li>Book: “LLM Engineer’s Handbook: Master the art of engineering large language models from concept to production”(Paperback – 22 October 2024) <ul>
<li><a class="link" target="_blank" rel="noopener" href="https://www.amazon.sg/dp/1836200072">amazon<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
</ul>
</li>
<li>Roadmap for Scientist:<br> <img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/mlabonne/llm-course/main/img/roadmap_scientist.png" alt="Roadmap"></li>
<li>Roadmap for Engineer:<br> <img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/mlabonne/llm-course/main/img/roadmap_engineer.png" alt="Roadmap"></li>
</ul>
</li>
<li><strong>DataWhale</strong><ol>
<li>基础知识：<a class="link" target="_blank" rel="noopener" href="https://datawhalechina.github.io/so-large-lm/">《大模型基础：一文了解大模型基础知识》<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li>应用开发：<a class="link" target="_blank" rel="noopener" href="https://datawhalechina.github.io/llm-universe/">《动手学大模型应用开发》<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li>手撕架构：<a class="link" target="_blank" rel="noopener" href="https://github.com/datawhalechina/tiny-universe">《大模型白盒子构建指南》<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><br><img lazyload="" src="/images/loading.svg" data-src="https://github.com/datawhalechina/tiny-universe/raw/main/images/tiny-universe-head2.png"><blockquote>
<p>本项目是一个从原理出发、以“白盒”为导向、围绕大模型全链路的“手搓”大模型指南，旨在帮助有传统深度学习基础的读者从底层原理出发，“纯手搓”搭建一个清晰、可用的大模型系统，包括大模型本身、RAG 框架、Agent 系统及大模型评估体系。本项目将从基础原理出发，深入剖析每一个技术点并附以完整的代码实现，以细致讲解和代码注释帮助读者独立复现大模型核心部分，并在复现中实现对大模型的深入理解与掌握。</p>
</blockquote>
</li>
<li>部署&amp;微调：<a class="link" target="_blank" rel="noopener" href="https://github.com/datawhalechina/self-llm">《开源大模型食用指南》<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><br><img lazyload="" src="/images/loading.svg" data-src="https://github.com/datawhalechina/self-llm/raw/master/images/head-img.png"><blockquote>
<p>《开源大模型食用指南》针对中国宝宝量身打造的基于Linux环境 <strong>快速微调（全参数/Lora）</strong>、<strong>部署</strong> 国内外开源大模型（LLM）/多模态大模型（MLLM）教程。</p>
</blockquote>
</li>
<li>进阶：<a class="link" target="_blank" rel="noopener" href="https://github.com/datawhalechina/happy-llm/">Happy-LLM<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a> (<a class="link" target="_blank" rel="noopener" href="https://www.datawhale.cn/learn/summary/179">pdf下载<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a> / <a class="link" target="_blank" rel="noopener" href="https://datawhalechina.github.io/happy-llm/#/">在线阅读<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>)<blockquote>
<p>很多小伙伴在看完 Datawhale开源项目：self-llm《开源大模型食用指南》后，感觉意犹未尽。于是我们（Datawhale）决定推出《Happy-LLM》项目，旨在帮助大家 <strong>深入理解LLM的原理和训练过程</strong>。</p>
</blockquote>
</li>
</ol>
</li>
</ol>
<h4 id="提示词工程"><a href="#提示词工程" class="headerlink" title="提示词工程"></a>提示词工程</h4><ul>
<li><a class="link" target="_blank" rel="noopener" href="https://www.promptingguide.ai/zh">Prompt Engineering Guide<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
</ul>
<h4 id="分布式训练"><a href="#分布式训练" class="headerlink" title="分布式训练"></a>分布式训练</h4><ul>
<li>跟李沐学AI：分布式训练【动手学深度学习v2】<ul>
<li><a class="link" target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1jU4y1G7iu/">bilibili video<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
</ul>
</li>
<li>Lil’Log: <strong>How to Train Really Large Models on Many GPUs?</strong><ul>
<li>发布于2021-09-25, 更新于2022-06-10</li>
<li><a class="link" target="_blank" rel="noopener" href="https://lilianweng.github.io/posts/2021-09-25-train-large/">https://lilianweng.github.io/posts/2021-09-25-train-large/<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li>训练并行性：单卡的主要瓶颈是 <strong>GPU内存不够</strong>，无法训练超大型神经网络<ol>
<li><strong>数据并行</strong> (Data Parallelism, DP)<ul>
<li><strong>Naive DP</strong>: 将相同的模型权重复制到多个worker中，并分配给每个worker一小部分数据，同时进行处理。<ul>
<li>当模型太大无法装入一台worker时，将未使用的参数卸载回 CPU，以使用有限的 GPU 内存。</li>
<li>数据交换传输应在后端进行，并且不会干扰训练计算。</li>
</ul>
</li>
<li>当每个minibatch结束时，worker需要同步<code>梯度</code>或<code>权重</code>以避免过时。<ol>
<li><strong>批量同步并行</strong> | Bulk synchronous parallels (BSP)</li>
</ol>
<ul>
<li>worker在每个minibatch结束时同步数据。（停止并等待其他机器发送梯度）</li>
</ul>
<ol start="2">
<li><strong>异步并行</strong> | Asynchronous parallel (ASP)</li>
</ol>
<ul>
<li>每个 GPU 工作器都异步处理数据，无需等待或停顿。</li>
<li>很可能使用过时的权重，从而降低统计学习效率。</li>
<li>尽管它增加了计算时间，但可能不会加快训练收敛时间。</li>
</ul>
<ol start="3">
<li><strong>梯度累计</strong> | “gradient accumulation” in Distribution Data Parallel (DDP)</li>
</ol>
<ul>
<li>折中方案，每 x iterations 全局同步一次梯度<br>   <img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20250325163244188.png"></li>
</ul>
</li>
</ul>
</li>
<li><strong>模型并行</strong> (Model Parallelism, MP)<br><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20250325163755693.png"> <ul>
<li>（动机）旨在解决 “模型权重无法放入单个节点” 的情况，<strong>模型参数分布在多台机器上。</strong></li>
<li>（优点）MP 仅在一个worker上分配一小部分模型参数，因此<strong>内存使用量和计算量均有所减少</strong>。</li>
<li>（方法）由于深度神经网络通常包含一堆垂直层，因此 <strong>按层拆分大型模型</strong> 似乎很简单，其中 <strong>一小组连续的层</strong> 被分组到一个工作器上的一个分区中。</li>
<li>（不足）然而，通过具有顺序依赖性的多个此类worker运行每个数据批次的简单实现，会导致 <strong>等待时间的巨大泡沫</strong> 和 <strong>计算资源的严重利用不足</strong>。</li>
</ul>
</li>
<li><strong>流水线并行</strong> (Pipeline parallelism, PP)<br><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20250325164324184.png"><ul>
<li>将模型并行与数据并行相结合，以减少低效的时间“泡沫”。</li>
<li>主要思想是将一个小批次拆分为多个微批次，并使每个阶段worker能够同时处理一个微批次。</li>
<li>请注意，每个微批次都需要两次传递，一次向前，一次向后。worker间通信仅传输激活（向前）和梯度（向后）。这些传递的调度方式和梯度的聚合方式因方法而异。 </li>
<li>【分区（worker）的数量】也称为 <strong>流水线深度</strong></li>
<li><code>PipeDream</code> 安排每个worker交替处理前向和后向传递（<code>1F1B</code>）<br><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20250325164506319.png"></li>
</ul>
</li>
<li><strong>张量并行</strong> (Tensor Parallelism, TP)<ul>
<li>模型并行和流水线并行都垂直分割模型。另一方面，我们可以在多个设备上 <strong>水平划分</strong> 一次【张量运算】，这称为张量并行 (TP)。<br><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20250325165011906.png"></li>
</ul>
</li>
</ol>
</li>
</ul>
</li>
</ul>
<h3 id="LLM安全"><a href="#LLM安全" class="headerlink" title="LLM安全"></a>LLM安全</h3><ul>
<li>“Foundational Challenges in Assuring Alignment and Safety of Large Language Models” | LLM在“对齐”和“安全”上面临的基本挑战<ul>
<li>page: <a class="link" target="_blank" rel="noopener" href="https://llm-safety-challenges.github.io/">https://llm-safety-challenges.github.io/<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li>pdf: <a class="link" target="_blank" rel="noopener" href="https://arxiv.org/pdf/2404.09932">https://arxiv.org/pdf/2404.09932<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><blockquote>
<p>Abstract: This work identifies <strong>18 foundational challenges</strong> in assuring the alignment and safety of large language models (LLMs). These challenges are organized into three different categories: <strong>scientific understanding of LLMs（1.对LLM的科学理解）</strong>, <strong>development and deployment methods（2.开发和部署方法）</strong>, and <strong>sociotechnical challenges（3.社会&amp;技术挑战）</strong>.<br>Based on the identified challenges, we pose 200+, concrete research questions.</p>
</blockquote>
</li>
</ul>
</li>
</ul>
<h1 id="Models"><a href="#Models" class="headerlink" title="Models"></a>Models</h1><h2 id="LLaMA系列"><a href="#LLaMA系列" class="headerlink" title="LLaMA系列"></a>LLaMA系列</h2><ul>
<li>web: <a class="link" target="_blank" rel="noopener" href="https://www.llama.com/">https://www.llama.com/<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li>Meta AI</li>
<li>models:<ul>
<li><a class="link" target="_blank" rel="noopener" href="https://www.llama.com/models/llama-3/">LLaMA 3<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li><a class="link" target="_blank" rel="noopener" href="https://www.llama.com/models/llama-4/">LLaMA 4<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
</ul>
</li>
</ul>
<p>LLaMA-1 系列：</p>
<ul>
<li>Meta于2023年2月发布了LLaMA-1，包括7B、13B、30B和65B四个参数量版本。</li>
<li>这些模型在超过1T token的语料上进行了预训练，其中最大的65B参数模型在2,048张A100 80G GPU上训练了近21天。</li>
<li>LLaMA-1因其开源性和优异性能迅速成为开源社区中最受欢迎的大模型之一。</li>
</ul>
<p>LLaMA-2 系列：</p>
<ul>
<li>2023年7月，Meta发布了LLaMA-2，包含7B、13B、34B和70B四个参数量版本，除了34B模型外，其他均已开源。</li>
<li>LLaMA-2将预训练的语料扩充到了2T token，并将模型的上下文长度从2,048翻倍到了4,096。</li>
<li>引入了分组查询注意力机制（Grouped-Query Attention, GQA）等技术。</li>
</ul>
<p>LLaMA-3 系列：</p>
<ul>
<li>2024年4月，Meta发布了LLaMA-3，包括8B和70B两个参数量版本，同时透露400B的LLaMA-3还在训练中。</li>
<li>LLaMA-3支持8K长文本，并采用了编码效率更高的tokenizer，词表大小为128K。</li>
<li>使用了超过15T token的预训练语料，是LLaMA-2的7倍多。</li>
</ul>
<h3 id="LLaMA-1-2023-02"><a href="#LLaMA-1-2023-02" class="headerlink" title="LLaMA 1 (2023.02)"></a>LLaMA 1 (2023.02)</h3><p><em>LLaMA: Open and Efficient Foundation Language Models</em></p>
<ul>
<li>arXiv: 2302.13971v1 [cs.CL] 27 Feb 2023</li>
<li>核心Idea：<ul>
<li>计算成本重要性：推理时 &gt; 训练时</li>
<li>因此 <strong>对于一定参数量的模型，用更多data训练出更好的表现</strong>（同样表现的下的模型更小）<ul>
<li>训练成本变大</li>
<li>推理成本变小 ⭐</li>
</ul>
</li>
</ul>
</li>
<li>数据集大小：1.4T tokens</li>
<li>模型大小：<ul>
<li>7B</li>
<li>13B（比175B的GPT-3表现好）</li>
<li>33B</li>
<li>65B（对标Chinchilla-70B和PaLM-540B）</li>
</ul>
</li>
<li>训练成本(65B)：<ul>
<li>2048张A100(80G of RAM)</li>
<li>21 days</li>
<li>380 tokens/sec/GPU</li>
</ul>
</li>
</ul>
<h4 id="Approach"><a href="#Approach" class="headerlink" title="Approach"></a>Approach</h4><h5 id="Pre-training-Data"><a href="#Pre-training-Data" class="headerlink" title="Pre-training Data"></a>Pre-training Data</h5><ul>
<li>数据集总tokens：1.4T</li>
<li>除了Wikipedia和Books的数据（2个epoch），大多token在训练中只用一次（1个epoch）</li>
</ul>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20250608230251095.png"></p>
<h5 id="Architecture-⭐"><a href="#Architecture-⭐" class="headerlink" title="Architecture ⭐"></a>Architecture ⭐</h5><p>基于transformer架构，并借鉴之前一些工作的改进方案</p>
<ol>
<li><strong>Pre-norm</strong> &amp; <strong>RMSNorm</strong><ul>
<li>借鉴自 GPT-3，替换 Post-norm 和 LayerNorm</li>
</ul>
</li>
<li><strong>SwiGLU</strong> activation function<ul>
<li>借鉴自 PaLM，替换 ReLU</li>
<li>a dimension of <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.816ex;" xmlns="http://www.w3.org/2000/svg" width="4.103ex" height="2.773ex" role="img" focusable="false" viewBox="0 -864.9 1813.6 1225.5"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mfrac"><g data-mml-node="mn" transform="translate(220,394) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="mn" transform="translate(220,-345) scale(0.707)"><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path></g><rect width="553.6" height="60" x="120" y="220"></rect></g><g data-mml-node="mn" transform="translate(793.6,0)"><path data-c="34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z"></path></g><g data-mml-node="mi" transform="translate(1293.6,0)"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g></g></g></svg></mjx-container> instead of <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.023ex;" xmlns="http://www.w3.org/2000/svg" width="2.308ex" height="1.593ex" role="img" focusable="false" viewBox="0 -694 1020 704"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mn"><path data-c="34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z"></path></g><g data-mml-node="mi" transform="translate(500,0)"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g></g></g></svg></mjx-container> as in PaLM</li>
</ul>
</li>
<li><strong>Rotary Position Embeddings (RoPE)</strong><ul>
<li>借鉴自 GPTNeo，替换 absolute positional embeddings</li>
</ul>
</li>
</ol>
<p>不同size的模型的超参细节<br><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20250608231142370.png"></p>
<h5 id="Optimizer"><a href="#Optimizer" class="headerlink" title="Optimizer"></a>Optimizer</h5><ul>
<li>标准优化器: AdamW optimizer(β1 = 0.9, β2 = 0.95)</li>
<li>a cosine learning rate schedule | 余弦学习率策略<ul>
<li>最终学习率降至最大学习率的10%</li>
</ul>
</li>
<li>weight decay: 0.1</li>
<li>gradient clipping: 1.0</li>
<li>warmup steps: 2000</li>
<li>learning rate和batch size也随模型大小而改变（见Table 2）</li>
</ul>
<h5 id="Efficient-implementation"><a href="#Efficient-implementation" class="headerlink" title="Efficient implementation"></a>Efficient implementation</h5><p>高效实现模型计算/训练时间</p>
<ol>
<li>高效实现 causal Multi-Head Attention 来 减小runtime的memory<ul>
<li>通过：不存储/计算 mask部分的 key/query scores</li>
<li>代码：available in <code>xformers</code> library</li>
</ul>
</li>
<li>减少重复计算的activations数量<ul>
<li>通过：保存activations that are expensive to compute（例如the outputs of linear layers）</li>
<li>代码：手工实现transformer layers的 <code>backward function</code></li>
</ul>
</li>
<li>减少model的内存占用<ul>
<li>通过：model并行 / sequence并行</li>
</ul>
</li>
<li>同时进行 activation计算 和 GPU通信<ul>
<li>通过：<code>all_reduce</code> 操作</li>
</ul>
</li>
</ol>
<h4 id="Main-Results-TBD"><a href="#Main-Results-TBD" class="headerlink" title="Main Results (TBD)"></a>Main Results (TBD)</h4><h4 id="Instruction-Finetuning-TBD"><a href="#Instruction-Finetuning-TBD" class="headerlink" title="Instruction Finetuning (TBD)"></a>Instruction Finetuning (TBD)</h4><h4 id="Bias-Toxicity-and-Misinformation-TBD"><a href="#Bias-Toxicity-and-Misinformation-TBD" class="headerlink" title="Bias, Toxicity and Misinformation (TBD)"></a>Bias, Toxicity and Misinformation (TBD)</h4><h3 id="LLaMA-2-2023-07"><a href="#LLaMA-2-2023-07" class="headerlink" title="LLaMA 2 (2023.07)"></a>LLaMA 2 (2023.07)</h3><h3 id="LLaMA-3-2024-04"><a href="#LLaMA-3-2024-04" class="headerlink" title="LLaMA 3 (2024.04)"></a>LLaMA 3 (2024.04)</h3><h3 id="LLaMA-4-2025-04"><a href="#LLaMA-4-2025-04" class="headerlink" title="LLaMA 4 (2025.04)"></a>LLaMA 4 (2025.04)</h3><p><a class="link" target="_blank" rel="noopener" href="https://ai.meta.com/blog/llama-4-multimodal-intelligence/">The Llama 4 herd: The beginning of a new era of natively multimodal AI innovation<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><br><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20250609134222742.png"></p>

		</div>

		
		<div class="post-copyright-info w-full my-8 px-2 sm:px-6 md:px-8">
			<div class="article-copyright-info-container">
    <ul>
        <li><strong>Title:</strong> LLM(Large Language Model) 学习笔记</li>
        <li><strong>Author:</strong> LeoJeshua</li>
        <li><strong>Created at
                :</strong> 2025-03-08 10:32:00</li>
        
            <li>
                <strong>Updated at
                    :</strong> 2025-06-09 13:47:55
            </li>
        
        <li>
            <strong>Link:</strong> https://leojeshua.github.io/NLP/LLM/
        </li>
        <li>
            <strong>
                License:
            </strong>
            

            
                This work is licensed under <a class="license" target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0">CC BY-NC-SA 4.0</a>.
            
        </li>
    </ul>
</div>

		</div>
		

		
		<ul class="post-tags-box text-lg mt-1.5 flex-wrap justify-center flex md:hidden">
			
			<li class="tag-item mx-0.5">
				<a href="/tags/NLP/">#NLP</a>&nbsp;
			</li>
			
			<li class="tag-item mx-0.5">
				<a href="/tags/LLMs/">#LLMs</a>&nbsp;
			</li>
			
		</ul>
		

		

		
		<div class="article-nav my-8 flex justify-between items-center px-2 sm:px-6 md:px-8">
			
			<div class="article-prev border-border-color shadow-redefine-flat shadow-shadow-color-2 rounded-medium px-4 py-2 hover:shadow-redefine-flat-hover hover:shadow-shadow-color-2">
				<a class="prev" rel="prev" href="/Multimodal/Multimodal/">
					<span class="left arrow-icon flex justify-center items-center">
						<i class="fa-solid fa-chevron-left"></i>
					</span>
					<span class="title flex justify-center items-center">
						<span class="post-nav-title-item">多模态(Multimodal) 及 多模态大语言模型(MLLMs) 学习笔记</span>
						<span class="post-nav-item">Prev posts</span>
					</span>
				</a>
			</div>
			
			
			<div class="article-next border-border-color shadow-redefine-flat shadow-shadow-color-2 rounded-medium px-4 py-2 hover:shadow-redefine-flat-hover hover:shadow-shadow-color-2">
				<a class="next" rel="next" href="/CV/Steganography/">
					<span class="title flex justify-center items-center">
						<span class="post-nav-title-item">Image Steganography</span>
						<span class="post-nav-item">Next posts</span>
					</span>
					<span class="right arrow-icon flex justify-center items-center">
						<i class="fa-solid fa-chevron-right"></i>
					</span>
				</a>
			</div>
			
		</div>
		


		
	</div>

	
	<div class="toc-content-container">
		<div class="post-toc-wrap">
    <div class="post-toc">
        <div class="toc-title">On this page</div>
        <div class="page-title">
            LLM(Large Language Model) 学习笔记
        </div>
        <ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%BF%A1%E6%81%AF%E6%94%B6%E9%9B%86"><span class="nav-text">信息收集</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8F%82%E8%80%83%E6%8E%A8%E6%96%87"><span class="nav-text">参考推文</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%B5%84%E6%96%99%E6%80%BB%E7%BB%93"><span class="nav-text">资料总结</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#LLM%E5%85%A8%E6%A0%88%EF%BC%88%E8%AF%BE%E7%A8%8B%E8%A7%86%E9%A2%91%EF%BC%89"><span class="nav-text">LLM全栈（课程视频）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#LLM%E5%85%A8%E6%A0%88%EF%BC%88%E6%96%87%E6%9C%AC%E8%B5%84%E6%96%99%EF%BC%89"><span class="nav-text">LLM全栈（文本资料）</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B"><span class="nav-text">提示词工程</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83"><span class="nav-text">分布式训练</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#LLM%E5%AE%89%E5%85%A8"><span class="nav-text">LLM安全</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Models"><span class="nav-text">Models</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#LLaMA%E7%B3%BB%E5%88%97"><span class="nav-text">LLaMA系列</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#LLaMA-1-2023-02"><span class="nav-text">LLaMA 1 (2023.02)</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Approach"><span class="nav-text">Approach</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Main-Results-TBD"><span class="nav-text">Main Results (TBD)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Instruction-Finetuning-TBD"><span class="nav-text">Instruction Finetuning (TBD)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Bias-Toxicity-and-Misinformation-TBD"><span class="nav-text">Bias, Toxicity and Misinformation (TBD)</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#LLaMA-2-2023-07"><span class="nav-text">LLaMA 2 (2023.07)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#LLaMA-3-2024-04"><span class="nav-text">LLaMA 3 (2024.04)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#LLaMA-4-2025-04"><span class="nav-text">LLaMA 4 (2025.04)</span></a></li></ol></li></ol></li></ol>

    </div>
</div>
	</div>
	
</div>
			</div>

			
		</div>

		<div class="main-content-footer">
			<footer class="footer mt-5 py-5 h-auto text-base text-third-text-color relative border-t-2 border-t-border-color">
    <div class="info-container py-3 text-center">
        
        <div class="text-center">
            &copy;
            
              <span>2024</span>
              -
            
            2025&nbsp;&nbsp;<i class="fa-solid fa-cog fa-spin" style="--fa-animation-duration:15s"></i>&nbsp;&nbsp;<a href="/">LeoJeshua</a>
            
                
                <p class="post-count space-x-0.5">
                    <span>
                        15 posts in total
                    </span>
                    
                        <span>
                            23.4k words in total
                        </span>
                    
                </p>
            
        </div>
        
            <script data-swup-reload-script src="https://cn.vercount.one/js"></script>
            <div class="relative text-center lg:absolute lg:right-[20px] lg:top-1/2 lg:-translate-y-1/2 lg:text-right">
                
                    <span id="busuanzi_container_site_uv" class="lg:!block">
                        <span class="text-sm">VISITOR COUNT</span>
                        <span id="busuanzi_value_site_uv"></span>
                    </span>
                
                
                    <span id="busuanzi_container_site_pv" class="lg:!block">
                        <span class="text-sm">TOTAL PAGE VIEWS</span>
                        <span id="busuanzi_value_site_pv"></span>
                    </span>
                
            </div>
        
        <div class="relative text-center lg:absolute lg:left-[20px] lg:top-1/2 lg:-translate-y-1/2 lg:text-left">
            <span class="lg:block text-sm">POWERED BY <?xml version="1.0" encoding="utf-8"?><!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"><svg class="relative top-[2px] inline-block align-baseline" version="1.1" id="圖層_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" width="1rem" height="1rem" viewBox="0 0 512 512" enable-background="new 0 0 512 512" xml:space="preserve"><path fill="#0E83CD" d="M256.4,25.8l-200,115.5L56,371.5l199.6,114.7l200-115.5l0.4-230.2L256.4,25.8z M349,354.6l-18.4,10.7l-18.6-11V275H200v79.6l-18.4,10.7l-18.6-11v-197l18.5-10.6l18.5,10.8V237h112v-79.6l18.5-10.6l18.5,10.8V354.6z"/></svg><a target="_blank" class="text-base" href="https://hexo.io">Hexo</a></span>
            <span class="text-sm lg:block">THEME&nbsp;<a class="text-base" target="_blank" href="https://github.com/EvanNotFound/hexo-theme-redefine">Redefine v2.8.2</a></span>
        </div>
        
        
            <div>
                Blog up for <span class="odometer" id="runtime_days" ></span> days <span class="odometer" id="runtime_hours"></span> hrs <span class="odometer" id="runtime_minutes"></span> Min <span class="odometer" id="runtime_seconds"></span> Sec
            </div>
        
        
            <script data-swup-reload-script>
                try {
                    function odometer_init() {
                    const elements = document.querySelectorAll('.odometer');
                    elements.forEach(el => {
                        new Odometer({
                            el,
                            format: '( ddd).dd',
                            duration: 200
                        });
                    });
                    }
                    odometer_init();
                } catch (error) {}
            </script>
        
        
            
                
        
                
        
                

                    
                        <script data-swup-reload-script>var url_1736="https://api.cdnorg.cn:666";var token_1736="8d393e3086e1d2d48267460f67b7bf8d1a09f23f231d32de4f3fb3a12f3af020";var cltj_1736=document.createElement("script");cltj_1736.src=url_1736+"/tj/tongji.js?v=2.201";var s_1736=document.getElementsByTagName("script")[0];s_1736.parentNode.insertBefore(cltj_1736,s_1736);</script>
                    
        
                

                    
                        <script data-swup-reload-script type="text/javascript">(function(){var baidu=document.createElement("script");baidu.src="//i.6v6.work/v/?uid=388547";var cnzz=document.getElementsByTagName("script")[0];cnzz.parentNode.insertBefore(baidu,cnzz)})();</script>
                    
        
        
    </div>  
</footer>
		</div>
	</div>

	
	<div class="post-tools">
		<div class="post-tools-container">
	<ul class="article-tools-list">
		<!-- TOC aside toggle -->
		
		<li class="right-bottom-tools page-aside-toggle">
			<i class="fa-regular fa-outdent"></i>
		</li>
		

		<!-- go comment -->
		
	</ul>
</div>
	</div>
	

	<div class="right-side-tools-container">
		<div class="side-tools-container">
	<ul class="hidden-tools-list">
		<li class="right-bottom-tools tool-font-adjust-plus flex justify-center items-center">
			<i class="fa-regular fa-magnifying-glass-plus"></i>
		</li>

		<li class="right-bottom-tools tool-font-adjust-minus flex justify-center items-center">
			<i class="fa-regular fa-magnifying-glass-minus"></i>
		</li>

		<li class="right-bottom-tools tool-dark-light-toggle flex justify-center items-center">
			<i class="fa-regular fa-moon"></i>
		</li>

		<!-- rss -->
		

		

		<li class="right-bottom-tools tool-scroll-to-bottom flex justify-center items-center">
			<i class="fa-regular fa-arrow-down"></i>
		</li>
	</ul>

	<ul class="visible-tools-list">
		<li class="right-bottom-tools toggle-tools-list flex justify-center items-center">
			<i class="fa-regular fa-cog fa-spin"></i>
		</li>
		
		<li class="right-bottom-tools tool-scroll-to-top flex justify-center items-center">
			<i class="arrow-up fas fa-arrow-up"></i>
			<span class="percent"></span>
		</li>
		
		
	</ul>
</div>
	</div>

	<div class="image-viewer-container">
	<img src="">
</div>

	

</main>


<script  src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/js/build/libs/Swup.min.js" ></script><script  src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/js/build/libs/SwupSlideTheme.min.js" ></script><script  src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/js/build/libs/SwupScriptsPlugin.min.js" ></script><script  src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/js/build/libs/SwupProgressPlugin.min.js" ></script><script  src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/js/build/libs/SwupScrollPlugin.min.js" ></script><script  src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/js/build/libs/SwupPreloadPlugin.min.js" ></script>
<script>
    const swup = new Swup({
        plugins: [
            new SwupScriptsPlugin({
                optin: true,
            }),
            new SwupProgressPlugin(),
            new SwupScrollPlugin({
                offset: 80,
            }),
            new SwupSlideTheme({
                mainElement: ".main-content-body",
            }),
            new SwupPreloadPlugin(),
        ],
        containers: ["#swup"],
    });
</script>




	<script type="module" src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/js/build/tools/imageViewer.js" ></script><script type="module" src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/js/build/utils.js" ></script><script type="module" src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/js/build/main.js" ></script><script type="module" src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/js/build/layouts/navbarShrink.js" ></script><script type="module" src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/js/build/tools/scrollTopBottom.js" ></script><script type="module" src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/js/build/tools/lightDarkSwitch.js" ></script><script type="module" src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/js/build/layouts/categoryList.js" ></script>




    <script type="module" src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/js/build/tools/codeBlock.js" ></script>



    <script type="module" src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/js/build/layouts/lazyload.js" ></script>



    <script  src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/js/build/tools/runtime.js" ></script>
    <script  src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/js/build/libs/odometer.min.js" ></script>
    <link rel="stylesheet" href="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/assets/odometer-theme-minimal.css">



  <script  src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/js/build/libs/Typed.min.js" ></script>
  <script type="module" src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/js/build/plugins/typed.js" ></script>







    <script  src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/js/build/libs/anime.min.js" ></script>




    <script type="module" src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/js/build/tools/tocToggle.js" data-swup-reload-script></script><script type="module" src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/js/build/layouts/toc.js" data-swup-reload-script></script><script type="module" src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/js/build/plugins/tabs.js" data-swup-reload-script></script>


<script  src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/js/build/libs/moment-with-locales.min.js" data-swup-reload-script></script>
<script type="module" src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/js/build/layouts/essays.js" data-swup-reload-script></script>




	
</body>

</html>