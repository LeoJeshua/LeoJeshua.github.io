<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="keywords" content="Hexo Theme Redefine">
    
    <meta name="author" content="LeoJeshua">
    
    <!-- Completely eliminate flash of wrong theme -->
    <script>
        (function() {
            const THEME_KEY = "REDEFINE-THEME-STATUS";
            const DARK = "dark", LIGHT = "light";
            
            // Get preferred theme
            function getTheme() {
                try {
                    const saved = localStorage.getItem(THEME_KEY);
                    if (saved) {
                        const { isDark } = JSON.parse(saved);
                        return isDark ? DARK : LIGHT;
                    }
                } catch (e) {}
                
                return matchMedia("(prefers-color-scheme: dark)").matches ? DARK : LIGHT;
            }
            
            // Apply theme to document
            function applyTheme(theme) {
                const isDark = theme === DARK;
                const root = document.documentElement;
                
                // Set data attribute for CSS variables
                root.setAttribute("data-theme", theme);
                
                // Set classes for compatibility
                root.classList.add(theme);
                root.classList.remove(isDark ? LIGHT : DARK);
                root.style.colorScheme = theme;
            }
            
            // Initial application
            const theme = getTheme();
            applyTheme(theme);
            
            // Listen for system preference changes
            matchMedia("(prefers-color-scheme: dark)").addEventListener("change", ({ matches }) => {
                // Only update if using system preference (no localStorage entry)
                if (!localStorage.getItem(THEME_KEY)) {
                    applyTheme(matches ? DARK : LIGHT);
                }
            });
            
            // Set body classes once DOM is ready
            if (document.readyState !== "loading") {
                document.body.classList.add(theme + "-mode");
            } else {
                document.addEventListener("DOMContentLoaded", () => {
                    document.body.classList.add(theme + "-mode");
                    document.body.classList.remove((theme === DARK ? LIGHT : DARK) + "-mode");
                });
            }
        })();
    </script>
    
    <!-- Critical CSS to prevent flash -->
    <style>
        :root[data-theme="dark"] {
            --background-color: #202124;
            --background-color-transparent: rgba(32, 33, 36, 0.6);
            --second-background-color: #2d2e32;
            --third-background-color: #34353a;
            --third-background-color-transparent: rgba(32, 33, 36, 0.6);
            --primary-color: #0066CC;
            --first-text-color: #ffffff;
            --second-text-color: #eeeeee;
            --third-text-color: #bebec6;
            --fourth-text-color: #999999;
            --default-text-color: #bebec6;
            --invert-text-color: #373D3F;
            --border-color: rgba(255, 255, 255, 0.08);
            --selection-color: #0066CC;
            --shadow-color-1: rgba(255, 255, 255, 0.08);
            --shadow-color-2: rgba(255, 255, 255, 0.05);
        }
        
        :root[data-theme="light"] {
            --background-color: #fff;
            --background-color-transparent: rgba(255, 255, 255, 0.6);
            --second-background-color: #f8f8f8;
            --third-background-color: #f2f2f2;
            --third-background-color-transparent: rgba(241, 241, 241, 0.6);
            --primary-color: #0066CC;
            --first-text-color: #16171a;
            --second-text-color: #2f3037;
            --third-text-color: #5e5e5e;
            --fourth-text-color: #eeeeee;
            --default-text-color: #373D3F;
            --invert-text-color: #bebec6;
            --border-color: rgba(0, 0, 0, 0.08);
            --selection-color: #0066CC;
            --shadow-color-1: rgba(0, 0, 0, 0.08);
            --shadow-color-2: rgba(0, 0, 0, 0.05);
        }
        
        body {
            background-color: var(--background-color);
            color: var(--default-text-color);
        }
        
        /* Apply body classes as soon as DOM is ready */
        :root[data-theme="dark"] body {
            background-color: var(--background-color);
            color: var(--default-text-color);
        }
    </style>
    
    <!-- preconnect -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>

    
        
        
        
            <link rel="preconnect" href="https://registry.npmmirror.com" crossorigin>
        
    
    <!--- Seo Part-->
    
    <link rel="canonical" href="https://leojeshua.github.io/dms/paper-collection-of-safe-diffusion/"/>
    <meta name="robots" content="index,follow">
    <meta name="googlebot" content="index,follow">
    <meta name="revisit-after" content="1 days">
    
    
    
        
        <meta name="description" content="Hexo Theme Redefine, Redefine Your Hexo Journey.">
<meta property="og:type" content="article">
<meta property="og:title" content="Paper Collection of Safe Diffusion">
<meta property="og:url" content="https://leojeshua.github.io/DMs/Paper-Collection-of-Safe-Diffusion/index.html">
<meta property="og:site_name" content="The Blog of LeoJeshua">
<meta property="og:description" content="Hexo Theme Redefine, Redefine Your Hexo Journey.">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://leojeshua.github.io/images/redefine-og.webp">
<meta property="article:published_time" content="2024-12-21T07:49:09.000Z">
<meta property="article:modified_time" content="2025-10-14T07:57:19.780Z">
<meta property="article:author" content="LeoJeshua">
<meta property="article:tag" content="DMs">
<meta property="article:tag" content="Paper Collection">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://leojeshua.github.io/images/redefine-og.webp">
    
    
    <!--- Icon Part-->
    <link rel="icon" type="image/png" href="/images/avatar.png" sizes="192x192">
    <link rel="apple-touch-icon" sizes="180x180" href="/images/avatar.png">
    <meta name="theme-color" content="#A31F34">
    <link rel="shortcut icon" href="/images/avatar.png">
    <!--- Page Info-->
    
    <title>
        
            Paper Collection of Safe Diffusion | Academic Blog of LeoJeshua
        
    </title>

    <link rel="stylesheet" href="https://registry.npmmirror.com/hexo-theme-redefine/2.8.5/files/source/fonts/Chillax/chillax.css">

    <!--- Inject Part-->
    
        
            
    
            
    

    
<link rel="stylesheet" href="/css/style.css">


    
        <link rel="stylesheet" href="https://registry.npmmirror.com/hexo-theme-redefine/2.8.5/files/source/css/build/tailwind.css">
    

    <link rel="stylesheet" href="https://registry.npmmirror.com/hexo-theme-redefine/2.8.5/files/source/fonts/GeistMono/geist-mono.css">
    <link rel="stylesheet" href="https://registry.npmmirror.com/hexo-theme-redefine/2.8.5/files/source/fonts/Geist/geist.css">
    <!--- Font Part-->
    
    
    
    
    
    

    <script id="hexo-configurations">
    window.config = {"hostname":"leojeshua.github.io","root":"/","language":"en"};
    window.theme = {"articles":{"style":{"font_size":"16px","line_height":1.5,"image_border_radius":"2px","image_alignment":"center","image_caption":false,"link_icon":true,"delete_mask":false,"title_alignment":"left","headings_top_spacing":{"h1":"3.2rem","h2":"2.5rem","h3":"1.8rem","h4":"1.3rem","h5":"1.2rem","h6":"1.1rem"}},"word_count":{"enable":true,"count":true,"min2read":true},"author_label":{"enable":true,"auto":false,"list":[]},"code_block":{"copy":true,"style":"mac","highlight_theme":{"light":"github","dark":"vs2015"},"font":{"enable":false,"family":null,"url":null}},"toc":{"enable":true,"max_depth":4,"number":false,"expand":true,"init_open":true},"copyright":{"enable":true,"default":"cc_by_nc_sa"},"lazyload":true,"pangu_js":false,"recommendation":{"enable":false,"title":"推荐阅读","limit":3,"mobile_limit":2,"placeholder":"/images/wallhaven-wqery6-light.webp","skip_dirs":[]}},"colors":{"primary":"#A31F34","secondary":null,"default_mode":"light"},"global":{"fonts":{"chinese":{"enable":false,"family":null,"url":null},"english":{"enable":false,"family":null,"url":null},"title":{"enable":false,"family":null,"url":null}},"content_max_width":"1200px","sidebar_width":"30%","hover":{"shadow":true,"scale":false},"scroll_progress":{"bar":false,"percentage":true},"website_counter":{"url":"https://cn.vercount.one/js","enable":true,"site_pv":true,"site_uv":true,"post_pv":true},"single_page":true,"preloader":{"enable":false,"custom_message":null},"side_tools":{"gear_rotation":true,"auto_expand":false},"open_graph":{"enable":true,"image":"/images/redefine-og.webp","description":"Hexo Theme Redefine, Redefine Your Hexo Journey."},"google_analytics":{"enable":false,"id":null}},"home_banner":{"enable":true,"style":"static","image":{"light":"/images/wallhaven-wqery6-light.webp","dark":"/images/wallhaven-wqery6-dark.webp"},"title":"从-1开始的科研训练之路","subtitle":{"text":["If you shed tears when you miss the sun, you also miss the stars.","Reading maketh a full man; conference a ready man; and writing an exact man. (Francis Bacon)","Who drives me forward like fate? The Myself striding on my back."],"hitokoto":{"enable":false,"show_author":false,"api":"https://v1.hitokoto.cn"},"typing_speed":100,"backing_speed":80,"starting_delay":500,"backing_delay":1500,"loop":true,"smart_backspace":true},"text_color":{"light":"#fff","dark":"#d1d1b6"},"text_style":{"title_size":"2.8rem","subtitle_size":"1.5rem","line_height":1.2},"custom_font":{"enable":false,"family":null,"url":null},"social_links":{"enable":true,"style":"default","links":{"github":"https://github.com/LeoJeshua","instagram":null,"zhihu":null,"twitter":null,"email":"jiaxu.liu.ai@gmail.com"},"qrs":{"weixin":null}}},"plugins":{"feed":{"enable":false},"aplayer":{"enable":false,"type":"fixed","audios":[{"name":null,"artist":null,"url":null,"cover":null,"lrc":null}]},"mermaid":{"enable":false,"version":"11.4.1"}},"version":"2.8.5","navbar":{"auto_hide":true,"color":{"left":"#f78736","right":"#367df7","transparency":35},"width":{"home":"1200px","pages":"1000px"},"links":{"Home":{"path":"/","icon":"fa-regular fa-house"},"Archives":{"path":"/archives","icon":"fa-regular fa-archive"},"Categories":{"path":"/categories/","icon":"fa-regular fa-folder"},"Tags":{"icon":"fa-regular fa-tags","path":"/tags/"}},"search":{"enable":false,"preload":true}},"page_templates":{"friends_column":2,"tags_style":"cloud"},"home":{"sidebar":{"enable":true,"position":"right","first_item":"menu","announcement":"Aspiring to contribute to cutting-edge AI security research with a focus on offensive strategies to uncover and mitigate AI vulnerabilities.","show_on_mobile":true,"links":null},"article_date_format":"auto","excerpt_length":200,"categories":{"enable":true,"limit":3},"tags":{"enable":true,"limit":3}},"footerStart":"2024/12/20 21:33:00"};
    window.lang_ago = {"second":"%s seconds ago","minute":"%s minutes ago","hour":"%s hours ago","day":"%s days ago","week":"%s weeks ago","month":"%s months ago","year":"%s years ago"};
    window.data = {"masonry":false};
  </script>
    
    <!--- Fontawesome Part-->
    <link rel="stylesheet" href="https://registry.npmmirror.com/hexo-theme-redefine/2.8.5/files/source/fontawesome/fontawesome.min.css">
    <link rel="stylesheet" href="https://registry.npmmirror.com/hexo-theme-redefine/2.8.5/files/source/fontawesome/brands.min.css">
    <link rel="stylesheet" href="https://registry.npmmirror.com/hexo-theme-redefine/2.8.5/files/source/fontawesome/solid.min.css">
    <link rel="stylesheet" href="https://registry.npmmirror.com/hexo-theme-redefine/2.8.5/files/source/fontawesome/regular.min.css">
    
    
    
    
<meta name="generator" content="Hexo 7.3.0"></head>



<body>
	<div class="progress-bar-container">
	

	
	<span class="pjax-progress-bar"></span>
	<!--        <span class="swup-progress-icon">-->
	<!--            <i class="fa-solid fa-circle-notch fa-spin"></i>-->
	<!--        </span>-->
	
</div>

<main class="page-container" id="swup">

	

	<div class="main-content-container flex flex-col justify-between min-h-dvh">
		<div class="main-content-header">
			<header class="navbar-container px-6 md:px-12">
    <div class="navbar-content transition-navbar ">
        <div class="left">
            
            <a class="logo-title" href="/">
                
                Academic Blog of LeoJeshua
                
            </a>
        </div>

        <div class="right">
            <!-- PC -->
            <div class="desktop">
                <ul class="navbar-list">
                    
                        
                            

                            <li class="navbar-item">
                                <!-- Menu -->
                                <a class=""
                                   href="/"
                                        >
                                    <i class="fa-regular fa-house fa-fw"></i>
                                    HOME
                                    
                                </a>

                                <!-- Submenu -->
                                
                            </li>
                    
                        
                            

                            <li class="navbar-item">
                                <!-- Menu -->
                                <a class=""
                                   href="/archives"
                                        >
                                    <i class="fa-regular fa-archive fa-fw"></i>
                                    ARCHIVES
                                    
                                </a>

                                <!-- Submenu -->
                                
                            </li>
                    
                        
                            

                            <li class="navbar-item">
                                <!-- Menu -->
                                <a class=""
                                   href="/categories/"
                                        >
                                    <i class="fa-regular fa-folder fa-fw"></i>
                                    CATEGORIES
                                    
                                </a>

                                <!-- Submenu -->
                                
                            </li>
                    
                        
                            

                            <li class="navbar-item">
                                <!-- Menu -->
                                <a class=""
                                   href="/tags/"
                                        >
                                    <i class="fa-regular fa-tags fa-fw"></i>
                                    TAGS
                                    
                                </a>

                                <!-- Submenu -->
                                
                            </li>
                    
                    
                </ul>
            </div>
            <!-- Mobile -->
            <div class="mobile">
                
                <div class="icon-item navbar-bar">
                    <div class="navbar-bar-middle"></div>
                </div>
            </div>
        </div>
    </div>

    <!-- Mobile sheet -->
    <div class="navbar-drawer h-dvh w-full absolute top-0 left-0 bg-background-color flex flex-col justify-between">
        <ul class="drawer-navbar-list flex flex-col px-4 justify-center items-start">
            
                
                    

                    <li class="drawer-navbar-item text-base my-1.5 flex flex-col w-full">
                        
                        <a class="py-1.5 px-2 flex flex-row items-center justify-between gap-1 hover:!text-primary active:!text-primary text-2xl font-semibold group border-b border-border-color hover:border-primary w-full "
                           href="/"
                        >
                            <span>
                                HOME
                            </span>
                            
                                <i class="fa-regular fa-house fa-sm fa-fw"></i>
                            
                        </a>
                        

                        
                    </li>
            
                
                    

                    <li class="drawer-navbar-item text-base my-1.5 flex flex-col w-full">
                        
                        <a class="py-1.5 px-2 flex flex-row items-center justify-between gap-1 hover:!text-primary active:!text-primary text-2xl font-semibold group border-b border-border-color hover:border-primary w-full "
                           href="/archives"
                        >
                            <span>
                                ARCHIVES
                            </span>
                            
                                <i class="fa-regular fa-archive fa-sm fa-fw"></i>
                            
                        </a>
                        

                        
                    </li>
            
                
                    

                    <li class="drawer-navbar-item text-base my-1.5 flex flex-col w-full">
                        
                        <a class="py-1.5 px-2 flex flex-row items-center justify-between gap-1 hover:!text-primary active:!text-primary text-2xl font-semibold group border-b border-border-color hover:border-primary w-full "
                           href="/categories/"
                        >
                            <span>
                                CATEGORIES
                            </span>
                            
                                <i class="fa-regular fa-folder fa-sm fa-fw"></i>
                            
                        </a>
                        

                        
                    </li>
            
                
                    

                    <li class="drawer-navbar-item text-base my-1.5 flex flex-col w-full">
                        
                        <a class="py-1.5 px-2 flex flex-row items-center justify-between gap-1 hover:!text-primary active:!text-primary text-2xl font-semibold group border-b border-border-color hover:border-primary w-full "
                           href="/tags/"
                        >
                            <span>
                                TAGS
                            </span>
                            
                                <i class="fa-regular fa-tags fa-sm fa-fw"></i>
                            
                        </a>
                        

                        
                    </li>
            

            
            
        </ul>

        <div class="statistics flex justify-around my-2.5">
    <a class="item tag-count-item flex flex-col justify-center items-center w-20" href="/tags">
        <div class="number text-2xl sm:text-xl text-second-text-color font-semibold">19</div>
        <div class="label text-third-text-color text-sm">Tags</div>
    </a>
    <a class="item tag-count-item flex flex-col justify-center items-center w-20" href="/categories">
        <div class="number text-2xl sm:text-xl text-second-text-color font-semibold">11</div>
        <div class="label text-third-text-color text-sm">Categories</div>
    </a>
    <a class="item tag-count-item flex flex-col justify-center items-center w-20" href="/archives">
        <div class="number text-2xl sm:text-xl text-second-text-color font-semibold">15</div>
        <div class="label text-third-text-color text-sm">Posts</div>
    </a>
</div>
    </div>

    <div class="window-mask"></div>

</header>


		</div>

		<div class="main-content-body transition-fade-up">
			

			<div class="main-content">
				<div class="post-page-container flex relative justify-between box-border w-full h-full">
	<div class="article-content-container">

		<div class="article-title relative w-full">
			
			<div class="w-full flex items-center pt-6 justify-start">
				<h1 class="article-title-regular text-second-text-color tracking-tight text-4xl md:text-6xl font-semibold px-2 sm:px-6 md:px-8 py-3">Paper Collection of Safe Diffusion</h1>
			</div>
			
		</div>

		
		<div class="article-header flex flex-row gap-2 items-center px-2 sm:px-6 md:px-8">
			<div class="avatar w-[46px] h-[46px] flex-shrink-0 rounded-medium border border-border-color p-[1px]">
				<img src="/images/avatar.png">
			</div>
			<div class="info flex flex-col justify-between">
				<div class="author flex items-center">
					<span class="name text-default-text-color text-lg font-semibold">LeoJeshua</span>
					
					<span class="author-label ml-1.5 text-xs px-2 py-0.5 rounded-small text-third-text-color border border-shadow-color-1">Lv2</span>
					
				</div>
				<div class="meta-info">
					<div class="article-meta-info">
    <span class="article-date article-meta-item">
        <i class="fa-regular fa-pen-fancy"></i>&nbsp;
        <span class="desktop">2024-12-21 15:49:09</span>
        <span class="mobile">2024-12-21 15:49:09</span>
        <span class="hover-info">Created</span>
    </span>
    
        <span class="article-date article-meta-item">
            <i class="fa-regular fa-wrench"></i>&nbsp;
            <span class="desktop">2025-10-14 15:57:19</span>
            <span class="mobile">2025-10-14 15:57:19</span>
            <span class="hover-info">Updated</span>
        </span>
    

    
        <span class="article-categories article-meta-item">
            <i class="fa-regular fa-folders"></i>&nbsp;
            <ul>
                
                
                    
                        
                        <li>
                            <a href="/categories/AI/">AI</a>&nbsp;
                        </li>
                    
                    
                
                    
                        
                            <li>></li>
                        
                        <li>
                            <a href="/categories/AI/Security-in-AI/">Security in AI</a>&nbsp;
                        </li>
                    
                    
                
                    
                        
                            <li>></li>
                        
                        <li>
                            <a href="/categories/AI/Security-in-AI/DMs/">DMs</a>&nbsp;
                        </li>
                    
                    
                
            </ul>
        </span>
    
    
        <span class="article-tags article-meta-item">
            <i class="fa-regular fa-tags"></i>&nbsp;
            <ul>
                
                    <li>
                        <a href="/tags/DMs/">DMs</a>&nbsp;
                    </li>
                
                    <li>
                        | <a href="/tags/Paper-Collection/">Paper Collection</a>&nbsp;
                    </li>
                
            </ul>
        </span>
    

    
    
        <span class="article-wordcount article-meta-item">
            <i class="fa-regular fa-typewriter"></i>&nbsp;<span>13.3k Words</span>
        </span>
    
    
        <span class="article-min2read article-meta-item">
            <i class="fa-regular fa-clock"></i>&nbsp;<span>48 Mins</span>
        </span>
    
    
        <span class="article-pv article-meta-item">
            <i class="fa-regular fa-eye"></i>&nbsp;<span id="busuanzi_value_page_pv"></span>
        </span>
    
</div>

				</div>
			</div>
		</div>
		

		


		<div class="article-content markdown-body px-2 sm:px-6 md:px-8 pb-8">
			<h1 id="NeurIPS2024"><a href="#NeurIPS2024" class="headerlink" title="NeurIPS2024"></a>NeurIPS2024</h1><p>Submission Deadline: 2024.05.23</p>
<p>Official Site: </p>
<ul>
<li><a class="link"   target="_blank" rel="noopener" href="https://nips.cc/virtual/2024/papers.html?filter=titles&search=diffusion" >NeurIPS 2024 Papers<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li><a class="link"   target="_blank" rel="noopener" href="https://safegenaiworkshop.github.io/" >Safe Generative AI Workshop @ NeurIPS 2024<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><ul>
<li>openreview: <a class="link"   target="_blank" rel="noopener" href="https://openreview.net/group?id=NeurIPS.cc/2024/Workshop/SafeGenAi#tab-accept-oral" >https://openreview.net/group?id=NeurIPS.cc/2024/Workshop/SafeGenAi#tab-accept-oral<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
</ul>
</li>
</ul>
<p>Tools:</p>
<ul>
<li><a class="link"   target="_blank" rel="noopener" href="https://neurips.exa.ai/" >neurips.exa.ai<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li><a class="link"   target="_blank" rel="noopener" href="https://papers.cool/arxiv/search?highlight=1&query=attack+on+diffusion+model" >papers.cool<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
</ul>
<h2 id="Attack"><a href="#Attack" class="headerlink" title="Attack"></a>Attack</h2><h3 id="Backdoors-Attack"><a href="#Backdoors-Attack" class="headerlink" title="Backdoors Attack"></a>Backdoors Attack</h3><h4 id="BiBadDiff"><a href="#BiBadDiff" class="headerlink" title="BiBadDiff"></a>BiBadDiff</h4><p><em>From Trojan Horses to Castle Walls: Unveiling Bilateral Data Poisoning Effects in Diffusion Models</em></p>
<ul>
<li>pdf: <a class="link"   target="_blank" rel="noopener" href="https://arxiv.org/pdf/2311.02373" >https://arxiv.org/pdf/2311.02373<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li>code: <a class="link"   target="_blank" rel="noopener" href="https://github.com/OPTML-Group/BiBadDiff" >https://github.com/OPTML-Group/BiBadDiff<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li>poster: <a class="link"   target="_blank" rel="noopener" href="https://nips.cc/virtual/2024/poster/92999" >https://nips.cc/virtual/2024/poster/92999<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><blockquote>
<p>尽管最先进的扩散模型 (DM) 在图像生成方面表现出色，但对其安全性的担忧依然存在。早期的研究强调了 DM 容易受到数据中毒攻击，但这些研究对图像分类提出了比传统方法 (如 BadNets) 更严格的要求。这是因为技术需要修改扩散训练和取样程序。<br>与之前的工作不同，我们研究了类 BadNet 的数据中毒方法是否可以直接降低 DM 的生成。换句话说，如果只有训练数据集被污染 (没有操纵扩散过程) ，这将如何影响学习的 DM 的性能？在这个设置中，我们揭示了双边数据中毒效应，它不仅服务于对抗目的 (损害 DM 的功能) ，而且还提供了防御优势 (可以在针对中毒攻击的分类任务中利用这一优势进行防御)。<br>我们展示了类似 BadNet 的数据中毒攻击在 DM 中对于产生不正确的图像 (与预期的文本条件不一致) 仍然有效。与此同时，中毒的 DM 在生成的图像中表现出更高的触发比率，这种现象我们称之为 “触发放大”。然后，可以使用这种洞察力来增强中毒训练数据的检测。此外，即使在低中毒率的情况下，研究 DM 的中毒效应对于设计针对此类攻击的鲁棒图像分类器也是有价值的。<br>最后，我们通过研究 DM 固有的数据记忆倾向，在数据中毒和数据复制现象之间建立了有意义的联系。代码可于 <a class="link"   target="_blank" rel="noopener" href="https://github.com/optml-group/bibaddiff" >https://github.com/optml-group/bibaddiff<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a> 索取。</p>
</blockquote>
</li>
</ul>
<!-- ![](https://nips.cc/media/PosterPDFs/NeurIPS%202024/92999.png) -->
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20250106140414.png"
                      alt="20250106140414"
                ></p>
<h3 id="Adversarial-Attack"><a href="#Adversarial-Attack" class="headerlink" title="Adversarial Attack"></a>Adversarial Attack</h3><h4 id="PAP"><a href="#PAP" class="headerlink" title="PAP"></a>PAP</h4><p><em>Prompt-Agnostic Adversarial Perturbation for Customized Diffusion Models</em></p>
<ul>
<li>pdf: <a class="link"   target="_blank" rel="noopener" href="https://arxiv.org/pdf/2408.10571v1" >https://arxiv.org/pdf/2408.10571v1<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li>project-page: <a class="link"   target="_blank" rel="noopener" href="https://vancyland.github.io/PAP.github.io/" >https://vancyland.github.io/PAP.github.io/<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li>poster: <a class="link"   target="_blank" rel="noopener" href="https://nips.cc/virtual/2024/poster/93631" >https://nips.cc/virtual/2024/poster/93631<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><blockquote>
<p>扩散模型彻底改变了定制文本到图像的生成，允许高效地从带有文本描述的个人数据合成照片。然而，这些进步带来了风险，包括隐私泄露和未经授权的艺术品复制。<br>先前的研究主要围绕使用特定于提示的方法来生成对抗性示例以保护个人图像，但现有方法的有效性受到对不同提示的适应性限制的阻碍。<br>在本文中，我们介绍了一种用于定制扩散模型的 <strong>prompt无关的对抗扰动 (PAP) 方法</strong>。PAP 首先使用拉普拉斯近似对prompt分布进行建模，然后通过基于建模分布最大化扰动期望来产生即时不可知扰动。这种方法有效地解决了prompt不可知攻击，从而提高了防御稳定性。<br>在人脸隐私和艺术风格保护方面的大量实验表明，与现有技术相比，我们的方法具有更优越的泛化能力。</p>
</blockquote>
</li>
</ul>
<!-- ![](https://nips.cc/media/PosterPDFs/NeurIPS%202024/93631.png) -->
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20250106140739.png"
                      alt="20250106140739"
                ></p>
<h4 id="AdvAD"><a href="#AdvAD" class="headerlink" title="AdvAD"></a>AdvAD</h4><p><em>AdvAD: Exploring Non-Parametric Diffusion for Imperceptible Adversarial Attacks</em></p>
<ul>
<li>pdf: <a class="link"   target="_blank" rel="noopener" href="https://openreview.net/pdf/edd586d663019327dfd268abca5445420d0591fa.pdf" >https://openreview.net/pdf/edd586d663019327dfd268abca5445420d0591fa.pdf<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li>code: <a class="link"   target="_blank" rel="noopener" href="https://github.com/XianguiKang/AdvAD" >https://github.com/XianguiKang/AdvAD<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li>poster: <a class="link"   target="_blank" rel="noopener" href="https://nips.cc/virtual/2024/poster/93401" >https://nips.cc/virtual/2024/poster/93401<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><!-- ![](https://nips.cc/media/PosterPDFs/NeurIPS%202024/93401.png) --></li>
<li>idea: 探索非参数扩散以实现不可察觉的对抗性攻击</li>
</ul>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20250106140755.png"
                      alt="20250106140755"
                ></p>
<h3 id="MIA-Member-Inference-Attack"><a href="#MIA-Member-Inference-Attack" class="headerlink" title="MIA (Member Inference Attack)"></a>MIA (Member Inference Attack)</h3><h4 id="CLiD"><a href="#CLiD" class="headerlink" title="CLiD"></a>CLiD</h4><p><em>Membership Inference on Text-to-Image Diffusion Models via Conditional Likelihood Discrepancy</em></p>
<ul>
<li>pdf: <a class="link"   target="_blank" rel="noopener" href="https://arxiv.org/pdf/2405.14800" >https://arxiv.org/pdf/2405.14800<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li>code: <a class="link"   target="_blank" rel="noopener" href="https://github.com/zhaisf/CLiD" >https://github.com/zhaisf/CLiD<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li>poster: <a class="link"   target="_blank" rel="noopener" href="https://nips.cc/virtual/2024/poster/96064" >https://nips.cc/virtual/2024/poster/96064<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><!-- ![](https://nips.cc/media/PosterPDFs/NeurIPS%202024/96064.png) --></li>
<li>idea: 基于条件似然差异的T2I扩散模型的成员推断<blockquote>
<p>T2I扩散模型在可控图像生成领域取得了巨大的成功，同时也伴随着隐私泄露和数据版权问题。<br>在这些上下文中，成员推断作为一种潜在的审计方法，用于检测未经授权的数据使用。尽管在扩散模型方面已经做了一些努力，但由于计算开销较大和泛化能力增强，它们不适用于文本到图像的扩散模型。<br>在本文中，我们首先确定了文本到图像扩散模型中的条件过拟合现象，表明这些模型倾向于过拟合给定相应文本的图像的条件分布，而不仅仅是图像的边缘分布。在此基础上，我们推导出一个分析指标，即 <strong>条件似然差异 (CLiD)</strong> ，以执行成员推理，从而降低了估计个体样本记忆的随机性。<br>实验结果表明，该方法在不同的数据分布和数据集尺度上都明显优于以前的方法。此外，我们的方法显示出优越的抵抗过度拟合缓解策略，如早期停止和数据增强。</p>
</blockquote>
</li>
</ul>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20250106140848.png"
                      alt="20250106140848"
                ></p>
<h3 id="Watermark"><a href="#Watermark" class="headerlink" title="Watermark"></a>Watermark</h3><h4 id="ZoDiac"><a href="#ZoDiac" class="headerlink" title="ZoDiac"></a>ZoDiac</h4><p><em>Attack-Resilient Image Watermarking Using Stable Diffusion</em></p>
<ul>
<li>pdf: <a class="link"   target="_blank" rel="noopener" href="https://arxiv.org/pdf/2401.04247" >https://arxiv.org/pdf/2401.04247<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li>code: <a class="link"   target="_blank" rel="noopener" href="https://github.com/zhanglijun95/ZoDiac" >https://github.com/zhanglijun95/ZoDiac<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li>poster: <a class="link"   target="_blank" rel="noopener" href="https://nips.cc/virtual/2024/poster/94294" >https://nips.cc/virtual/2024/poster/94294<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><blockquote>
<p>图像水印对于追踪图像来源和证明所有权至关重要。随着稳定扩散等生成模型的出现，这些模型可以创建虚假但逼真的图像，水印对于确保人工创建的图像可可靠识别变得尤为重要。<br>遗憾的是，同样的稳定扩散技术可以去除使用现有方法注入的水印。<br>为了解决这个问题，我们提出了 <strong>ZoDiac</strong>，它 <strong>使用预先训练的稳定扩散模型将水印注入可训练的潜在空间，从而使水印即使在受到攻击时也能在潜在向量中被可靠地检测到</strong>。<br>我们在 MS-COCO、DiffusionDB 和 WikiArt 三个基准测试上对 ZoDiac 进行了评估，发现 ZoDiac 能够抵御最先进的水印攻击，水印检测率超过 98%，误报率低于 6.4%，优于最先进的水印方法。我们假设，扩散模型中的往复式去噪过程可能在面对强攻击时固有地增强水印的鲁棒性，并验证了这一假设。我们的研究表明，稳定扩散是一种很有前景的鲁棒水印方法，甚至能够抵御基于稳定扩散的攻击方法。</p>
</blockquote>
</li>
</ul>
<!-- ![](https://nips.cc/media/PosterPDFs/NeurIPS%202024/94294.png) -->
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20250106140912.png"
                      alt="20250106140912"
                ></p>
<h3 id="Federated-Learning"><a href="#Federated-Learning" class="headerlink" title="Federated Learning"></a>Federated Learning</h3><h4 id="DataStealing"><a href="#DataStealing" class="headerlink" title="DataStealing"></a>DataStealing</h4><p><em>DataStealing: Steal Data from Diffusion Models in Federated Learning with Multiple Trojans</em></p>
<ul>
<li>pdf: <a class="link"   target="_blank" rel="noopener" href="https://openreview.net/pdf?id=792txRlKit" >https://openreview.net/pdf?id=792txRlKit<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li>code: <a class="link"   target="_blank" rel="noopener" href="https://github.com/yuangan/DataStealing" >https://github.com/yuangan/DataStealing<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li>openreview: <a class="link"   target="_blank" rel="noopener" href="https://openreview.net/forum?id=792txRlKit" >https://openreview.net/forum?id=792txRlKit<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li>poster: <a class="link"   target="_blank" rel="noopener" href="https://nips.cc/virtual/2024/poster/96480" >https://nips.cc/virtual/2024/poster/96480<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><blockquote>
<p>联邦学习（FL）通常用于协同训练具有隐私保护的模型。<br>在本文中，我们发现<strong>流行的扩散模型为 FL 引入了新的漏洞</strong>，这带来了严重的隐私威胁。尽管采取了严格的数据管理措施，攻击者仍然可以 <strong>通过多个木马从本地客户端窃取大量隐私数据，这些木马通过多个触发器控制生成行为。</strong> 我们将这项新任务称为 <strong>DataStealing</strong>，并证明攻击者可以基于我们在原始 FL 系统中提出的组合触发器（ComboT）实现目的。<br>然而，基于距离的高级 FL 防御仍然能够根据每个本地更新之间的距离有效地过滤恶意更新。因此，我们提出了一种自适应尺度关键参数（AdaSCP）攻击来绕过防御并将恶意更新无缝地合并到全局模型中。具体而言，AdaSCP 使用扩散模型主要时间步中的梯度来评估参数的重要性。随后，它会自适应地寻求最佳比例因子并在将关键参数更新上传到服务器之前将其放大。因此，恶意更新变得与良性更新相似，使得基于距离的防御难以识别。<br>大量实验表明，使用 FL 训练扩散模型存在泄露数千张图像的风险。此外，这些实验证明了 AdaSCP 在击败高级基于距离的防御方面的有效性。我们希望这项工作能够引起 FL 社区对扩散模型关键隐私安全问题的更多关注。</p>
</blockquote>
</li>
</ul>
<!-- ![](https://nips.cc/media/PosterPDFs/NeurIPS%202024/96480.png) -->
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20250106140956.png"
                      alt="20250106140956"
                ></p>
<h2 id="Defence"><a href="#Defence" class="headerlink" title="Defence"></a>Defence</h2><h3 id="Anti-Adversarial-Prompt"><a href="#Anti-Adversarial-Prompt" class="headerlink" title="Anti-Adversarial Prompt"></a>Anti-Adversarial Prompt</h3><h4 id="GuardT2I"><a href="#GuardT2I" class="headerlink" title="GuardT2I"></a>GuardT2I</h4><p><em>GuardT2I: Defending Text-to-Image Models from Adversarial Prompts</em></p>
<ul>
<li>pdf: <a class="link"   target="_blank" rel="noopener" href="https://arxiv.org/pdf/2403.01446" >https://arxiv.org/pdf/2403.01446<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li>code: <a class="link"   target="_blank" rel="noopener" href="https://github.com/cure-lab/GuardT2I" >https://github.com/cure-lab/GuardT2I<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li>model: <a class="link"   target="_blank" rel="noopener" href="https://huggingface.co/YijunYang280/GuardT2I/" >https://huggingface.co/YijunYang280/GuardT2I/<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li>poster: <a class="link"   target="_blank" rel="noopener" href="https://nips.cc/virtual/2024/poster/95982" >https://nips.cc/virtual/2024/poster/95982<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><blockquote>
<p>尽管现有的对策如NSFW分类器或模型微调以<strong>去除不适当的概念</strong>，但T2I模型的最新进展已经引起了人们对其可能被滥用以产生不适当或不适合工作的内容的重大安全担忧。<br>为了应对这一挑战，我们的研究揭示了 <strong>GuardT2I</strong>，这是一个新的调节框架，采用生成方法来 <strong>增强T2I模型对对抗性提示的鲁棒性</strong>。<br>GuardT2I 没有进行二元分类，而是<strong>利用大型语言模型有条件地将T2I模型中的 文本引导embedding 转换为 自然语言</strong>，以实现有效的对对性提示检测，同时不影响模型的固有性能。<br>我们广泛的实验表明，GuardT2I在不同的对抗场景中表现优于领先的商业解决方案，如OpenAI-Moderation和Microsoft Azure Moderator。</p>
</blockquote>
</li>
</ul>
<!-- ![](https://nips.cc/media/PosterPDFs/NeurIPS%202024/95982.png) -->
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20250106141013.png"
                      alt="20250106141013"
                ></p>
<ul>
<li>Stage1: LLM Generation. <ul>
<li>借助 <code>c·LLM</code> ，将T2I模型中的text guidance embedding转换为natural language ( <code>Prompt Interpretation</code> )</li>
<li>将该任务视为一个条件生成任务</li>
<li>合并cross-attention modules 到 pre-trained LLMs，得到一个conditional LLM ( <code>c·LLM</code> )</li>
</ul>
</li>
<li>Stage2: Generation Parsing. 对 <code>Prompt Interpretation</code> 进行双层分析：<ul>
<li><strong>Verbalizer</strong> 检测 <code>Prompt Interpretation</code> 中是否含有NSFW词汇 (简单直接)。<ul>
<li>NSFW词汇是开发者 predefine 的，文中使用了25个常见的NSFW词汇。</li>
</ul>
</li>
<li><strong>Sentence Similarity Checker</strong> 检测生成的 <code>Prompt Interpretation</code> 与 <code>initial prompt</code> 之间的相似度，如果相似度低于某个阈值，则判定是 <strong>潜在恶意(potential malicious)</strong> 的。<ul>
<li>使用了现有的sentence similarity model -&gt; <code>SentenceBERT</code></li>
</ul>
</li>
</ul>
</li>
<li>Decision &amp; Reason:<ul>
<li>根据stage2的结果综合判断，来做出是否reject的决定（中止T2I的推理过程）</li>
<li>GuardT2I于T2I是并行运行的，所以没有额外的性能损失。（只要GuardT2I的运行速度大于T2I的推理速度）<ul>
<li>比Safety Checker快300倍</li>
<li>对模型原有的生成性能影响很小</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>实验部分，也对MMA-Diffusion做了针对性改进，以测试GuardT2I的面对Adaptive Attacks时的能力。</p>
<h3 id="Unlearn"><a href="#Unlearn" class="headerlink" title="Unlearn"></a>Unlearn</h3><h4 id="AdvUnlearn"><a href="#AdvUnlearn" class="headerlink" title="AdvUnlearn"></a>AdvUnlearn</h4><p><em>Defensive Unlearning with Adversarial Training for Robust Concept Erasure in Diffusion Models</em></p>
<ul>
<li>idea: 对抗性训练 + Unlearning</li>
<li>pdf: <a class="link"   target="_blank" rel="noopener" href="https://arxiv.org/pdf/2405.15234" >https://arxiv.org/pdf/2405.15234<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li>code: <a class="link"   target="_blank" rel="noopener" href="https://github.com/OPTML-Group/AdvUnlearn" >https://github.com/OPTML-Group/AdvUnlearn<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li>demo: <a class="link"   target="_blank" rel="noopener" href="https://huggingface.co/spaces/Intel/AdvUnlearn" >https://huggingface.co/spaces/Intel/AdvUnlearn<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li>Unlearned DM Benchmark: <a class="link"   target="_blank" rel="noopener" href="https://huggingface.co/spaces/Intel/UnlearnDiffAtk-Benchmark" >https://huggingface.co/spaces/Intel/UnlearnDiffAtk-Benchmark<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li>HF Model: <a class="link"   target="_blank" rel="noopener" href="https://huggingface.co/OPTML-Group/AdvUnlearn" >https://huggingface.co/OPTML-Group/AdvUnlearn<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li>poster: <a class="link"   target="_blank" rel="noopener" href="https://nips.cc/virtual/2024/poster/94320" >https://nips.cc/virtual/2024/poster/94320<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><blockquote>
<p>扩散模型 (DM) 在文本转图像生成方面取得了显著成功，但也存在安全风险，例如可能生成有害内容和侵犯版权。<br>Machine Unlearning（也称为概念擦除）技术已被开发用于应对这些风险。然而，这些技术仍然容易受到对抗性提示攻击，这种攻击可能导致机器学习模型在完成机器学习后重新生成包含本应擦除的概念（例如裸体）的不良图像。<br>本研究旨在通过将 <strong>对抗性训练 (AT) 的原理</strong> 融入Machine Unlearn，增强概念擦除的鲁棒性，从而 <strong>构建了称为 AdvUnlearn 的鲁棒机器学习框架</strong>。<br>然而，有效且高效地实现这一目标并非易事。首先，我们发现直接实施对抗性训练 (AT) 会损害机器学习模型在完成机器学习后的图像生成质量。为了解决这个问题，我们在一个额外的保留集上开发了一个效用保留正则化，以优化 AdvUnlearn 中概念擦除鲁棒性和模型效用之间的权衡。此外，我们认为文本编码器比 UNet 更适合进行鲁棒化，从而确保了去学习的有效性。并且，所获得的文本编码器可以作为各种数据挖掘类型的即插即用型鲁棒去学习器。<br>从实证角度来看，我们进行了大量实验，以证明 AdvUnlearn 在各种数据挖掘去学习场景中的鲁棒性优势，包括裸体、物体和风格概念的擦除。除了鲁棒性之外，AdvUnlearn 还在模型效用之间实现了平衡。<br>据我们所知，这是<strong>第一篇系统地探索通过 AT 进行鲁棒数据挖掘unlearn的研究</strong>，使其有别于现有那些忽视概念擦除鲁棒性的方法。代码可在 <a class="link"   target="_blank" rel="noopener" href="https://github.com/OPTML-Group/AdvUnlearn" >https://github.com/OPTML-Group/AdvUnlearn<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a> 获取。警告：本文包含的模型输出可能具有冒犯性。</p>
</blockquote>
</li>
</ul>
<!-- ![](https://nips.cc/media/PosterPDFs/NeurIPS%202024/94320.png) -->
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20250106141035.png"
                      alt="20250106141035"
                ></p>
<h4 id="Leveraging-Catastrophic-Forgetting"><a href="#Leveraging-Catastrophic-Forgetting" class="headerlink" title="Leveraging Catastrophic Forgetting"></a>Leveraging Catastrophic Forgetting</h4><p><em>Leveraging Catastrophic Forgetting to Develop Safe Diffusion Models against Malicious Finetuning</em></p>
<ul>
<li>pdf: <a class="link"   target="_blank" rel="noopener" href="https://openreview.net/pdf?id=pR37AmwbOt" >https://openreview.net/pdf?id=pR37AmwbOt<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li>openreview: <a class="link"   target="_blank" rel="noopener" href="https://openreview.net/forum?id=pR37AmwbOt" >https://openreview.net/forum?id=pR37AmwbOt<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li>poster: <a class="link"   target="_blank" rel="noopener" href="https://nips.cc/virtual/2024/poster/93554" >https://nips.cc/virtual/2024/poster/93554<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li>idea: 利用灾难性遗忘开发安全扩散模型以抵御恶意微调<blockquote>
<p>扩散模型 (DM) 在基于文本提示的图像生成方面表现出显著的能力。人们提出了许多方法来确保这些模型生成安全的图像。<br>早期的方法试图将安全过滤器纳入模型，以减少产生有害图像的风险，但这种外部过滤器本身并不能解除模型的毒性，可以很容易地绕过。因此，考虑到 <strong>模型Unlearn</strong> 和 <strong>数据清洗</strong> 对模型参数的影响，它们是维护模型安全的最基本的方法。然而，即使使用这些方法，恶意的微调仍然会使模型倾向于生成有害或不良的图像。<br>受<strong>灾难性遗忘现象</strong>的启发，我们提出了一种使用 <strong>对比学习</strong> 的训练策略，以 <strong>增加清洁和有害数据分布之间的潜在空间距离，从而保护模型不被微调以生成由于遗忘引起的有害图像。</strong><br>实验结果表明，我们的方法不仅在恶意微调之前保持了清晰的图像生成能力，而且<strong>在恶意微调之后有效地防止了 DM 产生有害的图像。</strong> 我们的方法还可以与其他安全方法相结合，以进一步保持其安全性，防止恶意微调。</p>
</blockquote>
</li>
</ul>
<!-- ![](https://nips.cc/media/PosterPDFs/NeurIPS%202024/93554.png) -->
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20250110161946.png"
                      alt="20250110161946"
                ></p>
<h3 id="Memory-Editing"><a href="#Memory-Editing" class="headerlink" title="Memory Editing"></a>Memory Editing</h3><p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/%E5%9B%BE%E7%89%871.png"
                      alt="图片1"
                ></p>
<h4 id="Finding-NeMo"><a href="#Finding-NeMo" class="headerlink" title="Finding NeMo"></a>Finding NeMo</h4><p><em>Finding NeMo: Localizing Neurons Responsible For Memorization in Diffusion Models</em></p>
<ul>
<li>pdf: <a class="link"   target="_blank" rel="noopener" href="https://arxiv.org/pdf/2406.02366" >https://arxiv.org/pdf/2406.02366<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li>project page: <a class="link"   target="_blank" rel="noopener" href="https://ml-research.github.io/localizing_memorization_in_diffusion_models/" >https://ml-research.github.io/localizing_memorization_in_diffusion_models/<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li>code: <a class="link"   target="_blank" rel="noopener" href="https://github.com/ml-research/localizing_memorization_in_diffusion_models" >https://github.com/ml-research/localizing_memorization_in_diffusion_models<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li>poster: <a class="link"   target="_blank" rel="noopener" href="https://nips.cc/virtual/2024/poster/94713" >https://nips.cc/virtual/2024/poster/94713<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><blockquote>
<p>扩散模型（DMs）产生非常详细和高质量的图像。他们的能力来自于对大量数据的广泛训练——这些数据通常是从互联网上抓取的，没有适当的归属或内容创作者的同意。不幸的是，这种做法引起了隐私和知识产权问题，因为DMs可以记住并在推理时再现其潜在的敏感或受版权保护的训练图像。<br>之前的努力通过改变扩散过程的输入来防止这个问题，从而防止DM在推理过程中生成记忆的样本，或者从训练中完全删除记忆的数据。虽然当DMs被开发和部署在一个安全且持续监控的环境中时，这些解决方案是可行的，但它们存在攻击者规避保护措施的风险，并且当DMs本身被公开发布时，这些解决方案是无效的。<br>为了解决这个问题，我们引入了 <strong>NeMo</strong>，这是 <strong>第一种将单个数据样本的记忆定位到DMs的交叉注意层神经元水平的方法。</strong><br>通过我们的实验，我们发现在许多情况下，单个神经元负责记忆特定的训练样本。<strong>通过停用这些记忆神经元，我们可以避免在推理时重复训练数据，增加生成输出的多样性，并减轻私有和版权数据的泄漏。</strong> 通过这种方式，我们的NEMO有助于更负责任的部署DMs。</p>
</blockquote>
</li>
</ul>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://nips.cc/media/PosterPDFs/NeurIPS%202024/94713.png"
                     
                ></p>
<ul>
<li>Privacy&#x2F;Copyright issue</li>
<li><strong>Data-Sample-Level Memory</strong></li>
<li>2 kind of Memory: <ul>
<li>Verbatim Memory(VM)：逐字记忆，神经元记忆整个训练样本。</li>
<li>Template Memory(TM)：模板记忆，神经元记忆训练样本的主体构成。</li>
</ul>
</li>
<li>基于：MIA的启发，扩散模型对记忆样本和非记忆样本的相应不同。<ul>
<li>对于记忆的样本，模型预测的initial nosie(根据$X_T$预测的$X_{T-1}$)趋向一致，与seed无关。 &#x3D;&gt; 即预测噪声之于seed的分布是一致且平缓的。</li>
<li>对于非记忆的样本，模型预测的initial nosie更加多样，分布更加陡峭。</li>
</ul>
</li>
<li>方法：随机停用（先随机停用layer筛选出可能的layer，然后对可能的layer随机停用神经元，筛选出可能的memory neuron）</li>
<li>most training data samples are memorized by just <strong>a few or even a single neuron</strong>.</li>
</ul>
<h4 id="P-ESD-P-AC-SGAW-Wrokshop"><a href="#P-ESD-P-AC-SGAW-Wrokshop" class="headerlink" title="P-ESD&#x2F;P-AC [SGAW Wrokshop]"></a>P-ESD&#x2F;P-AC [SGAW Wrokshop]</h4><p><em>Pruning for Robust Concept Erasing in Diffusion Models</em></p>
<ul>
<li><p>pdf: <a class="link"   target="_blank" rel="noopener" href="https://openreview.net/pdf?id=jD1eWpUMOf" >https://openreview.net/pdf?id=jD1eWpUMOf<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
</li>
<li><p>poster in workshop: <a class="link"   target="_blank" rel="noopener" href="https://neurips.cc/virtual/2024/106210" >https://neurips.cc/virtual/2024/106210<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
</li>
<li><p>openreview(8-5-8): <a class="link"   target="_blank" rel="noopener" href="https://openreview.net/forum?id=jD1eWpUMOf" >https://openreview.net/forum?id=jD1eWpUMOf<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<blockquote>
<p>我们引入了一个简单而有效的 <strong>基于剪枝的概念擦除框架</strong>。<br>通过 <strong>将概念擦除和剪枝集成到一个目标中</strong> ，我们的方法有效地消除了模型中的概念知识，同时切断了可能重新激活概念相关隐藏状态的路径，确保了 <strong>对抗性提示的稳健性</strong>。<br>实验结果表明，我们的模型对对抗性攻击的抵御能力得到了显著增强。与现有的概念擦除方法相比，我们的方法在 NSFW 内容和艺术作品风格的擦除方面取得了约 30% 的提升。</p>
</blockquote>
</li>
<li><p>NSFW&#x2F;Copyright issue</p>
</li>
<li><p><strong>Concept-Level Memory</strong></p>
</li>
<li><p>Background: fine-tuning-based erasing is vulnerable to adversarial attacks !</p>
<ul>
<li>Existing erasing methods fine-tune parameters to “deactivate” such neurons to achieve removal in training data. However, these neurons might be “reactivated” when inputs are cleverly designed（对擦除概念很重要的神经元对明确设计的对抗性提示很敏 感。因此，它们可以被”重新激活”以重新生成要删除的概念。）</li>
</ul>
</li>
<li><p>Hypothesis: the generation of a specific concept is correlated with <strong>a subset of neurons in diffusion models</strong>, which we refer to as concept neurons in this paper</p>
<ul>
<li>the generation of a specific concept is correlated with a subset of neurons in diffusion models, which we refer to as <code>concept neurons</code> in this paper</li>
</ul>
</li>
<li><p>基于：神经元的激活程度与概念的生成相关。</p>
</li>
<li><p>设计了两种方法：</p>
<ul>
<li>NP-ESD （直接剪除变化最大的top1神经元；擦除效果差，干扰大）（只能说明这些是构成该concept的重要神经元，但是不能说明是区别于其他concept的关键神经元）</li>
<li>P-ESD （hard掩码优化；擦除更好，干扰更小）</li>
</ul>
</li>
</ul>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20250110160709.png"
                      alt="20250110160709"
                ></p>
<h1 id="CVPR-2025"><a href="#CVPR-2025" class="headerlink" title="CVPR 2025"></a>CVPR 2025</h1><p>Submission Deadline: 2024.11.15</p>
<p>Official Site:</p>
<ul>
<li><a class="link"   target="_blank" rel="noopener" href="https://cvpr.thecvf.com/virtual/2025/papers.html" >CVPR 2025 Papers<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
</ul>
<p>WeChat Article:</p>
<ul>
<li><a class="link"   target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/PWHZr6D4oQiZ-6c-gHA3tw" >我用Gemini处理了28篇CVPR 25文章——看看LLM怎么解读CVPR最新T2I动向<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
</ul>
<h2 id="Attack-1"><a href="#Attack-1" class="headerlink" title="Attack"></a>Attack</h2><h3 id="Adversarial-Attack-1"><a href="#Adversarial-Attack-1" class="headerlink" title="Adversarial Attack"></a>Adversarial Attack</h3><h4 id="FastProtect"><a href="#FastProtect" class="headerlink" title="FastProtect"></a>FastProtect</h4><p><em>Nearly Zero-Cost Protection Against Mimicry by Personalized Diffusion Models</em></p>
<ul>
<li>TL;DR: 针对DMs的几乎零开销的实时的图像保护方法</li>
<li><a class="link"   target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content/CVPR2025/papers/Ahn_Nearly_Zero-Cost_Protection_Against_Mimicry_by_Personalized_Diffusion_Models_CVPR_2025_paper.pdf" >pdf<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li><a class="link"   target="_blank" rel="noopener" href="https://cvpr.thecvf.com/virtual/2025/poster/33351" >poster<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li><a class="link"   target="_blank" rel="noopener" href="https://youtu.be/IV9hoKMgX1Q" >video<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><blockquote>
<p>扩散模型的最新进展彻底改变了图像生成，但也带来了滥用的风险，例如复制艺术品或生成深度伪造作品。<br>现有的图像保护方法虽然有效，但难以在保护效果(protection performance)、不可见性(invisibility)和延迟(inference time)之间取得平衡，从而限制了实际应用。<br>我们引入 <strong>扰动预训练</strong> 来降低延迟，并提出了一种 <strong>混合扰动方法</strong> ，该方法可以动态地适应输入图像，从而最大限度地减少性能下降。<br>我们新颖的训练策略 <strong>计算跨多个 VAE 特征空间的保护损失</strong> ，而推理阶段的 <strong>自适应定向保护则增强了鲁棒性和隐形性</strong>。<br>实验表明，该方法具有相当的protection performance，并且invisibility得到提升，inference time也显著缩短。</p>
</blockquote>
</li>
</ul>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20251014135435022.png"
                     
                ></p>
<h3 id="Data-Poisoning-Attack"><a href="#Data-Poisoning-Attack" class="headerlink" title="Data Poisoning Attack"></a>Data Poisoning Attack</h3><h4 id="Silent-Branding-Attack"><a href="#Silent-Branding-Attack" class="headerlink" title="Silent Branding Attack"></a>Silent Branding Attack</h4><p><em>Silent Branding Attack: Trigger-free Data Poisoning Attack on Text-to-Image Diffusion Models</em></p>
<ul>
<li>TL;DR: 一种数据投毒方法，让模型生成的图片包含 specific brand logo，并且不需要 text trigger。</li>
<li><a class="link"   target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content/CVPR2025/papers/Jang_Silent_Branding_Attack_Trigger-free_Data_Poisoning_Attack_on_Text-to-Image_Diffusion_CVPR_2025_paper.pdf" >pdf<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li><a class="link"   target="_blank" rel="noopener" href="https://cvpr.thecvf.com/virtual/2025/poster/35225" >poster<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li><a class="link"   target="_blank" rel="noopener" href="https://silent-branding.github.io/" >webpage<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><blockquote>
<p>文本到图像的扩散模型在从文本提示生成高质量内容方面取得了显著成功。然而，由于它们依赖于公开数据，并且为了进行微调而共享数据，这些模型尤其容易受到数据中毒攻击。<br>本文提出了一种名为 <strong>“静默品牌攻击”（Silent Branding Attack）</strong> 的新型数据中毒方法，它能够 <strong>操纵T2I DMs，生成包含特定品牌标识或符号的图像，而无需任何文本触发。</strong><br>我们发现，<strong>当某些视觉模式在训练数据中重复出现时，即使没有提示，模型也能学会在输出中自然地重现这些模式</strong>。利用这一特性，我们开发了一种 <strong>自动化数据中毒算法，该算法可以不显眼地将标识注入原始图像中，确保它们自然融合且不被检测到。</strong> 在此中毒数据集上训练的模型能够生成包含标识的图像，而不会降低图像质量或文本对齐。<br>我们在大规模高质量图像数据集和风格个性化数据集上，通过两种实际设置实验验证了我们的静默品牌攻击，即使没有特定的文本触发，也能获得很高的成功率。人工评估和包括徽标检测在内的定量指标表明，我们的方法可以隐秘地嵌入徽标。</p>
</blockquote>
</li>
</ul>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20251014151718634.png"
                     
                ></p>
<h3 id="MIA"><a href="#MIA" class="headerlink" title="MIA"></a>MIA</h3><h4 id="CDI-Copyrighted-Data-Identification"><a href="#CDI-Copyrighted-Data-Identification" class="headerlink" title="CDI (Copyrighted Data Identification)"></a>CDI (Copyrighted Data Identification)</h4><p><em>CDI: Copyrighted Data Identification in Diffusion Models</em></p>
<ul>
<li><a class="link"   target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content/CVPR2025/papers/Dubinski_CDI_Copyrighted_Data_Identification_in_Diffusion_Models_CVPR_2025_paper.pdf" >pdf<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li><a class="link"   target="_blank" rel="noopener" href="https://cvpr.thecvf.com/virtual/2025/poster/34687" >poster<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li><a class="link"   target="_blank" rel="noopener" href="https://youtu.be/eWr2KGhx0Tw" >video<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><blockquote>
<p>扩散模型 (DMs) 的训练得益于海量且多样化的数据集。由于这些数据通常是未经数据所有者许可从互联网上抓取的，这引发了人们对版权和知识产权保护的担忧。<br>虽然对于由 DMs 在推理时完美重建的训练样本，数据的（非法）使用很容易被检测到，但当可疑 DMs 的输出不是近似副本时，数据所有者很难验证他们的数据是否用于训练。从概念上讲，成员推断攻击 (MIA) 可以检测给定数据点是否在训练期间被使用，它是解决这一挑战的合适工具。然而，我们证明现有的 MIA 不足以在大型、最先进的 DMs 中可靠地确定单个图像的成员资格。<br>为了克服这一限制，我们提出了 <strong>CDI，一个供数据所有者识别其数据集是否用于训练给定 DMs 的框架。</strong><br>CDI 依赖于 <strong>数据集推断技术</strong>，即 CDI 并非使用来自单个数据点的成员资格信号，而是利用了这样一个事实：<strong>大多数数据所有者（例如图片库提供商、视觉媒体公司，甚至个人艺术家）都拥有包含多个公开data points的数据集，这些data points可能全部用于训练特定的 DMs 。</strong><br>通过选择性地聚合来自现有 MIAs 的信号，并使用新的人工方法提取这些数据集的特征，将其输入评分模型，并进行严格的统计测试，CDI 允许数据所有者 <strong>仅使用 70 个 data points，以超过 99% 的置信度</strong> 识别其数据是否被用于训练特定的数据挖掘模型 (DM)。因此，CDI 是数据所有者对其版权数据被非法使用进行索赔的有力工具。</p>
</blockquote>
</li>
</ul>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20251014143944627.png"
                     
                ></p>
<h3 id="Bias"><a href="#Bias" class="headerlink" title="Bias"></a>Bias</h3><h4 id="IBI-Implicit-Bias-Injection-Attacks"><a href="#IBI-Implicit-Bias-Injection-Attacks" class="headerlink" title="IBI (Implicit Bias Injection Attacks)"></a>IBI (Implicit Bias Injection Attacks)</h4><p><em>Implicit Bias Injection Attacks against Text-to-Image Diffusion Models</em></p>
<ul>
<li><a class="link"   target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content/CVPR2025/papers/Huang_Implicit_Bias_Injection_Attacks_against_Text-to-Image_Diffusion_Models_CVPR_2025_paper.pdf" >pdf<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li><a class="link"   target="_blank" rel="noopener" href="https://cvpr.thecvf.com/virtual/2025/poster/34474" >poster<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><blockquote>
<p>文本转图像扩散模型 (T2I DMs) 的普及使得人工智能生成的图像在日常生活中日益常见。然而，存在偏见的 T2I 模型可能会生成具有特定倾向的内容，从而可能影响人们的感知。故意利用这些偏见可能会向公众传递误导性信息。<br>目前对偏见的研究主要针对具有可识别视觉模式的显性偏见，例如肤色和性别。<br>本文介绍了 <strong>一种新型的隐性偏见，它缺乏显性视觉特征，但可以在不同的语义语境中以多种方式表现出来。</strong> 这种微妙且多变的特性使得这种偏见难以检测、易于传播，并且能够适应各种场景。<br>我们进一步提出了一个针对 T2I 扩散模型的 <strong>隐性偏见注入攻击框架 (IBI-Attacks)，该框架通过在提示嵌入空间中预先计算一个通用的偏见方向，并根据不同的输入自适应地调整它。</strong> 我们的攻击模块可以无缝集成到预训练的扩散模型中，即插即用，无需直接操作用户输入或重新训练模型。<br>大量实验验证了我们的方案在保留原始语义的同时，通过微妙而多样的修改引入偏差的有效性。我们的攻击在各种场景中的强大隐蔽性和可转移性进一步强调了我们的方法的重要性。</p>
</blockquote>
</li>
</ul>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20251008004029738.png"
                     
                ></p>
<h3 id="Watermarks"><a href="#Watermarks" class="headerlink" title="Watermarks"></a>Watermarks</h3><h4 id="Black-Box-Forgery-Attacks-on-Semantic-Watermarks"><a href="#Black-Box-Forgery-Attacks-on-Semantic-Watermarks" class="headerlink" title="Black-Box Forgery Attacks on Semantic Watermarks"></a>Black-Box Forgery Attacks on Semantic Watermarks</h4><p><em>Black-Box Forgery Attacks on Semantic Watermarks for Diffusion Models</em></p>
<ul>
<li>TL;DR: 黑盒条件下 伪造 语义水印</li>
<li><a class="link"   target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content/CVPR2025/papers/Muller_Black-Box_Forgery_Attacks_on_Semantic_Watermarks_for_Diffusion_Models_CVPR_2025_paper.pdf" >pdf<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li><a class="link"   target="_blank" rel="noopener" href="https://cvpr.thecvf.com/virtual/2025/poster/34820" >poster<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li><a class="link"   href="ttps://github.com/and-mill/semantic-forgery" >code<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><blockquote>
<p>将水印集成到潜在扩散模型 (LDMs) 的生成过程中，可以简化生成内容的检测和归因。<br>语义水印，例如树形年轮(Tree-Rings)和高斯阴影(Gaussian Shading)，代表了一类新颖的水印技术，易于实现，并且对各种扰动具有高度的鲁棒性。<br>然而，我们的工作揭示了 <strong>语义水印的一个根本安全漏洞</strong> 。我们表明，<strong>攻击者可以利用不相关的模型，即使使用不同的潜在空间和架构（UNet 与 DiT），也能执行强大且逼真的伪造攻击</strong>。<br>具体来说，我们设计了 <strong>两种水印伪造攻击</strong> 。第一种攻击通过 <strong>在不相关的 LDMs 中操纵任意图像的潜在表示，使其更接近带水印图像的潜在表示(Imprint-F)</strong> ，从而将目标水印嵌入真实图像中。我们还表明，该技术可用于去除水印(Imprint-R)。第二种攻击通过 **反转带水印图像并使用任意提示重新生成它，来生成带有目标水印的新图像(Reprompt)**。<br>两种攻击都只需要一张带有目标水印的参考图像。总而言之，我们的研究结果质疑了语义水印的适用性，因为攻击者在现实条件下很容易伪造或移除这些水印。</p>
</blockquote>
</li>
</ul>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20251014144622223.png"
                     
                ></p>
<h2 id="Defence-1"><a href="#Defence-1" class="headerlink" title="Defence"></a>Defence</h2><h3 id="Guidence"><a href="#Guidence" class="headerlink" title="Guidence"></a>Guidence</h3><h4 id="DAG-Detect-and-Guide"><a href="#DAG-Detect-and-Guide" class="headerlink" title="DAG (Detect-and-Guide)"></a>DAG (Detect-and-Guide)</h4><p><em>Detect-and-Guide: Self-regulation of Diffusion Models for Safe Text-to-Image Generation</em></p>
<ul>
<li><a class="link"   target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content/CVPR2025/papers/Li_Detect-and-Guide_Self-regulation_of_Diffusion_Models_for_Safe_Text-to-Image_Generation_via_CVPR_2025_paper.pdf" >pdf<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li><a class="link"   target="_blank" rel="noopener" href="https://cvpr.thecvf.com/virtual/2025/poster/32690" >poster<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><blockquote>
<p>文本到图像的扩散模型在合成任务中取得了最先进的结果； 然而，人们越来越担心它们可能被滥用来创建有害内容。为了减轻这些风险，人们开发了事后模型干预技术，例如概念遗忘和安全指导。<br>然而，微调模型权重或调整扩散模型的隐藏状态以一种不可解释的方式进行，使得不清楚中间变量的哪一部分负责不安全的生成。当从复杂的多概念提示中删除有害概念时，这些干预措施会严重影响采样轨迹，从而阻碍了它们在现实世界中的实际使用。尽管它们在单一概念提示上有效，但当前的方法仍然面临着挑战，因为它们很难在不破坏良性概念语义的情况下精确删除有害概念。<br>在这项工作中，我们提出了 <strong>检测和引导（DAG）</strong> 安全生成框架， <strong>利用扩散模型的内部知识在采样过程中进行自我诊断和细粒度的自我调节。</strong><br>DAG首先使用优化标记的细化交叉注意力图从噪声潜伏中检测有害概念，然后应用具有自适应强度和编辑区域的安全引导来否定不安全生成。优化只需要小型注释数据集，可以提供具有普遍性和概念特异性的精确检测图。 此外，<strong>DAG不需要对扩散模型进行微调</strong>，因此不会对其生成多样性造成损失。<br>擦除色情内容的实验表明，DAG 实现了最先进的安全生成性能，在多概念现实世界提示上平衡了危害缓解和文本跟踪性能。</p>
</blockquote>
</li>
</ul>
<h4 id="Concept-Replacer"><a href="#Concept-Replacer" class="headerlink" title="Concept Replacer"></a>Concept Replacer</h4><p>Concept Replacer: Replacing Sensitive Concepts in Diffusion Models via Precision Localization</p>
<ul>
<li><a class="link"   target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_Concept_Replacer_Replacing_Sensitive_Concepts_in_Diffusion_Models_via_Precision_CVPR_2025_paper.pdf" >pdf<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li><a class="link"   target="_blank" rel="noopener" href="https://cvpr.thecvf.com/virtual/2025/poster/33513" >poster<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><blockquote>
<p>随着大规模扩散模型的不断发展，它们在生成高质量图像方面表现出色，但同时也常常会生成一些不受欢迎的内容，例如色情或暴力内容。<br>现有的概念移除方法通常会引导图像生成过程，但可能会无意中修改不相关的区域，从而导致与原始模型不一致。<br>我们提出了一种新的扩散模型中的<strong>目标概念替换方法</strong>，能够在不影响非目标区域的情况下移除特定概念。<br>我们的方法引入了 <strong>一个专用的概念定位器，用于在去噪过程中精确识别目标概念</strong> ，该定位器采用少样本学习进行训练，只需要极少的标记数据。在已识别的区域内，我们引入了一个无需训练的 <strong>双提示交叉注意力 (DPCA) 模块</strong> 来替换目标概念，确保对周围内容的干扰最小。<br>我们对我们的方法进行了 <strong>概念定位精度</strong> 和 <strong>替换效率</strong> 的评估。实验结果表明，我们的方法在目标概念定位方面取得了卓越的精度，并在对非目标区域影响最小的情况下进行了连贯的概念替换，优于现有方法。</p>
</blockquote>
</li>
</ul>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20251014133757225.png"
                     
                ></p>
<h3 id="Unlern"><a href="#Unlern" class="headerlink" title="Unlern"></a>Unlern</h3><h4 id="EraseDiff"><a href="#EraseDiff" class="headerlink" title="EraseDiff"></a>EraseDiff</h4><p><em>Erasing Undesirable Influence in Diffusion Models</em></p>
<ul>
<li><a class="link"   target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content/CVPR2025/papers/Wu_Erasing_Undesirable_Influence_in_Diffusion_Models_CVPR_2025_paper.pdf" >pdf<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li><a class="link"   target="_blank" rel="noopener" href="https://cvpr.thecvf.com/virtual/2025/poster/33939" >poster<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><blockquote>
<p>扩散模型在生成高质量图像方面非常有效，但也存在风险，例如无意中生成 NSFW（不适合工作）内容。<br>尽管已经提出了各种技术来减轻扩散模型中的不良影响，同时保持整体性能，但在这些目标之间取得平衡仍然具有挑战性。<br>在这项工作中，我们引入了 EraseDiff，这是一种旨在 <strong>保留扩散模型对保留数据的效用，同时删除与要遗忘的数据相关的不需要的信息的算法。</strong><br>我们的方法使用值函数将此任务表述为约束优化问题，从而产生用于解决优化问题的自然一阶算法。通过改变生成过程以偏离地面实况去噪轨迹，我们更新保存参数，同时控制约束减少以确保有效擦除，从而达到最佳权衡。<br>大量的实验和与最先进算法的彻底比较表明，EraseDiff 有效地保持了模型的效用、功效和效率。</p>
</blockquote>
</li>
</ul>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20251008005106312.png"
                     
                ></p>
<h4 id="Localized-Concept-Erasure-GLoCE"><a href="#Localized-Concept-Erasure-GLoCE" class="headerlink" title="Localized Concept Erasure (GLoCE)"></a>Localized Concept Erasure (GLoCE)</h4><p><em>Localized Concept Erasure for Text-to-Image Diffusion Models Using Training-Free Gated Low-Rank Adaptation</em></p>
<ul>
<li><a class="link"   target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content/CVPR2025/papers/Lee_Localized_Concept_Erasure_for_Text-to-Image_Diffusion_Models_Using_Training-Free_Gated_CVPR_2025_paper.pdf" >pdf<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li><a class="link"   target="_blank" rel="noopener" href="https://cvpr.thecvf.com/virtual/2025/poster/34742" >poster<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><blockquote>
<p>基于微调的概念擦除已显示出良好的效果，它通过移除目标概念并保留剩余概念，防止文本到图像的扩散模型生成有害内容。为了在概念擦除后保持扩散模型的生成能力，需要仅移除图像中局部出现的目标概念所在的图像区域，而保留其他区域。<br>然而，现有技术通常会为了擦除出现在特定区域的局部目标概念而牺牲其他图像区域的保真度，从而降低图像生成的整体性能。<br>为了解决这些限制，我们首先引入了一个称为 <strong>Localized Concept Erasure</strong> 的框架，<strong>该框架允许仅删除图像中包含目标概念的特定区域，同时保留其他区域</strong>。<br>作为局部概念擦除的解决方案，我们提出了一种 <strong>training-free</strong> 的方法，称为 <strong>Gated Low-rank adaptation for Concept Erasure (GLoCE)</strong> ，该方法在扩散模型中注入了一个轻量级模块。GLoCE 由低秩矩阵和一个简单的门组成，仅由几个无需训练的概念生成步骤决定。通过将 GLoCE 直接应用于图像嵌入，并设计仅针对目标概念激活的门控，GLoCE 可以选择性地仅移除目标概念的区域，即使目标概念和剩余概念共存于图像中。<br>大量实验表明，GLoCE 不仅在擦除局部目标概念后提高了图像与文本提示的保真度，而且在有效性、特异性和稳健性方面也大幅超越现有技术，并且可以扩展到大规模概念擦除。</p>
</blockquote>
</li>
</ul>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20251013153220944.png"
                     
                ></p>
<h4 id="ACE-Anti-editing-Concept-Erasure"><a href="#ACE-Anti-editing-Concept-Erasure" class="headerlink" title="ACE (Anti-editing Concept Erasure)"></a>ACE (Anti-editing Concept Erasure)</h4><p><em>ACE: Anti-Editing Concept Erasure in Text-to-Image Models</em></p>
<ul>
<li><a class="link"   target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_ACE_Anti-Editing_Concept_Erasure_in_Text-to-Image_Models_CVPR_2025_paper.pdf" >pdf<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li><a class="link"   target="_blank" rel="noopener" href="https://cvpr.thecvf.com/virtual/2025/poster/33574" >poster<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li><a class="link"   target="_blank" rel="noopener" href="https://github.com/120L020904/ACE" >github<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><blockquote>
<p>文本到图像传播模型的最新进展极大地促进了高质量图像的生成，但也引发了人们对非法创建有害内容（例如受版权保护的图像）的担忧。<br>现有的概念擦除方法在防止提示中产生被擦除的概念方面取得了优异的效果，但在防止不必要的编辑方面通常表现不佳。<br>为了解决这个问题，我们提出了 <strong>一种 Anti-editing 的 Concept Erasure (ACE) 方法，它不仅在生成过程中擦除目标概念，还在编辑过程中将其过滤掉。</strong><br>具体而言，我们建议 <strong>在条件和非条件噪声预测中注入擦除指导</strong> ，使模型能够有效地防止在编辑和生成过程中产生擦除概念。此外， <strong>在训练过程中引入随机校正指导</strong> ，以解决无关概念的擦除问题。<br>我们使用代表性编辑方法（例如 <code>LEDITS++</code> 和 <code>MasaCtrl</code>）进行了擦除编辑实验，以擦除 IP 字符，结果表明，我们的 ACE 能够有效地在两种编辑类型中过滤掉目标概念。进一步的实验（删除显性概念和艺术风格）进一步证明了我们的 ACE 比最先进的方法表现更佳。我们的代码将公开发布。</p>
</blockquote>
</li>
</ul>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20251013153539968.png"
                     
                ></p>
<h4 id="STEREO-Search-Thoroughly-Enough-Robustly-Erase-Once"><a href="#STEREO-Search-Thoroughly-Enough-Robustly-Erase-Once" class="headerlink" title="STEREO (Search Thoroughly Enough, Robustly Erase Once)"></a>STEREO (Search Thoroughly Enough, Robustly Erase Once)</h4><p><em>STEREO: A Two-Stage Framework for Adversarially Robust Concept Erasing from Text-to-Image Diffusion Models</em> <code>Highlight</code></p>
<ul>
<li><a class="link"   target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content/CVPR2025/papers/Srivatsan_STEREO_A_Two-Stage_Framework_for_Adversarially_Robust_Concept_Erasing_from_CVPR_2025_paper.pdf" >pdf<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li><a class="link"   target="_blank" rel="noopener" href="https://cvpr.thecvf.com/virtual/2025/poster/32792" >poster<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><blockquote>
<p>大规模文本转图像扩散 (T2ID) 模型的快速普及引发了人们对其可能被滥用生成有害内容的严重担忧。尽管已经提出了许多从 T2ID 模型中擦除不良概念的方法，但它们常常会给人一种虚假的安全感，因为概念擦除模型 (CEM) 很容易被对抗性攻击欺骗，从而生成被擦除的概念。<br>尽管最近出现了一些 <strong>基于对抗性训练的鲁棒概念擦除方法</strong>，但它们为了获得鲁棒性，会牺牲实用性（良性概念的生成质量），并且&#x2F;或者仍然容易受到高级嵌入空间攻击。这些局限性源于鲁棒 CEM 未能彻底搜索嵌入空间中的“盲点(blind spots)”。<br>为了弥补这一缺陷，我们提出了 <strong>STEREO，这是一个新颖的两阶段框架</strong>，它将对抗性训练作为鲁棒概念擦除的第一步，而非唯一步骤。<br>在第一阶段，<strong>Search Thoroughly Enough (STE)：使用对抗性训练作为漏洞识别机制</strong>，以进行足够彻底的搜索；在第二阶段，<strong>Robustly Erase Once (REO)：引入了一个基于锚点概念的(anchor-concept-based)组合目标，以鲁棒的方式一次性擦除目标概念，同时尽量减少模型效用的下降。</strong><br>我们将 STEREO 与 7 种最先进的概念擦除方法进行了对比，证明了其在抵御白盒、黑盒和高级嵌入空间攻击方面具有增强的鲁棒性，并且能够在很大程度上保留效用。</p>
</blockquote>
</li>
</ul>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20251013162042504.png"
                     
                ></p>
<h4 id="RIIDL-Responsible-Interpretable-Intermediate-Diffusion-Latents"><a href="#RIIDL-Responsible-Interpretable-Intermediate-Diffusion-Latents" class="headerlink" title="RIIDL (Responsible Interpretable Intermediate Diffusion Latents)"></a>RIIDL (Responsible Interpretable Intermediate Diffusion Latents)</h4><p><em>Plug-and-Play Interpretable Responsible Text-to-Image Generation via Dual-Space Multi-facet Concept Control</em></p>
<ul>
<li><a class="link"   target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content/CVPR2025/papers/Azam_Plug-and-Play_Interpretable_Responsible_Text-to-Image_Generation_via_Dual-Space_Multi-facet_Concept_Control_CVPR_2025_paper.pdf" >pdf<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li><a class="link"   target="_blank" rel="noopener" href="https://cvpr.thecvf.com/virtual/2025/poster/33451" >poster<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li><a class="link"   target="_blank" rel="noopener" href="https://basim-azam.github.io/responsiblediffusion/" >webpage<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><blockquote>
<p>围绕文本转图像 (T2I) 模型的伦理问题要求对生成内容进行全面控制。现有的针对负责任的 T2I 模型的这些问题的技术旨在使生成的内容公平安全（非暴力&#x2F;明确）。然而，这些方法仍然局限于单独处理责任概念的各个方面，同时也缺乏可解释性。此外，它们通常需要修改原始模型，这会影响模型性能。<br>在本文中，我们提出了一种独特的技术，通过同时考虑广泛的概念来实现负责任的 T2I 生成，并且以可扩展的方式实现公平安全的内容生成。关键思想是 使用 <strong>外部的即插即用(plug-and-play)机制</strong> 蒸馏 target T2I pipeline ，该机制根据 target T2I pipeline 学习 the desired concepts 的 <strong>可解释的合成的责任空间(an interpretable composite responsible space)。</strong><br>我们使用 <strong>知识蒸馏(knowledge distillation) 和 概念白化(concept whitening)</strong> 来实现这一点。在推理时，学习到的空间用于调节生成内容。典型的 T2I 管道为我们的方法提供了两个插件点，即：<strong>文本嵌入空间</strong> 和 <strong>扩散模型潜在空间</strong>。<br>我们针对这两个方面开发了模块，并通过一系列强大的结果证明了我们方法的有效性。我们的代码和模型将在论文被接受后公开。</p>
</blockquote>
</li>
</ul>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20251013161422499.png"
                     
                ></p>
<h4 id="AdaVD-Adaptive-Vaule-Decomposer"><a href="#AdaVD-Adaptive-Vaule-Decomposer" class="headerlink" title="AdaVD (Adaptive Vaule Decomposer)"></a>AdaVD (Adaptive Vaule Decomposer)</h4><p><em>Precise, Fast, and Low-cost Concept Erasure in Value Space: Orthogonal Complement Matters</em></p>
<ul>
<li><a class="link"   target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Precise_Fast_and_Low-cost_Concept_Erasure_in_Value_Space__CVPR_2025_paper.pdf" >pdf<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li><a class="link"   target="_blank" rel="noopener" href="https://cvpr.thecvf.com/virtual/2025/poster/34263" >poster<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><blockquote>
<p>扩散模型成功实现了文本到图像的生成，这迫切需要以精确、及时且低成本的方式从预训练模型中擦除不需要的概念，例如版权、冒犯性和不安全的概念。概念擦除的双重需求要求在生成过程中精确删除目标概念（即erasure efficacy），同时对非目标内容生成的影响最小（即prior preservation）。<br>现有方法要么计算成本高昂，要么在维持擦除效率和先验保留之间的有效平衡方面面临挑战。<br>为了改进，我们提出了 <strong>一种精确、快速且低成本的概念擦除方法，称为 Adaptive Vaule Decomposer (AdaVD, 自适应的Value分解器)，它无需训练。</strong><br>该方法基于经典的 <strong>线性代数正交补运算，在扩散模型UNet中每个交叉注意层的值空间中实现。</strong> 设计了<strong>一种有效的移位因子，用于自适应地控制擦除强度，在不牺牲擦除效率的情况下增强先验保留。</strong><br>大量实验结果表明，所提出的 AdaVD 在单概念和多概念擦除方面均有效，与第二佳方法相比，先验保存率提高了 2 到 10 倍，同时，与基于训练和无需训练的现有技术相比，均达到了最佳或接近最佳的擦除效率。AdaVD 支持一系列扩散模型和下游图像生成任务，其代码即将公开。</p>
</blockquote>
</li>
</ul>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20251013163517981.png"
                     
                ></p>
<h4 id="FADE-Fine-grained-Attenuation-for-Diffusion-Erasure"><a href="#FADE-Fine-grained-Attenuation-for-Diffusion-Erasure" class="headerlink" title="FADE (Fine-grained Attenuation for Diffusion Erasure)"></a>FADE (Fine-grained Attenuation for Diffusion Erasure)</h4><p><em>Fine-Grained Erasure in Text-to-Image Diffusion-based Foundation Models</em></p>
<ul>
<li>TL;DR: 减少概念擦除时 对 邻接&#x2F;相关概念 的影响</li>
<li><a class="link"   target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content/CVPR2025/papers/Thakral_Fine-Grained_Erasure_in_Text-to-Image_Diffusion-based_Foundation_Models_CVPR_2025_paper.pdf" >pdf<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li><a class="link"   target="_blank" rel="noopener" href="https://cvpr.thecvf.com/virtual/2025/poster/33583" >poster<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><blockquote>
<p>现有的文本转图像生成模型中的去学习算法在移除特定目标概念时，往往无法保留语义相关概念的知识——这一挑战被称为 <strong>adjacency(邻接)</strong> 。<br>为了解决这个问题，我们提出了<strong>FADE（Fine-grained Attenuation for Diffusion Erasure，细粒度衰减扩散擦除）</strong>，在扩散模型中引入了 <strong>adjacency-aware unlearning</strong> 。<br>FADE 包含两个组件：**(1) Concept Lattice（概念格）<strong>，用于识别相关概念的邻接集；</strong>(2) Mesh Modules（网格模块）**，采用结构化的擦除、邻接和引导损失组件组合。这些组件能够 <strong>精确擦除目标概念，同时保持相关和不相关概念之间的保真度。</strong><br>通过在 Stanford Dogs、Oxford Flowers、CUB、I2P、Imagenette 和 ImageNet-1k 等数据集上进行评估，FADE 有效地删除了目标概念，对相关概念的影响最小，与最先进的方法相比，保留性能至少提高了 12%。</p>
</blockquote>
</li>
</ul>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20251014145855328.png"
                     
                ></p>
<h4 id="TIU-The-Illusion-of-Unlearning"><a href="#TIU-The-Illusion-of-Unlearning" class="headerlink" title="TIU (The Illusion of Unlearning)"></a>TIU (The Illusion of Unlearning)</h4><p><em>The Illusion of Unlearning: The Unstable Nature of Machine Unlearning in Text-to-Image Diffusion Models</em></p>
<ul>
<li><a class="link"   target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content/CVPR2025/papers/George_The_Illusion_of_Unlearning_The_Unstable_Nature_of_Machine_Unlearning_CVPR_2025_paper.pdf" >pdf<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li><a class="link"   target="_blank" rel="noopener" href="https://cvpr.thecvf.com/virtual/2025/poster/33746" >poster<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li><a class="link"   target="_blank" rel="noopener" href="https://github.com/NGK2110/TIU" >github<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><blockquote>
<p>文生图模型，例如Stable Diffusion、DALL·E 和 Midjourney，近年来人气飙升。然而，这些模型基于海量数据进行训练，其中可能包含未经许可使用的私密、露骨或受版权保护的内容，这引发了严重的法律和伦理问题。鉴于近期旨在保护个人数据隐私的法规，旨在从模型中移除特定概念的Machine Unlearn(MU)方法激增。<br>然而，我们发现这些Unlearn技术存在一个关键缺陷：<strong>即使使用一般或不相关的提示，当模型进行微调时，已学习的概念仍会重新出现。</strong><br>本文通过广泛的研究，首次揭示了 <strong>文生图DMs中现有Unlearn方法的不稳定性。</strong><br>我们提出了<strong>一个包含若干指标的框架</strong>，用于分析现有Unlearn方法的稳定性。<br>此外，本文对基于映射的Unlearn方法不稳定性的原因进行了初步探讨，这些见解可以指导未来研究更稳健的Unlearn技术。提供了用于实施所提框架的匿名代码。</p>
</blockquote>
</li>
</ul>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20251013155034971.png"
                     
                ></p>
<h4 id="Six-CD-Benchmark"><a href="#Six-CD-Benchmark" class="headerlink" title="Six-CD Benchmark"></a>Six-CD Benchmark</h4><p><em>Six-CD: Benchmarking Concept Removals for Text-to-image Diffusion Models</em></p>
<ul>
<li>TL;DR: 概念擦除基准测试数据集&#x2F;指标</li>
<li><a class="link"   target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content/CVPR2025/papers/Ren_Six-CD_Benchmarking_Concept_Removals_for_Text-to-image_Diffusion_Models_CVPR_2025_paper.pdf" >pdf<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li><a class="link"   target="_blank" rel="noopener" href="https://cvpr.thecvf.com/virtual/2025/poster/34826" >poster<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><blockquote>
<p>文本转图像 (T2I) 扩散模型在生成与文本提示紧密对应的图像方面展现出卓越的能力。然而，T2I 扩散模型的进步也带来了巨大的风险，因为这些模型可能被用于恶意目的，例如生成包含暴力或裸体的图像，或在不恰当的语境中创建未经授权的公众人物肖像。<br>为了降低这些风险，一些概念移除方法被提出。这些方法旨在修改扩散模型，以防止生成恶意和不受欢迎的概念。尽管做出了这些努力，现有研究仍面临一些挑战：(1) 缺乏对综合数据集的一致性比较；(2) 有害和裸体概念中的提示无效；(3) 忽视了对包含恶意概念的提示中生成良性部分的能力的评估。<br>为了弥补这些不足，我们建议通过引入一个 <strong>新数据集 Six-CD</strong> 以及一个 <strong>全新的评估指标</strong> 来对概念移除方法进行基准测试。<br>在该基准测试中，我们对概念移除进行了全面的评估，实验观察和讨论为该领域提供了宝贵的见解。</p>
</blockquote>
</li>
</ul>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20251014145656219.png"
                     
                ><br><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20251014145628765.png"
                     
                ></p>
<h3 id="Bias-1"><a href="#Bias-1" class="headerlink" title="Bias"></a>Bias</h3><h4 id="MPR-Multi-group-Proportional-Representation"><a href="#MPR-Multi-group-Proportional-Representation" class="headerlink" title="MPR (Multi-group Proportional Representation)"></a>MPR (Multi-group Proportional Representation)</h4><p><em>Multi-Group Proportional Representations for Text-to-Image Models</em></p>
<ul>
<li><a class="link"   target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content/CVPR2025/papers/Jung_Multi-Group_Proportional_Representations_for_Text-to-Image_Models_CVPR_2025_paper.pdf" >pdf<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li><a class="link"   target="_blank" rel="noopener" href="https://cvpr.thecvf.com/virtual/2025/poster/34035" >poster<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><blockquote>
<p>文本转图像生成模型可以根据文本描述创建生动逼真的图像。随着这些模型的普及，它们也暴露出新的担忧，即它们能否代表不同的人口群体、传播刻板印象以及抹去少数群体的形象。<br>尽管人们越来越关注人工智能 (AI) 的“安全”和“负责任”设计，但目前尚无成熟的方法来系统地测量和控制大型图像生成模型中的表征损害。<br>本文介绍了一个 <strong>用于测量T2IDMs生成的图像中 交叉群体表征 的全新框架。</strong><br>我们提出了一种新的 <strong>多群体均衡的表征 (MPR) 指标</strong> 的应用，以严格评估图像生成中的表征损害，并 <strong>开发了一种算法来优化生成模型以达到该表征指标</strong>。MPR 评估生成模型生成的图像中 <strong>给定人群群体表征统计数据的最坏情况偏差</strong>，从而允许根据用户需求进行灵活且针对特定情境的测量。<br>通过实验，我们证明 MPR 可以 <strong>有效地测量多个交叉群体的代表性统计数据</strong>，并且当用作训练目标时，可以 <strong>引导模型在保持生成质量的同时，实现跨人口群体的更平衡的生成。</strong></p>
</blockquote>
</li>
</ul>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20251013164853941.png"
                     
                ></p>
<h4 id="Rethinking-Training-for-De-biasing-Text-to-Image-Generation"><a href="#Rethinking-Training-for-De-biasing-Text-to-Image-Generation" class="headerlink" title="Rethinking Training for De-biasing Text-to-Image Generation"></a>Rethinking Training for De-biasing Text-to-Image Generation</h4><p><em>Rethinking Training for De-biasing Text-to-Image Generation: Unlocking the Potential of Stable Diffusion</em></p>
<ul>
<li><a class="link"   target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content/CVPR2025/papers/Kim_Rethinking_Training_for_De-biasing_Text-to-Image_Generation_Unlocking_the_Potential_of_CVPR_2025_paper.pdf" >pdf<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li><a class="link"   target="_blank" rel="noopener" href="https://cvpr.thecvf.com/virtual/2025/poster/34534" >poster<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><blockquote>
<p>文本转图像模型（例如稳定扩散）的最新进展显示出明显的人口统计学偏差。<br>现有的去偏差技术严重依赖于额外的训练，这会带来高昂的计算成本，并可能损害核心图像生成功能。这阻碍了它们在实际应用中的广泛应用。<br>在本文中，我们探索了稳定扩散在 <strong>无需额外训练的情况下降低偏差的潜力</strong> ，这一潜力被人们忽视。<br>通过分析，我们发现与少数族裔属性相关的初始噪声构成了稳定扩散中“少数族裔区域”降低偏差的机会。为了释放这一潜力，我们提出了 <strong>一种名为 “弱引导(weak guidance)” 的新型去偏差方法</strong>，该方法经过精心设计，可以 <strong>在不损害语义完整性的情况下将随机噪声引导至少数族裔区域。</strong><br>通过对不同版本稳定扩散的分析和实验，我们证明了我们提出的方法能够在无需额外训练的情况下有效降低偏差，既实现了效率，又保留了核心图像生成功能。</p>
</blockquote>
</li>
</ul>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20251014135522383.png"
                     
                ></p>
<h3 id="Watermarks-1"><a href="#Watermarks-1" class="headerlink" title="Watermarks"></a>Watermarks</h3><h4 id="SleeperMark"><a href="#SleeperMark" class="headerlink" title="SleeperMark"></a>SleeperMark</h4><p><em>SleeperMark: Towards Robust Watermark against Fine-Tuning Text-to-image Diffusion Models</em></p>
<ul>
<li>TL;DR: 模型在适应新任务时很容易忘记先前学习的水印知识，SleeperMark提出一种抗微调的水印嵌入方法</li>
<li><a class="link"   target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_SleeperMark_Towards_Robust_Watermark_against_Fine-Tuning_Text-to-image_Diffusion_Models_CVPR_2025_paper.pdf" >pdf<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li><a class="link"   target="_blank" rel="noopener" href="https://cvpr.thecvf.com/virtual/2025/poster/33491" >poster<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><blockquote>
<p>大规模文本转图像 (T2I) 扩散模型的最新进展已赋能各种下游应用，包括风格定制、主题驱动的个性化和条件生成。由于 T2I 模型需要大量数据和计算资源进行训练，因此它们对其合法所有者而言构成了高价值的知识产权 (IP)，但也使其成为攻击者未经授权进行微调的目标，攻击者试图利用这些模型进行定制化、通常有利可图的应用。<br>现有的扩散模型 IP 保护方法通常包括嵌入水印模式，然后通过检查生成的输出或检查模型的特征空间来验证所有权。然而，在实际场景中，当嵌入水印的模型进行微调，且在验证过程中无法访问特征空间（即黑盒设置）时，这些技术本质上是无效的。<br>模型在适应新任务时很容易忘记先前学习的水印知识。为了应对这一挑战，我们提出了 <strong>SleeperMark</strong>，这是一个旨在 <strong>将弹性水印嵌入 T2I 扩散模型的新颖框架</strong> 。<br>SleeperMark 明确 <strong>引导模型将水印信息与其学习到的语义概念分离，从而使模型能够保留嵌入的水印，同时继续针对新的下游任务进行微调。</strong><br>我们进行了大量的实验，证明了 SleeperMark 在各种类型的扩散模型（包括潜在扩散模型（例如稳定扩散）和像素扩散模型（例如 DeepFloyd-IF））中的有效性，并展现出<strong>对下游微调和图像及模型层面各种攻击的稳健性，同时对模型的生成能力影响极小。</strong></p>
</blockquote>
</li>
</ul>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20251014151057735.png"
                     
                ></p>
<h1 id="ICCV-2025"><a href="#ICCV-2025" class="headerlink" title="ICCV 2025"></a>ICCV 2025</h1><p>Submission Deadline: 2025.03.07</p>
<p>Official Site:</p>
<ul>
<li><a class="link"   target="_blank" rel="noopener" href="https://iccv.thecvf.com/virtual/2025/papers.html" >ICCV 2025 Papers<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
</ul>
<h2 id="Attack-2"><a href="#Attack-2" class="headerlink" title="Attack"></a>Attack</h2><h2 id="Defence-2"><a href="#Defence-2" class="headerlink" title="Defence"></a>Defence</h2><h3 id="Unlearn-1"><a href="#Unlearn-1" class="headerlink" title="Unlearn"></a>Unlearn</h3><h4 id="TRCE-Towards-Reliable-Malicious-Concept-Erasure"><a href="#TRCE-Towards-Reliable-Malicious-Concept-Erasure" class="headerlink" title="TRCE (Towards Reliable Malicious Concept Erasure)"></a>TRCE (Towards Reliable Malicious Concept Erasure)</h4><p><em>TRCE: Towards Reliable Malicious Concept Erasure in Text-to-Image Diffusion Models</em></p>
<ul>
<li><a class="link"   target="_blank" rel="noopener" href="https://arxiv.org/pdf/2503.07389" >pdf<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li><a class="link"   target="_blank" rel="noopener" href="https://iccv.thecvf.com/virtual/2025/poster/21" >poster<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li><a class="link"   target="_blank" rel="noopener" href="https://github.com/ddgoodgood/TRCE" >code<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><blockquote>
<p>文本到图像扩散模型的最新进展使得生成逼真的图像成为可能，但也存在生成恶意内容（例如 NSFW 图片）的风险。为了降低风险，人们研究了概念擦除方法，以帮助模型忘记特定概念。<br>然而，目前的研究难以完全擦除隐含在提示（例如隐喻表达或对抗性提示）中的恶意概念，同时保留模型的正常生成能力。<br>为了应对这一挑战，我们的研究提出了 <strong>TRCE</strong>，它 <strong>使用两阶段概念擦除策略来在可靠擦除和知识保存之间实现有效的权衡</strong> 。<br>首先，TRCE 从擦除隐含在文本提示中的恶意语义开始。<strong>通过确定有效的映射目标（即 [EoT] 嵌入），我们优化了交叉注意力层，将恶意提示映射到上下文相似但概念安全的提示。</strong> 此步骤可防止模型在去噪过程中受到恶意语义的过度影响。在此基础上，考虑到扩散模型采样轨迹的确定性，<strong>TRCE 通过对比学习进一步引导早期去噪预测向安全方向发展，远离不安全方向，从而进一步避免恶意内容的生成。</strong><br>最后，我们在多个恶意概念擦除基准上对 TRCE 进行了全面的评估，结果证明了其 <strong>在擦除恶意概念方面的有效性，同时更好地保留了模型原有的生成能力</strong> 。本文涵盖了模型生成的内容中可能包含攻击性内容。</p>
</blockquote>
</li>
</ul>
<!-- ![](https://iccv.thecvf.com/media/PosterPDFs/ICCV%202025/21.png) -->
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20251014154352078.png"
                     
                ></p>
<h4 id="SuMa-Subspace-Mapping"><a href="#SuMa-Subspace-Mapping" class="headerlink" title="SuMa (Subspace Mapping)"></a>SuMa (Subspace Mapping)</h4><p><em>SuMa: A Subspace Mapping Approach for Robust and Effective Concept Erasure in Text-to-Image Diffusion Models</em></p>
<ul>
<li><a class="link"   target="_blank" rel="noopener" href="https://arxiv.org/pdf/2509.05625" >pdf<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li><a class="link"   target="_blank" rel="noopener" href="https://iccv.thecvf.com/virtual/2025/poster/418" >poster<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li><a class="link"   target="_blank" rel="noopener" href="https://youtu.be/SeqAEhOZbEQ" >video<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><blockquote>
<p>文本到图像扩散模型的快速发展引发了人们对其可能被滥用于生成有害或未经授权内容的担忧。为了解决这些问题，人们提出了几种概念擦除方法。<br>然而，大多数方法都无法实现 <strong>完整性（即完全删除目标概念的能力）</strong> 和 <strong>有效性（即保持图像质量）</strong> 。虽然近期有少数技术成功实现了针对 NSFW 概念的上述目标，但没有一种技术能够处理诸如受版权保护的人物或名人等狭义概念。<br>消除这些狭义概念对于解决版权和法律问题至关重要。然而，由于这些概念与非目标相邻概念的距离很近，因此从扩散模型中删除它们具有挑战性，需要更精细的操作。在本文中，我们介绍了<strong>子空间映射（SuMa）</strong>，这是一种新颖的方法，专门用于实现 <strong>擦除这些狭义概念的完整性和有效性。</strong><br><strong>SuMa 首先得出一个代表要消除的概念的目标子空间，然后通过将其映射到一个参考子空间，使两者之间的距离最小化，从而对其进行中和</strong>。这种映射可确保目标概念被完全消除，同时保持图像质量。<br>我们用 SuMa 在四项任务中进行了广泛的实验：<strong>子类消除</strong>、<strong>名人消除</strong>、<strong>艺术风格消除</strong> 和 <strong>实例消除</strong>，并将实验结果与当前最先进的方法进行了比较。我们的方法不仅在图像质量方面优于那些注重有效性的方法，而且还取得了与注重完整性的方法相当的结果。</p>
</blockquote>
</li>
</ul>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20251014155700535.png"
                     
                ></p>
<h4 id="EraseBench"><a href="#EraseBench" class="headerlink" title="EraseBench"></a>EraseBench</h4><p><em>Erasing More Than Intended? How Concept Erasure Degrades the Generation of Non-Target Concepts</em></p>
<ul>
<li><a class="link"   target="_blank" rel="noopener" href="https://arxiv.org/pdf/2501.09833v2" >pdf<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li><a class="link"   target="_blank" rel="noopener" href="https://iccv.thecvf.com/virtual/2025/poster/1222" >poster<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><blockquote>
<p>概念擦除技术因其从文本转图像模型中移除不想要概念的潜力而备受关注。虽然这些方法在受控环境中通常表现出良好的效果，但它们在实际应用中的稳健性和部署适用性仍不确定。<br>在本研究中，我们 <strong>(1) 发现了 评估 净化模型 的关键缺陷</strong> ，尤其是在评估其在不同概念维度上的表现方面；**(2) 系统地分析了 擦除后文本转图像模型的失效模式** 。我们重点研究了概念移除对不同层次互联关系（包括视觉相似、二项式和语义相关概念）中的非目标概念造成的意外后果。<br>为了更全面地评估概念擦除，我们引入了 <strong>EraseBench</strong>，这是 <strong>一个多维框架，旨在严格评估擦除后的文本转图像模型</strong> 。它包含 <strong>100</strong> 多个不同的概念、精心策划的种子提示以确保可重复的图像生成，以及用于基于模型评估的专用评估提示。我们的框架 <strong>与一套强大的评估指标相结合</strong> ，对 <strong>概念擦除的有效性及其对模型行为的长期影响</strong> 进行了全面而深入的分析。<br>我们的研究结果揭示了 <strong>概念纠缠现象，其中擦除导致非目标概念的意外抑制，导致溢出退化，表现为扭曲和生成质量下降</strong>。</p>
</blockquote>
</li>
</ul>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20251014154506706.png"
                     
                ></p>

		</div>

		
		<div class="post-copyright-info w-full my-8 px-2 sm:px-6 md:px-8">
			<div class="article-copyright-info-container">
    <ul>
        <li><strong>Title:</strong> Paper Collection of Safe Diffusion</li>
        <li><strong>Author:</strong> LeoJeshua</li>
        <li><strong>Created at
                :</strong> 2024-12-21 15:49:09</li>
        
            <li>
                <strong>Updated at
                    :</strong> 2025-10-14 15:57:19
            </li>
        
        <li>
            <strong>Link:</strong> https://leojeshua.github.io/DMs/Paper-Collection-of-Safe-Diffusion/
        </li>
        <li>
            <strong>
                License:
            </strong>
            

            
                This work is licensed under <a class="license" target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0">CC BY-NC-SA 4.0</a>.
            
        </li>
    </ul>
</div>

		</div>
		

		
		<ul class="post-tags-box text-lg mt-1.5 flex-wrap justify-center flex md:hidden">
			
			<li class="tag-item mx-0.5">
				<a href="/tags/DMs/">#DMs</a>&nbsp;
			</li>
			
			<li class="tag-item mx-0.5">
				<a href="/tags/Paper-Collection/">#Paper Collection</a>&nbsp;
			</li>
			
		</ul>
		

		

		
		<div class="article-nav my-8 flex justify-between items-center px-2 sm:px-6 md:px-8">
			
			<div class="article-prev border-border-color shadow-redefine-flat shadow-shadow-color-2 rounded-medium px-4 py-2 hover:shadow-redefine-flat-hover hover:shadow-shadow-color-2">
				<a class="prev" rel="prev" href="/Course/eecs498/eecs498/">
					<span class="left arrow-icon flex justify-center items-center">
						<i class="fa-solid fa-chevron-left"></i>
					</span>
					<span class="title flex justify-center items-center">
						<span class="post-nav-title-item truncate max-w-48">Notes of &#34;EECS498/598 Deep Learning for Computer Vision (FA2019)&#34;</span>
						<span class="post-nav-item">Prev posts</span>
					</span>
				</a>
			</div>
			
			
			<div class="article-next border-border-color shadow-redefine-flat shadow-shadow-color-2 rounded-medium px-4 py-2 hover:shadow-redefine-flat-hover hover:shadow-shadow-color-2">
				<a class="next" rel="next" href="/CV/Patch-Level-Adversarial-Attacks-in-Computer-Vision/">
					<span class="title flex justify-center items-center">
						<span class="post-nav-title-item truncate max-w-48">Patch-Level Adversarial Attacks on Computer Vision</span>
						<span class="post-nav-item">Next posts</span>
					</span>
					<span class="right arrow-icon flex justify-center items-center">
						<i class="fa-solid fa-chevron-right"></i>
					</span>
				</a>
			</div>
			
		</div>
		


		
	</div>

	
	<div class="toc-content-container">
		<div class="post-toc-wrap">
	<div class="post-toc">
		<div class="toc-title">On this page</div>
		<div class="page-title">Paper Collection of Safe Diffusion</div>
		<ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#NeurIPS2024"><span class="nav-text">NeurIPS2024</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Attack"><span class="nav-text">Attack</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Backdoors-Attack"><span class="nav-text">Backdoors Attack</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#BiBadDiff"><span class="nav-text">BiBadDiff</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Adversarial-Attack"><span class="nav-text">Adversarial Attack</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#PAP"><span class="nav-text">PAP</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#AdvAD"><span class="nav-text">AdvAD</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#MIA-Member-Inference-Attack"><span class="nav-text">MIA (Member Inference Attack)</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#CLiD"><span class="nav-text">CLiD</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Watermark"><span class="nav-text">Watermark</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#ZoDiac"><span class="nav-text">ZoDiac</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Federated-Learning"><span class="nav-text">Federated Learning</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#DataStealing"><span class="nav-text">DataStealing</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Defence"><span class="nav-text">Defence</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Anti-Adversarial-Prompt"><span class="nav-text">Anti-Adversarial Prompt</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#GuardT2I"><span class="nav-text">GuardT2I</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Unlearn"><span class="nav-text">Unlearn</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#AdvUnlearn"><span class="nav-text">AdvUnlearn</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Leveraging-Catastrophic-Forgetting"><span class="nav-text">Leveraging Catastrophic Forgetting</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Memory-Editing"><span class="nav-text">Memory Editing</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Finding-NeMo"><span class="nav-text">Finding NeMo</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#P-ESD-P-AC-SGAW-Wrokshop"><span class="nav-text">P-ESD&#x2F;P-AC [SGAW Wrokshop]</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#CVPR-2025"><span class="nav-text">CVPR 2025</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Attack-1"><span class="nav-text">Attack</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Adversarial-Attack-1"><span class="nav-text">Adversarial Attack</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#FastProtect"><span class="nav-text">FastProtect</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Data-Poisoning-Attack"><span class="nav-text">Data Poisoning Attack</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Silent-Branding-Attack"><span class="nav-text">Silent Branding Attack</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#MIA"><span class="nav-text">MIA</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#CDI-Copyrighted-Data-Identification"><span class="nav-text">CDI (Copyrighted Data Identification)</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Bias"><span class="nav-text">Bias</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#IBI-Implicit-Bias-Injection-Attacks"><span class="nav-text">IBI (Implicit Bias Injection Attacks)</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Watermarks"><span class="nav-text">Watermarks</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Black-Box-Forgery-Attacks-on-Semantic-Watermarks"><span class="nav-text">Black-Box Forgery Attacks on Semantic Watermarks</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Defence-1"><span class="nav-text">Defence</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Guidence"><span class="nav-text">Guidence</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#DAG-Detect-and-Guide"><span class="nav-text">DAG (Detect-and-Guide)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Concept-Replacer"><span class="nav-text">Concept Replacer</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Unlern"><span class="nav-text">Unlern</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#EraseDiff"><span class="nav-text">EraseDiff</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Localized-Concept-Erasure-GLoCE"><span class="nav-text">Localized Concept Erasure (GLoCE)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#ACE-Anti-editing-Concept-Erasure"><span class="nav-text">ACE (Anti-editing Concept Erasure)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#STEREO-Search-Thoroughly-Enough-Robustly-Erase-Once"><span class="nav-text">STEREO (Search Thoroughly Enough, Robustly Erase Once)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#RIIDL-Responsible-Interpretable-Intermediate-Diffusion-Latents"><span class="nav-text">RIIDL (Responsible Interpretable Intermediate Diffusion Latents)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#AdaVD-Adaptive-Vaule-Decomposer"><span class="nav-text">AdaVD (Adaptive Vaule Decomposer)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#FADE-Fine-grained-Attenuation-for-Diffusion-Erasure"><span class="nav-text">FADE (Fine-grained Attenuation for Diffusion Erasure)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#TIU-The-Illusion-of-Unlearning"><span class="nav-text">TIU (The Illusion of Unlearning)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Six-CD-Benchmark"><span class="nav-text">Six-CD Benchmark</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Bias-1"><span class="nav-text">Bias</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#MPR-Multi-group-Proportional-Representation"><span class="nav-text">MPR (Multi-group Proportional Representation)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Rethinking-Training-for-De-biasing-Text-to-Image-Generation"><span class="nav-text">Rethinking Training for De-biasing Text-to-Image Generation</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Watermarks-1"><span class="nav-text">Watermarks</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#SleeperMark"><span class="nav-text">SleeperMark</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#ICCV-2025"><span class="nav-text">ICCV 2025</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Attack-2"><span class="nav-text">Attack</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Defence-2"><span class="nav-text">Defence</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Unlearn-1"><span class="nav-text">Unlearn</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#TRCE-Towards-Reliable-Malicious-Concept-Erasure"><span class="nav-text">TRCE (Towards Reliable Malicious Concept Erasure)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#SuMa-Subspace-Mapping"><span class="nav-text">SuMa (Subspace Mapping)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#EraseBench"><span class="nav-text">EraseBench</span></a></li></ol></li></ol></li></ol></li></ol>

	</div>
</div>
	</div>
	
</div>
			</div>

			
		</div>

		<div class="main-content-footer">
			<footer class="footer mt-5 py-5 h-auto text-base text-third-text-color relative border-t-2 border-t-border-color">
    <div class="info-container py-3 text-center">
        
        <div class="text-center">
            &copy;
            
              <span>2024</span>
              -
            
            2025&nbsp;&nbsp;<i class="fa-solid fa-cog fa-spin" style="--fa-animation-duration:15s"></i>&nbsp;&nbsp;<a href="/">LeoJeshua</a>
            
                
                <p class="post-count space-x-0.5">
                    <span>
                        15 posts in total
                    </span>
                    
                        <span>
                            30.6k words in total
                        </span>
                    
                </p>
            
        </div>
        
            <script data-swup-reload-script src="https://cn.vercount.one/js"></script>
            <div class="relative text-center lg:absolute lg:right-[20px] lg:top-1/2 lg:-translate-y-1/2 lg:text-right">
                
                    <span id="busuanzi_container_site_uv" class="lg:!block">
                        <span class="text-sm">VISITOR COUNT</span>
                        <span id="busuanzi_value_site_uv"></span>
                    </span>
                
                
                    <span id="busuanzi_container_site_pv" class="lg:!block">
                        <span class="text-sm">TOTAL PAGE VIEWS</span>
                        <span id="busuanzi_value_site_pv"></span>
                    </span>
                
            </div>
        
        <div class="relative text-center lg:absolute lg:left-[20px] lg:top-1/2 lg:-translate-y-1/2 lg:text-left">
            <span class="lg:block text-sm">POWERED BY <?xml version="1.0" encoding="utf-8"?><!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"><svg class="relative top-[2px] inline-block align-baseline" version="1.1" id="圖層_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" width="1rem" height="1rem" viewBox="0 0 512 512" enable-background="new 0 0 512 512" xml:space="preserve"><path fill="#0E83CD" d="M256.4,25.8l-200,115.5L56,371.5l199.6,114.7l200-115.5l0.4-230.2L256.4,25.8z M349,354.6l-18.4,10.7l-18.6-11V275H200v79.6l-18.4,10.7l-18.6-11v-197l18.5-10.6l18.5,10.8V237h112v-79.6l18.5-10.6l18.5,10.8V354.6z"/></svg><a target="_blank" class="text-base" href="https://hexo.io">Hexo</a></span>
            <span class="text-sm lg:block">THEME&nbsp;<a class="text-base" target="_blank" href="https://github.com/EvanNotFound/hexo-theme-redefine">Redefine v2.8.5</a></span>
        </div>
        
        
            <div>
                Blog up for <span class="odometer" id="runtime_days" ></span> days <span class="odometer" id="runtime_hours"></span> hrs <span class="odometer" id="runtime_minutes"></span> Min <span class="odometer" id="runtime_seconds"></span> Sec
            </div>
        
        
            <script data-swup-reload-script>
                try {
                    function odometer_init() {
                    const elements = document.querySelectorAll('.odometer');
                    elements.forEach(el => {
                        new Odometer({
                            el,
                            format: '( ddd).dd',
                            duration: 200
                        });
                    });
                    }
                    odometer_init();
                } catch (error) {}
            </script>
        
        
            
                
        
                
        
                

                    
                        <script data-swup-reload-script>var url_1736="https://api.cdnorg.cn:666";var token_1736="8d393e3086e1d2d48267460f67b7bf8d1a09f23f231d32de4f3fb3a12f3af020";var cltj_1736=document.createElement("script");cltj_1736.src=url_1736+"/tj/tongji.js?v=2.201";var s_1736=document.getElementsByTagName("script")[0];s_1736.parentNode.insertBefore(cltj_1736,s_1736);</script>
                    
        
                

                    
                        <script data-swup-reload-script type="text/javascript">(function(){var baidu=document.createElement("script");baidu.src="//i.6v6.work/v/?uid=388547";var cnzz=document.getElementsByTagName("script")[0];cnzz.parentNode.insertBefore(baidu,cnzz)})();</script>
                    
        
        
    </div>  
</footer>
		</div>
	</div>

	
	<div class="post-tools">
		<div class="post-tools-container">
	<ul class="article-tools-list">
		<!-- TOC aside toggle -->
		
		<li class="right-bottom-tools page-aside-toggle">
			<i class="fa-regular fa-outdent"></i>
		</li>
		

		<!-- go comment -->
		
	</ul>
</div>
	</div>
	

	<div class="right-side-tools-container">
		<div class="side-tools-container">
	<ul class="hidden-tools-list">
		<li class="right-bottom-tools tool-font-adjust-plus flex justify-center items-center">
			<i class="fa-regular fa-magnifying-glass-plus"></i>
		</li>

		<li class="right-bottom-tools tool-font-adjust-minus flex justify-center items-center">
			<i class="fa-regular fa-magnifying-glass-minus"></i>
		</li>

		<li class="right-bottom-tools tool-dark-light-toggle flex justify-center items-center">
			<i class="fa-regular fa-moon"></i>
		</li>

		<!-- rss -->
		

		

		<li class="right-bottom-tools tool-scroll-to-bottom flex justify-center items-center">
			<i class="fa-regular fa-arrow-down"></i>
		</li>
	</ul>

	<ul class="visible-tools-list">
		<li class="right-bottom-tools toggle-tools-list flex justify-center items-center">
			<i class="fa-regular fa-cog fa-spin"></i>
		</li>
		
		<li class="right-bottom-tools tool-scroll-to-top flex justify-center items-center">
			<i class="arrow-up fas fa-arrow-up"></i>
			<span class="percent"></span>
		</li>
		
		
	</ul>
</div>
	</div>

	<div class="image-viewer-container">
	<img src="">
</div>

	

</main>


<script  src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.5/files/source/js/build/libs/Swup.min.js" ></script><script  src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.5/files/source/js/build/libs/SwupSlideTheme.min.js" ></script><script  src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.5/files/source/js/build/libs/SwupScriptsPlugin.min.js" ></script><script  src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.5/files/source/js/build/libs/SwupProgressPlugin.min.js" ></script><script  src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.5/files/source/js/build/libs/SwupScrollPlugin.min.js" ></script><script  src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.5/files/source/js/build/libs/SwupPreloadPlugin.min.js" ></script>
<script>
    const swup = new Swup({
        plugins: [
            new SwupScriptsPlugin({
                optin: true,
            }),
            new SwupProgressPlugin(),
            new SwupScrollPlugin({
                offset: 80,
            }),
            new SwupSlideTheme({
                mainElement: ".main-content-body",
            }),
            new SwupPreloadPlugin(),
        ],
        containers: ["#swup"],
    });
</script>




	<script type="module" src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.5/files/source/js/build/tools/imageViewer.js" ></script><script type="module" src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.5/files/source/js/build/utils.js" ></script><script type="module" src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.5/files/source/js/build/main.js" ></script><script type="module" src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.5/files/source/js/build/layouts/navbarShrink.js" ></script><script type="module" src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.5/files/source/js/build/tools/scrollTopBottom.js" ></script><script type="module" src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.5/files/source/js/build/tools/lightDarkSwitch.js" ></script><script type="module" src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.5/files/source/js/build/layouts/categoryList.js" ></script>




    <script type="module" src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.5/files/source/js/build/tools/codeBlock.js" ></script>



    <script type="module" src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.5/files/source/js/build/layouts/lazyload.js" ></script>



    <script  src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.5/files/source/js/build/tools/runtime.js" ></script>
    <script  src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.5/files/source/js/build/libs/odometer.min.js" ></script>
    <link rel="stylesheet" href="https://registry.npmmirror.com/hexo-theme-redefine/2.8.5/files/source/assets/odometer-theme-minimal.css">



  <script  src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.5/files/source/js/build/libs/Typed.min.js" ></script>
  <script type="module" src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.5/files/source/js/build/plugins/typed.js" ></script>







    <script  src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.5/files/source/js/build/libs/anime.min.js" ></script>




    <script type="module" src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.5/files/source/js/build/tools/tocToggle.js" data-swup-reload-script></script><script type="module" src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.5/files/source/js/build/layouts/toc.js" data-swup-reload-script></script><script type="module" src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.5/files/source/js/build/plugins/tabs.js" data-swup-reload-script></script>


<script  src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.5/files/source/js/build/libs/moment-with-locales.min.js" data-swup-reload-script></script>
<script type="module" src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.5/files/source/js/build/layouts/essays.js" data-swup-reload-script></script>




	
</body>

</html>