<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="keywords" content="Hexo Theme Redefine">
    
    <meta name="author" content="LeoJeshua">
    
    <!-- Completely eliminate flash of wrong theme -->
    <script>
        (function() {
            const THEME_KEY = "REDEFINE-THEME-STATUS";
            const DARK = "dark", LIGHT = "light";
            
            // Get preferred theme
            function getTheme() {
                try {
                    const saved = localStorage.getItem(THEME_KEY);
                    if (saved) {
                        const { isDark } = JSON.parse(saved);
                        return isDark ? DARK : LIGHT;
                    }
                } catch (e) {}
                
                return matchMedia("(prefers-color-scheme: dark)").matches ? DARK : LIGHT;
            }
            
            // Apply theme to document
            function applyTheme(theme) {
                const isDark = theme === DARK;
                const root = document.documentElement;
                
                // Set data attribute for CSS variables
                root.setAttribute("data-theme", theme);
                
                // Set classes for compatibility
                root.classList.add(theme);
                root.classList.remove(isDark ? LIGHT : DARK);
                root.style.colorScheme = theme;
            }
            
            // Initial application
            const theme = getTheme();
            applyTheme(theme);
            
            // Listen for system preference changes
            matchMedia("(prefers-color-scheme: dark)").addEventListener("change", ({ matches }) => {
                // Only update if using system preference (no localStorage entry)
                if (!localStorage.getItem(THEME_KEY)) {
                    applyTheme(matches ? DARK : LIGHT);
                }
            });
            
            // Set body classes once DOM is ready
            if (document.readyState !== "loading") {
                document.body.classList.add(theme + "-mode");
            } else {
                document.addEventListener("DOMContentLoaded", () => {
                    document.body.classList.add(theme + "-mode");
                    document.body.classList.remove((theme === DARK ? LIGHT : DARK) + "-mode");
                });
            }
        })();
    </script>
    
    <!-- Critical CSS to prevent flash -->
    <style>
        :root[data-theme="dark"] {
            --background-color: #202124;
            --background-color-transparent: rgba(32, 33, 36, 0.6);
            --second-background-color: #2d2e32;
            --third-background-color: #34353a;
            --third-background-color-transparent: rgba(32, 33, 36, 0.6);
            --primary-color: #0066CC;
            --first-text-color: #ffffff;
            --second-text-color: #eeeeee;
            --third-text-color: #bebec6;
            --fourth-text-color: #999999;
            --default-text-color: #bebec6;
            --invert-text-color: #373D3F;
            --border-color: rgba(255, 255, 255, 0.08);
            --selection-color: #0066CC;
            --shadow-color-1: rgba(255, 255, 255, 0.08);
            --shadow-color-2: rgba(255, 255, 255, 0.05);
        }
        
        :root[data-theme="light"] {
            --background-color: #fff;
            --background-color-transparent: rgba(255, 255, 255, 0.6);
            --second-background-color: #f8f8f8;
            --third-background-color: #f2f2f2;
            --third-background-color-transparent: rgba(241, 241, 241, 0.6);
            --primary-color: #0066CC;
            --first-text-color: #16171a;
            --second-text-color: #2f3037;
            --third-text-color: #5e5e5e;
            --fourth-text-color: #eeeeee;
            --default-text-color: #373D3F;
            --invert-text-color: #bebec6;
            --border-color: rgba(0, 0, 0, 0.08);
            --selection-color: #0066CC;
            --shadow-color-1: rgba(0, 0, 0, 0.08);
            --shadow-color-2: rgba(0, 0, 0, 0.05);
        }
        
        body {
            background-color: var(--background-color);
            color: var(--default-text-color);
        }
        
        /* Apply body classes as soon as DOM is ready */
        :root[data-theme="dark"] body {
            background-color: var(--background-color);
            color: var(--default-text-color);
        }
    </style>
    
    <!-- preconnect -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>

    
        
        
        
            <link rel="preconnect" href="https://registry.npmmirror.com" crossorigin>
        
    
    <!--- Seo Part-->
    
    <link rel="canonical" href="https://leojeshua.github.io/dms/paper-collection-of-safe-diffusion_cvpr-2025/"/>
    <meta name="robots" content="index,follow">
    <meta name="googlebot" content="index,follow">
    <meta name="revisit-after" content="1 days">
    
    
    
        
        <meta name="description" content="Hexo Theme Redefine, Redefine Your Hexo Journey.">
<meta property="og:type" content="article">
<meta property="og:title" content="Paper Collection of Safe Diffusion at CVPR 2025">
<meta property="og:url" content="https://leojeshua.github.io/DMs/Paper-Collection-of-Safe-Diffusion_CVPR-2025/index.html">
<meta property="og:site_name" content="The Blog of LeoJeshua">
<meta property="og:description" content="Hexo Theme Redefine, Redefine Your Hexo Journey.">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://leojeshua.github.io/images/redefine-og.webp">
<meta property="article:published_time" content="2025-02-26T07:49:09.000Z">
<meta property="article:modified_time" content="2025-11-14T06:23:47.823Z">
<meta property="article:author" content="LeoJeshua">
<meta property="article:tag" content="DMs">
<meta property="article:tag" content="Paper Collection">
<meta property="article:tag" content="CVPR">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://leojeshua.github.io/images/redefine-og.webp">
    
    
    <!--- Icon Part-->
    <link rel="icon" type="image/png" href="/images/avatar.png" sizes="192x192">
    <link rel="apple-touch-icon" sizes="180x180" href="/images/avatar.png">
    <meta name="theme-color" content="#A31F34">
    <link rel="shortcut icon" href="/images/avatar.png">
    <!--- Page Info-->
    
    <title>
        
            Paper Collection of Safe Diffusion at CVPR 2025 | Academic Blog of LeoJeshua
        
    </title>

    <link rel="stylesheet" href="https://registry.npmmirror.com/hexo-theme-redefine/2.8.5/files/source/fonts/Chillax/chillax.css">

    <!--- Inject Part-->
    
        
            
    
            
    

    
<link rel="stylesheet" href="/css/style.css">


    
        <link rel="stylesheet" href="https://registry.npmmirror.com/hexo-theme-redefine/2.8.5/files/source/css/build/tailwind.css">
    

    <link rel="stylesheet" href="https://registry.npmmirror.com/hexo-theme-redefine/2.8.5/files/source/fonts/GeistMono/geist-mono.css">
    <link rel="stylesheet" href="https://registry.npmmirror.com/hexo-theme-redefine/2.8.5/files/source/fonts/Geist/geist.css">
    <!--- Font Part-->
    
    
    
    
    
    

    <script id="hexo-configurations">
    window.config = {"hostname":"leojeshua.github.io","root":"/","language":"en"};
    window.theme = {"articles":{"style":{"font_size":"16px","line_height":1.5,"image_border_radius":"2px","image_alignment":"center","image_caption":false,"link_icon":true,"delete_mask":false,"title_alignment":"left","headings_top_spacing":{"h1":"3.2rem","h2":"2.5rem","h3":"1.8rem","h4":"1.3rem","h5":"1.2rem","h6":"1.1rem"}},"word_count":{"enable":true,"count":true,"min2read":true},"author_label":{"enable":true,"auto":false,"list":[]},"code_block":{"copy":true,"style":"mac","highlight_theme":{"light":"github","dark":"vs2015"},"font":{"enable":false,"family":null,"url":null}},"toc":{"enable":true,"max_depth":4,"number":false,"expand":true,"init_open":true},"copyright":{"enable":true,"default":"cc_by_nc_sa"},"lazyload":true,"pangu_js":false,"recommendation":{"enable":false,"title":"推荐阅读","limit":3,"mobile_limit":2,"placeholder":"/images/wallhaven-wqery6-light.webp","skip_dirs":[]}},"colors":{"primary":"#A31F34","secondary":null,"default_mode":"light"},"global":{"fonts":{"chinese":{"enable":false,"family":null,"url":null},"english":{"enable":false,"family":null,"url":null},"title":{"enable":false,"family":null,"url":null}},"content_max_width":"1200px","sidebar_width":"30%","hover":{"shadow":true,"scale":false},"scroll_progress":{"bar":false,"percentage":true},"website_counter":{"url":"https://cn.vercount.one/js","enable":true,"site_pv":true,"site_uv":true,"post_pv":true},"single_page":true,"preloader":{"enable":false,"custom_message":null},"side_tools":{"gear_rotation":true,"auto_expand":false},"open_graph":{"enable":true,"image":"/images/redefine-og.webp","description":"Hexo Theme Redefine, Redefine Your Hexo Journey."},"google_analytics":{"enable":false,"id":null}},"home_banner":{"enable":true,"style":"static","image":{"light":"/images/wallhaven-wqery6-light.webp","dark":"/images/wallhaven-wqery6-dark.webp"},"title":"从-1开始的科研训练之路","subtitle":{"text":["If you shed tears when you miss the sun, you also miss the stars.","Reading maketh a full man; conference a ready man; and writing an exact man. (Francis Bacon)","Who drives me forward like fate? The Myself striding on my back."],"hitokoto":{"enable":false,"show_author":false,"api":"https://v1.hitokoto.cn"},"typing_speed":100,"backing_speed":80,"starting_delay":500,"backing_delay":1500,"loop":true,"smart_backspace":true},"text_color":{"light":"#fff","dark":"#d1d1b6"},"text_style":{"title_size":"2.8rem","subtitle_size":"1.5rem","line_height":1.2},"custom_font":{"enable":false,"family":null,"url":null},"social_links":{"enable":true,"style":"default","links":{"github":"https://github.com/LeoJeshua","instagram":null,"zhihu":null,"twitter":null,"email":"jiaxu.liu.ai@gmail.com"},"qrs":{"weixin":null}}},"plugins":{"feed":{"enable":false},"aplayer":{"enable":false,"type":"fixed","audios":[{"name":null,"artist":null,"url":null,"cover":null,"lrc":null}]},"mermaid":{"enable":false,"version":"11.4.1"}},"version":"2.8.5","navbar":{"auto_hide":true,"color":{"left":"#f78736","right":"#367df7","transparency":35},"width":{"home":"1200px","pages":"1000px"},"links":{"Home":{"path":"/","icon":"fa-regular fa-house"},"Archives":{"path":"/archives","icon":"fa-regular fa-archive"},"Categories":{"path":"/categories/","icon":"fa-regular fa-folder"},"Tags":{"icon":"fa-regular fa-tags","path":"/tags/"}},"search":{"enable":false,"preload":true}},"page_templates":{"friends_column":2,"tags_style":"cloud"},"home":{"sidebar":{"enable":true,"position":"right","first_item":"menu","announcement":"Aspiring to contribute to cutting-edge AI security research with a focus on offensive strategies to uncover and mitigate AI vulnerabilities.","show_on_mobile":true,"links":null},"article_date_format":"auto","excerpt_length":200,"categories":{"enable":true,"limit":3},"tags":{"enable":true,"limit":3}},"footerStart":"2024/12/20 21:33:00"};
    window.lang_ago = {"second":"%s seconds ago","minute":"%s minutes ago","hour":"%s hours ago","day":"%s days ago","week":"%s weeks ago","month":"%s months ago","year":"%s years ago"};
    window.data = {"masonry":false};
  </script>
    
    <!--- Fontawesome Part-->
    <link rel="stylesheet" href="https://registry.npmmirror.com/hexo-theme-redefine/2.8.5/files/source/fontawesome/fontawesome.min.css">
    <link rel="stylesheet" href="https://registry.npmmirror.com/hexo-theme-redefine/2.8.5/files/source/fontawesome/brands.min.css">
    <link rel="stylesheet" href="https://registry.npmmirror.com/hexo-theme-redefine/2.8.5/files/source/fontawesome/solid.min.css">
    <link rel="stylesheet" href="https://registry.npmmirror.com/hexo-theme-redefine/2.8.5/files/source/fontawesome/regular.min.css">
    
    
    
    
<meta name="generator" content="Hexo 7.3.0"><style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}
</style></head>



<body>
	<div class="progress-bar-container">
	

	
	<span class="pjax-progress-bar"></span>
	<!--        <span class="swup-progress-icon">-->
	<!--            <i class="fa-solid fa-circle-notch fa-spin"></i>-->
	<!--        </span>-->
	
</div>

<main class="page-container" id="swup">

	

	<div class="main-content-container flex flex-col justify-between min-h-dvh">
		<div class="main-content-header">
			<header class="navbar-container px-6 md:px-12">
    <div class="navbar-content transition-navbar ">
        <div class="left">
            
            <a class="logo-title" href="/">
                
                Academic Blog of LeoJeshua
                
            </a>
        </div>

        <div class="right">
            <!-- PC -->
            <div class="desktop">
                <ul class="navbar-list">
                    
                        
                            

                            <li class="navbar-item">
                                <!-- Menu -->
                                <a class=""
                                   href="/"
                                        >
                                    <i class="fa-regular fa-house fa-fw"></i>
                                    HOME
                                    
                                </a>

                                <!-- Submenu -->
                                
                            </li>
                    
                        
                            

                            <li class="navbar-item">
                                <!-- Menu -->
                                <a class=""
                                   href="/archives"
                                        >
                                    <i class="fa-regular fa-archive fa-fw"></i>
                                    ARCHIVES
                                    
                                </a>

                                <!-- Submenu -->
                                
                            </li>
                    
                        
                            

                            <li class="navbar-item">
                                <!-- Menu -->
                                <a class=""
                                   href="/categories/"
                                        >
                                    <i class="fa-regular fa-folder fa-fw"></i>
                                    CATEGORIES
                                    
                                </a>

                                <!-- Submenu -->
                                
                            </li>
                    
                        
                            

                            <li class="navbar-item">
                                <!-- Menu -->
                                <a class=""
                                   href="/tags/"
                                        >
                                    <i class="fa-regular fa-tags fa-fw"></i>
                                    TAGS
                                    
                                </a>

                                <!-- Submenu -->
                                
                            </li>
                    
                    
                </ul>
            </div>
            <!-- Mobile -->
            <div class="mobile">
                
                <div class="icon-item navbar-bar">
                    <div class="navbar-bar-middle"></div>
                </div>
            </div>
        </div>
    </div>

    <!-- Mobile sheet -->
    <div class="navbar-drawer h-dvh w-full absolute top-0 left-0 bg-background-color flex flex-col justify-between">
        <ul class="drawer-navbar-list flex flex-col px-4 justify-center items-start">
            
                
                    

                    <li class="drawer-navbar-item text-base my-1.5 flex flex-col w-full">
                        
                        <a class="py-1.5 px-2 flex flex-row items-center justify-between gap-1 hover:!text-primary active:!text-primary text-2xl font-semibold group border-b border-border-color hover:border-primary w-full "
                           href="/"
                        >
                            <span>
                                HOME
                            </span>
                            
                                <i class="fa-regular fa-house fa-sm fa-fw"></i>
                            
                        </a>
                        

                        
                    </li>
            
                
                    

                    <li class="drawer-navbar-item text-base my-1.5 flex flex-col w-full">
                        
                        <a class="py-1.5 px-2 flex flex-row items-center justify-between gap-1 hover:!text-primary active:!text-primary text-2xl font-semibold group border-b border-border-color hover:border-primary w-full "
                           href="/archives"
                        >
                            <span>
                                ARCHIVES
                            </span>
                            
                                <i class="fa-regular fa-archive fa-sm fa-fw"></i>
                            
                        </a>
                        

                        
                    </li>
            
                
                    

                    <li class="drawer-navbar-item text-base my-1.5 flex flex-col w-full">
                        
                        <a class="py-1.5 px-2 flex flex-row items-center justify-between gap-1 hover:!text-primary active:!text-primary text-2xl font-semibold group border-b border-border-color hover:border-primary w-full "
                           href="/categories/"
                        >
                            <span>
                                CATEGORIES
                            </span>
                            
                                <i class="fa-regular fa-folder fa-sm fa-fw"></i>
                            
                        </a>
                        

                        
                    </li>
            
                
                    

                    <li class="drawer-navbar-item text-base my-1.5 flex flex-col w-full">
                        
                        <a class="py-1.5 px-2 flex flex-row items-center justify-between gap-1 hover:!text-primary active:!text-primary text-2xl font-semibold group border-b border-border-color hover:border-primary w-full "
                           href="/tags/"
                        >
                            <span>
                                TAGS
                            </span>
                            
                                <i class="fa-regular fa-tags fa-sm fa-fw"></i>
                            
                        </a>
                        

                        
                    </li>
            

            
            
        </ul>

        <div class="statistics flex justify-around my-2.5">
    <a class="item tag-count-item flex flex-col justify-center items-center w-20" href="/tags">
        <div class="number text-2xl sm:text-xl text-second-text-color font-semibold">23</div>
        <div class="label text-third-text-color text-sm">Tags</div>
    </a>
    <a class="item tag-count-item flex flex-col justify-center items-center w-20" href="/categories">
        <div class="number text-2xl sm:text-xl text-second-text-color font-semibold">11</div>
        <div class="label text-third-text-color text-sm">Categories</div>
    </a>
    <a class="item tag-count-item flex flex-col justify-center items-center w-20" href="/archives">
        <div class="number text-2xl sm:text-xl text-second-text-color font-semibold">18</div>
        <div class="label text-third-text-color text-sm">Posts</div>
    </a>
</div>
    </div>

    <div class="window-mask"></div>

</header>


		</div>

		<div class="main-content-body transition-fade-up">
			

			<div class="main-content">
				<div class="post-page-container flex relative justify-between box-border w-full h-full">
	<div class="article-content-container">

		<div class="article-title relative w-full">
			
			
			
			<img src="https://cvpr.thecvf.com/static/core/img/CVPR-logo.svg" alt="Paper Collection of Safe Diffusion at CVPR 2025" class="w-full h-60 sm:h-72 md:h-80 object-cover sm:rounded-t-large dark:brightness-75" />
			
			<div class="w-full flex items-center absolute bottom-0 justify-start">
				<h1 class="article-title-cover text-center mx-6 my-6 text-second-text-color bg-background-color-transparent px-4 py-3 text-3xl sm:text-4xl md:text-5xl font-semibold backdrop-blur-lg rounded-xl border border-border-color ">Paper Collection of Safe Diffusion at CVPR 2025</h1>
			</div>
			
		</div>

		
		<div class="article-header flex flex-row gap-2 items-center px-2 sm:px-6 md:px-8">
			<div class="avatar w-[46px] h-[46px] flex-shrink-0 rounded-medium border border-border-color p-[1px]">
				<img src="/images/avatar.png">
			</div>
			<div class="info flex flex-col justify-between">
				<div class="author flex items-center">
					<span class="name text-default-text-color text-lg font-semibold">LeoJeshua</span>
					
					<span class="author-label ml-1.5 text-xs px-2 py-0.5 rounded-small text-third-text-color border border-shadow-color-1">Lv3</span>
					
				</div>
				<div class="meta-info">
					<div class="article-meta-info">
    <span class="article-date article-meta-item">
        <i class="fa-regular fa-pen-fancy"></i>&nbsp;
        <span class="desktop">2025-02-26 15:49:09</span>
        <span class="mobile">2025-02-26 15:49:09</span>
        <span class="hover-info">Created</span>
    </span>
    
        <span class="article-date article-meta-item">
            <i class="fa-regular fa-wrench"></i>&nbsp;
            <span class="desktop">2025-11-14 14:23:47</span>
            <span class="mobile">2025-11-14 14:23:47</span>
            <span class="hover-info">Updated</span>
        </span>
    

    
        <span class="article-categories article-meta-item">
            <i class="fa-regular fa-folders"></i>&nbsp;
            <ul>
                
                
                    
                        
                        <li>
                            <a href="/categories/AI/">AI</a>&nbsp;
                        </li>
                    
                    
                
                    
                        
                            <li>></li>
                        
                        <li>
                            <a href="/categories/AI/Security-in-AI/">Security in AI</a>&nbsp;
                        </li>
                    
                    
                
                    
                        
                            <li>></li>
                        
                        <li>
                            <a href="/categories/AI/Security-in-AI/DMs/">DMs</a>&nbsp;
                        </li>
                    
                    
                
            </ul>
        </span>
    
    
        <span class="article-tags article-meta-item">
            <i class="fa-regular fa-tags"></i>&nbsp;
            <ul>
                
                    <li>
                        <a href="/tags/DMs/">DMs</a>&nbsp;
                    </li>
                
                    <li>
                        | <a href="/tags/Paper-Collection/">Paper Collection</a>&nbsp;
                    </li>
                
                    <li>
                        | <a href="/tags/CVPR/">CVPR</a>&nbsp;
                    </li>
                
            </ul>
        </span>
    

    
    
        <span class="article-wordcount article-meta-item">
            <i class="fa-regular fa-typewriter"></i>&nbsp;<span>7.8k Words</span>
        </span>
    
    
        <span class="article-min2read article-meta-item">
            <i class="fa-regular fa-clock"></i>&nbsp;<span>27 Mins</span>
        </span>
    
    
        <span class="article-pv article-meta-item">
            <i class="fa-regular fa-eye"></i>&nbsp;<span id="busuanzi_value_page_pv"></span>
        </span>
    
</div>

				</div>
			</div>
		</div>
		

		


		<div class="article-content markdown-body px-2 sm:px-6 md:px-8 pb-8">
			<h1 id="CVPR-2025"><a href="#CVPR-2025" class="headerlink" title="CVPR 2025"></a>CVPR 2025</h1><p>Submission Deadline: 2024.11.15</p>
<p>Official Site:</p>
<ul>
<li><a class="link" target="_blank" rel="noopener" href="https://cvpr.thecvf.com/virtual/2025/papers.html">CVPR 2025 Papers<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
</ul>
<p>WeChat Article:</p>
<ul>
<li><a class="link" target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/PWHZr6D4oQiZ-6c-gHA3tw">我用Gemini处理了28篇CVPR 25文章——看看LLM怎么解读CVPR最新T2I动向<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
</ul>
<h2 id="Attack"><a href="#Attack" class="headerlink" title="Attack"></a>Attack</h2><h3 id="Adversarial-Attack"><a href="#Adversarial-Attack" class="headerlink" title="Adversarial Attack"></a>Adversarial Attack</h3><h4 id="FastProtect"><a href="#FastProtect" class="headerlink" title="FastProtect"></a>FastProtect</h4><p><em>Nearly Zero-Cost Protection Against Mimicry by Personalized Diffusion Models</em></p>
<ul>
<li>TL;DR: 针对DMs的几乎零开销的实时的图像保护方法</li>
<li><a class="link" target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content/CVPR2025/papers/Ahn_Nearly_Zero-Cost_Protection_Against_Mimicry_by_Personalized_Diffusion_Models_CVPR_2025_paper.pdf">pdf<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li><a class="link" target="_blank" rel="noopener" href="https://cvpr.thecvf.com/virtual/2025/poster/33351">poster<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li><a class="link" target="_blank" rel="noopener" href="https://youtu.be/IV9hoKMgX1Q">video<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><blockquote>
<p>扩散模型的最新进展彻底改变了图像生成，但也带来了滥用的风险，例如复制艺术品或生成深度伪造作品。<br>现有的图像保护方法虽然有效，但难以在保护效果(protection performance)、不可见性(invisibility)和延迟(inference time)之间取得平衡，从而限制了实际应用。<br>我们引入 <strong>扰动预训练</strong> 来降低延迟，并提出了一种 <strong>混合扰动方法</strong> ，该方法可以动态地适应输入图像，从而最大限度地减少性能下降。<br>我们新颖的训练策略 <strong>计算跨多个 VAE 特征空间的保护损失</strong> ，而推理阶段的 <strong>自适应定向保护则增强了鲁棒性和隐形性</strong>。<br>实验表明，该方法具有相当的protection performance，并且invisibility得到提升，inference time也显著缩短。</p>
</blockquote>
</li>
</ul>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20251014135435022.png"></p>
<h4 id="I2VGuard"><a href="#I2VGuard" class="headerlink" title="I2VGuard"></a>I2VGuard</h4><p><em>I2VGuard: Safeguarding Images against Misuse in Diffusion-based Image-to-Video Models</em></p>
<ul>
<li>TL;DR: 针对T2V DMs, 在空间和时间两个维度，利用对抗攻击保护图像（降低生成Video的质量）</li>
<li><a class="link" target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content/CVPR2025/papers/Gui_I2VGuard_Safeguarding_Images_against_Misuse_in_Diffusion-based_Image-to-Video_Models_CVPR_2025_paper.pdf">pdf<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li><a class="link" target="_blank" rel="noopener" href="https://cvpr.thecvf.com/virtual/2025/poster/35251">poster<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><blockquote>
<p>图像转视频生成领域的最新进展使得静态图像的动画化成为可能，并提供了像素级的可控性。虽然这些模型在将单幅图像转换为生动动态视频方面拥有巨大潜力，但它们也存在滥用风险，可能影响隐私、安全和版权保护。<br>本文提出了一种新颖的方法，<strong>对图像施加难以察觉的扰动来降低生成视频的质量，从而保护图像免遭白盒图像转视频扩散模型的滥用。</strong> 具体而言，我们将该方法作为一种对抗性攻击，结合了空间、时间和扩散攻击模块。<strong>空间攻击</strong> 将图像特征从其原始分布转移到质量较低的目标分布，从而降低了视觉保真度。<strong>时间攻击</strong> 通过干扰引导运动生成的时间注意力图来破坏连贯运动。<br>为了增强我们的方法在不同模型中的鲁棒性，我们进一步提出了 <strong>一个利用对比损失的扩散攻击模块</strong> 。我们的方法可以轻松地与主流的基于扩散的 I2V 模型集成。<br>在 SVD、CogVideoX 和 ControlNeXt 上进行的大量实验表明，我们的方法会显著降低生成质量（包括视觉清晰度和运动一致性），同时仅会在图像中引入极少的伪影。据我们所知，我们是首个出于安全目的探索T2V对抗攻击的团队。</p>
</blockquote>
</li>
</ul>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20251014190103177.png"></p>
<h3 id="Data-Poisoning-Attack"><a href="#Data-Poisoning-Attack" class="headerlink" title="Data Poisoning Attack"></a>Data Poisoning Attack</h3><h4 id="Silent-Branding-Attack"><a href="#Silent-Branding-Attack" class="headerlink" title="Silent Branding Attack"></a>Silent Branding Attack</h4><p><em>Silent Branding Attack: Trigger-free Data Poisoning Attack on Text-to-Image Diffusion Models</em></p>
<ul>
<li>TL;DR: 一种数据投毒方法，让模型生成的图片包含 specific brand logo，并且不需要 text trigger。</li>
<li><a class="link" target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content/CVPR2025/papers/Jang_Silent_Branding_Attack_Trigger-free_Data_Poisoning_Attack_on_Text-to-Image_Diffusion_CVPR_2025_paper.pdf">pdf<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li><a class="link" target="_blank" rel="noopener" href="https://cvpr.thecvf.com/virtual/2025/poster/35225">poster<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li><a class="link" target="_blank" rel="noopener" href="https://silent-branding.github.io/">webpage<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><blockquote>
<p>文本到图像的扩散模型在从文本提示生成高质量内容方面取得了显著成功。然而，由于它们依赖于公开数据，并且为了进行微调而共享数据，这些模型尤其容易受到数据中毒攻击。<br>本文提出了一种名为 <strong>“静默品牌攻击”（Silent Branding Attack）</strong> 的新型数据中毒方法，它能够 <strong>操纵T2I DMs，生成包含特定品牌标识或符号的图像，而无需任何文本触发。</strong><br>我们发现，<strong>当某些视觉模式在训练数据中重复出现时，即使没有提示，模型也能学会在输出中自然地重现这些模式</strong>。利用这一特性，我们开发了一种 <strong>自动化数据中毒算法，该算法可以不显眼地将标识注入原始图像中，确保它们自然融合且不被检测到。</strong> 在此中毒数据集上训练的模型能够生成包含标识的图像，而不会降低图像质量或文本对齐。<br>我们在大规模高质量图像数据集和风格个性化数据集上，通过两种实际设置实验验证了我们的静默品牌攻击，即使没有特定的文本触发，也能获得很高的成功率。人工评估和包括徽标检测在内的定量指标表明，我们的方法可以隐秘地嵌入徽标。</p>
</blockquote>
</li>
</ul>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20251014151718634.png"></p>
<h3 id="MIA"><a href="#MIA" class="headerlink" title="MIA"></a>MIA</h3><h4 id="CDI-Copyrighted-Data-Identification"><a href="#CDI-Copyrighted-Data-Identification" class="headerlink" title="CDI (Copyrighted Data Identification)"></a>CDI (Copyrighted Data Identification)</h4><p><em>CDI: Copyrighted Data Identification in Diffusion Models</em></p>
<ul>
<li><a class="link" target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content/CVPR2025/papers/Dubinski_CDI_Copyrighted_Data_Identification_in_Diffusion_Models_CVPR_2025_paper.pdf">pdf<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li><a class="link" target="_blank" rel="noopener" href="https://cvpr.thecvf.com/virtual/2025/poster/34687">poster<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li><a class="link" target="_blank" rel="noopener" href="https://youtu.be/eWr2KGhx0Tw">video<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><blockquote>
<p>扩散模型 (DMs) 的训练得益于海量且多样化的数据集。由于这些数据通常是未经数据所有者许可从互联网上抓取的，这引发了人们对版权和知识产权保护的担忧。<br>虽然对于由 DMs 在推理时完美重建的训练样本，数据的（非法）使用很容易被检测到，但当可疑 DMs 的输出不是近似副本时，数据所有者很难验证他们的数据是否用于训练。从概念上讲，成员推断攻击 (MIA) 可以检测给定数据点是否在训练期间被使用，它是解决这一挑战的合适工具。然而，我们证明现有的 MIA 不足以在大型、最先进的 DMs 中可靠地确定单个图像的成员资格。<br>为了克服这一限制，我们提出了 <strong>CDI，一个供数据所有者识别其数据集是否用于训练给定 DMs 的框架。</strong><br>CDI 依赖于 <strong>数据集推断技术</strong>，即 CDI 并非使用来自单个数据点的成员资格信号，而是利用了这样一个事实：<strong>大多数数据所有者（例如图片库提供商、视觉媒体公司，甚至个人艺术家）都拥有包含多个公开data points的数据集，这些data points可能全部用于训练特定的 DMs 。</strong><br>通过选择性地聚合来自现有 MIAs 的信号，并使用新的人工方法提取这些数据集的特征，将其输入评分模型，并进行严格的统计测试，CDI 允许数据所有者 <strong>仅使用 70 个 data points，以超过 99% 的置信度</strong> 识别其数据是否被用于训练特定的数据挖掘模型 (DM)。因此，CDI 是数据所有者对其版权数据被非法使用进行索赔的有力工具。</p>
</blockquote>
</li>
</ul>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20251014143944627.png"></p>
<h3 id="Bias"><a href="#Bias" class="headerlink" title="Bias"></a>Bias</h3><h4 id="IBI-Implicit-Bias-Injection-Attacks"><a href="#IBI-Implicit-Bias-Injection-Attacks" class="headerlink" title="IBI (Implicit Bias Injection Attacks)"></a>IBI (Implicit Bias Injection Attacks)</h4><p><em>Implicit Bias Injection Attacks against Text-to-Image Diffusion Models</em></p>
<ul>
<li><a class="link" target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content/CVPR2025/papers/Huang_Implicit_Bias_Injection_Attacks_against_Text-to-Image_Diffusion_Models_CVPR_2025_paper.pdf">pdf<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li><a class="link" target="_blank" rel="noopener" href="https://cvpr.thecvf.com/virtual/2025/poster/34474">poster<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><blockquote>
<p>文本转图像扩散模型 (T2I DMs) 的普及使得人工智能生成的图像在日常生活中日益常见。然而，存在偏见的 T2I 模型可能会生成具有特定倾向的内容，从而可能影响人们的感知。故意利用这些偏见可能会向公众传递误导性信息。<br>目前对偏见的研究主要针对具有可识别视觉模式的显性偏见，例如肤色和性别。<br>本文介绍了 <strong>一种新型的隐性偏见，它缺乏显性视觉特征，但可以在不同的语义语境中以多种方式表现出来。</strong> 这种微妙且多变的特性使得这种偏见难以检测、易于传播，并且能够适应各种场景。<br>我们进一步提出了一个针对 T2I 扩散模型的 <strong>隐性偏见注入攻击框架 (IBI-Attacks)，该框架通过在提示嵌入空间中预先计算一个通用的偏见方向，并根据不同的输入自适应地调整它。</strong> 我们的攻击模块可以无缝集成到预训练的扩散模型中，即插即用，无需直接操作用户输入或重新训练模型。<br>大量实验验证了我们的方案在保留原始语义的同时，通过微妙而多样的修改引入偏差的有效性。我们的攻击在各种场景中的强大隐蔽性和可转移性进一步强调了我们的方法的重要性。</p>
</blockquote>
</li>
</ul>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20251008004029738.png"></p>
<h3 id="Watermarks"><a href="#Watermarks" class="headerlink" title="Watermarks"></a>Watermarks</h3><h4 id="Black-Box-Forgery-Attacks-on-Semantic-Watermarks"><a href="#Black-Box-Forgery-Attacks-on-Semantic-Watermarks" class="headerlink" title="Black-Box Forgery Attacks on Semantic Watermarks"></a>Black-Box Forgery Attacks on Semantic Watermarks</h4><p><em>Black-Box Forgery Attacks on Semantic Watermarks for Diffusion Models</em></p>
<ul>
<li>TL;DR: 黑盒条件下 伪造 语义水印</li>
<li><a class="link" target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content/CVPR2025/papers/Muller_Black-Box_Forgery_Attacks_on_Semantic_Watermarks_for_Diffusion_Models_CVPR_2025_paper.pdf">pdf<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li><a class="link" target="_blank" rel="noopener" href="https://cvpr.thecvf.com/virtual/2025/poster/34820">poster<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li><a class="link" href="ttps://github.com/and-mill/semantic-forgery">code<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><blockquote>
<p>将水印集成到潜在扩散模型 (LDMs) 的生成过程中，可以简化生成内容的检测和归因。<br>语义水印，例如树形年轮(Tree-Rings)和高斯阴影(Gaussian Shading)，代表了一类新颖的水印技术，易于实现，并且对各种扰动具有高度的鲁棒性。<br>然而，我们的工作揭示了 <strong>语义水印的一个根本安全漏洞</strong> 。我们表明，<strong>攻击者可以利用不相关的模型，即使使用不同的潜在空间和架构（UNet 与 DiT），也能执行强大且逼真的伪造攻击</strong>。<br>具体来说，我们设计了 <strong>两种水印伪造攻击</strong> 。第一种攻击通过 <strong>在不相关的 LDMs 中操纵任意图像的潜在表示，使其更接近带水印图像的潜在表示(Imprint-F)</strong> ，从而将目标水印嵌入真实图像中。我们还表明，该技术可用于去除水印(Imprint-R)。第二种攻击通过 **反转带水印图像并使用任意提示重新生成它，来生成带有目标水印的新图像(Reprompt)**。<br>两种攻击都只需要一张带有目标水印的参考图像。总而言之，我们的研究结果质疑了语义水印的适用性，因为攻击者在现实条件下很容易伪造或移除这些水印。</p>
</blockquote>
</li>
</ul>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20251014144622223.png"></p>
<h2 id="Defence"><a href="#Defence" class="headerlink" title="Defence"></a>Defence</h2><h3 id="Guidence"><a href="#Guidence" class="headerlink" title="Guidence"></a>Guidence</h3><h4 id="DAG-Detect-and-Guide"><a href="#DAG-Detect-and-Guide" class="headerlink" title="DAG (Detect-and-Guide)"></a>DAG (Detect-and-Guide)</h4><p><em>Detect-and-Guide: Self-regulation of Diffusion Models for Safe Text-to-Image Generation</em></p>
<ul>
<li><a class="link" target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content/CVPR2025/papers/Li_Detect-and-Guide_Self-regulation_of_Diffusion_Models_for_Safe_Text-to-Image_Generation_via_CVPR_2025_paper.pdf">pdf<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li><a class="link" target="_blank" rel="noopener" href="https://cvpr.thecvf.com/virtual/2025/poster/32690">poster<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><blockquote>
<p>文本到图像的扩散模型在合成任务中取得了最先进的结果； 然而，人们越来越担心它们可能被滥用来创建有害内容。为了减轻这些风险，人们开发了事后模型干预技术，例如概念遗忘和安全指导。<br>然而，微调模型权重或调整扩散模型的隐藏状态以一种不可解释的方式进行，使得不清楚中间变量的哪一部分负责不安全的生成。当从复杂的多概念提示中删除有害概念时，这些干预措施会严重影响采样轨迹，从而阻碍了它们在现实世界中的实际使用。尽管它们在单一概念提示上有效，但当前的方法仍然面临着挑战，因为它们很难在不破坏良性概念语义的情况下精确删除有害概念。<br>在这项工作中，我们提出了 <strong>检测和引导（DAG）</strong> 安全生成框架， <strong>利用扩散模型的内部知识在采样过程中进行自我诊断和细粒度的自我调节。</strong><br>DAG首先使用优化标记的细化交叉注意力图从噪声潜伏中检测有害概念，然后应用具有自适应强度和编辑区域的安全引导来否定不安全生成。优化只需要小型注释数据集，可以提供具有普遍性和概念特异性的精确检测图。 此外，<strong>DAG不需要对扩散模型进行微调</strong>，因此不会对其生成多样性造成损失。<br>擦除色情内容的实验表明，DAG 实现了最先进的安全生成性能，在多概念现实世界提示上平衡了危害缓解和文本跟踪性能。</p>
</blockquote>
</li>
</ul>
<h4 id="Concept-Replacer"><a href="#Concept-Replacer" class="headerlink" title="Concept Replacer"></a>Concept Replacer</h4><p>Concept Replacer: Replacing Sensitive Concepts in Diffusion Models via Precision Localization</p>
<ul>
<li><a class="link" target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_Concept_Replacer_Replacing_Sensitive_Concepts_in_Diffusion_Models_via_Precision_CVPR_2025_paper.pdf">pdf<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li><a class="link" target="_blank" rel="noopener" href="https://cvpr.thecvf.com/virtual/2025/poster/33513">poster<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><blockquote>
<p>随着大规模扩散模型的不断发展，它们在生成高质量图像方面表现出色，但同时也常常会生成一些不受欢迎的内容，例如色情或暴力内容。<br>现有的概念移除方法通常会引导图像生成过程，但可能会无意中修改不相关的区域，从而导致与原始模型不一致。<br>我们提出了一种新的扩散模型中的<strong>目标概念替换方法</strong>，能够在不影响非目标区域的情况下移除特定概念。<br>我们的方法引入了 <strong>一个专用的概念定位器，用于在去噪过程中精确识别目标概念</strong> ，该定位器采用少样本学习进行训练，只需要极少的标记数据。在已识别的区域内，我们引入了一个无需训练的 <strong>双提示交叉注意力 (DPCA) 模块</strong> 来替换目标概念，确保对周围内容的干扰最小。<br>我们对我们的方法进行了 <strong>概念定位精度</strong> 和 <strong>替换效率</strong> 的评估。实验结果表明，我们的方法在目标概念定位方面取得了卓越的精度，并在对非目标区域影响最小的情况下进行了连贯的概念替换，优于现有方法。</p>
</blockquote>
</li>
</ul>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20251014133757225.png"></p>
<h3 id="Unlern"><a href="#Unlern" class="headerlink" title="Unlern"></a>Unlern</h3><h4 id="EraseDiff"><a href="#EraseDiff" class="headerlink" title="EraseDiff"></a>EraseDiff</h4><p><em>Erasing Undesirable Influence in Diffusion Models</em></p>
<ul>
<li><a class="link" target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content/CVPR2025/papers/Wu_Erasing_Undesirable_Influence_in_Diffusion_Models_CVPR_2025_paper.pdf">pdf<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li><a class="link" target="_blank" rel="noopener" href="https://cvpr.thecvf.com/virtual/2025/poster/33939">poster<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li>note: 考虑到“擦除<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.667ex;" xmlns="http://www.w3.org/2000/svg" width="2.608ex" height="2.213ex" role="img" focusable="false" viewBox="0 -683 1152.9 978"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D43F" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path></g><g data-mml-node="mi" transform="translate(714,-150) scale(0.707)"><path data-c="1D453" d="M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z"></path></g></g></g></g></svg></mjx-container>”和“保留<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.357ex;" xmlns="http://www.w3.org/2000/svg" width="2.45ex" height="1.902ex" role="img" focusable="false" viewBox="0 -683 1082.9 840.8"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D43F" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path></g><g data-mml-node="mi" transform="translate(714,-150) scale(0.707)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g></g></g></g></svg></mjx-container>”两个目标，对vanilla MOO（多目标优化）改进，变成contrained optimization problem（有natutral first-order solution）。解决了优化梯度冲突问题。<blockquote>
<p>扩散模型在生成高质量图像方面非常有效，但也存在风险，例如无意中生成 NSFW（不适合工作）内容。<br>尽管已经提出了各种技术来减轻扩散模型中的不良影响，同时保持整体性能，但在这些目标之间取得平衡仍然具有挑战性。<br>在这项工作中，我们引入了 EraseDiff，这是一种旨在 <strong>保留扩散模型对保留数据的效用，同时删除与要遗忘的数据相关的不需要的信息的算法。</strong><br>我们的方法使用值函数将此任务表述为约束优化问题，从而产生用于解决优化问题的自然一阶算法。通过改变生成过程以偏离地面实况去噪轨迹，我们更新保存参数，同时控制约束减少以确保有效擦除，从而达到最佳权衡。<br>大量的实验和与最先进算法的彻底比较表明，EraseDiff 有效地保持了模型的效用、功效和效率。</p>
</blockquote>
</li>
</ul>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20251008005106312.png"></p>
<h4 id="Localized-Concept-Erasure-GLoCE"><a href="#Localized-Concept-Erasure-GLoCE" class="headerlink" title="Localized Concept Erasure (GLoCE)"></a>Localized Concept Erasure (GLoCE)</h4><p><em>Localized Concept Erasure for Text-to-Image Diffusion Models Using Training-Free Gated Low-Rank Adaptation</em></p>
<ul>
<li><a class="link" target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content/CVPR2025/papers/Lee_Localized_Concept_Erasure_for_Text-to-Image_Diffusion_Models_Using_Training-Free_Gated_CVPR_2025_paper.pdf">pdf<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li><a class="link" target="_blank" rel="noopener" href="https://cvpr.thecvf.com/virtual/2025/poster/34742">poster<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><blockquote>
<p>基于微调的概念擦除已显示出良好的效果，它通过移除目标概念并保留剩余概念，防止文本到图像的扩散模型生成有害内容。为了在概念擦除后保持扩散模型的生成能力，需要仅移除图像中局部出现的目标概念所在的图像区域，而保留其他区域。<br>然而，现有技术通常会为了擦除出现在特定区域的局部目标概念而牺牲其他图像区域的保真度，从而降低图像生成的整体性能。<br>为了解决这些限制，我们首先引入了一个称为 <strong>Localized Concept Erasure</strong> 的框架，<strong>该框架允许仅删除图像中包含目标概念的特定区域，同时保留其他区域</strong>。<br>作为局部概念擦除的解决方案，我们提出了一种 <strong>training-free</strong> 的方法，称为 <strong>Gated Low-rank adaptation for Concept Erasure (GLoCE)</strong> ，该方法在扩散模型中注入了一个轻量级模块。GLoCE 由低秩矩阵和一个简单的门组成，仅由几个无需训练的概念生成步骤决定。通过将 GLoCE 直接应用于图像嵌入，并设计仅针对目标概念激活的门控，GLoCE 可以选择性地仅移除目标概念的区域，即使目标概念和剩余概念共存于图像中。<br>大量实验表明，GLoCE 不仅在擦除局部目标概念后提高了图像与文本提示的保真度，而且在有效性、特异性和稳健性方面也大幅超越现有技术，并且可以扩展到大规模概念擦除。</p>
</blockquote>
</li>
</ul>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20251013153220944.png"></p>
<h4 id="ACE-Anti-editing-Concept-Erasure"><a href="#ACE-Anti-editing-Concept-Erasure" class="headerlink" title="ACE (Anti-editing Concept Erasure)"></a>ACE (Anti-editing Concept Erasure)</h4><p><em>ACE: Anti-Editing Concept Erasure in Text-to-Image Models</em></p>
<ul>
<li><a class="link" target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_ACE_Anti-Editing_Concept_Erasure_in_Text-to-Image_Models_CVPR_2025_paper.pdf">pdf<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li><a class="link" target="_blank" rel="noopener" href="https://cvpr.thecvf.com/virtual/2025/poster/33574">poster<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li><a class="link" target="_blank" rel="noopener" href="https://github.com/120L020904/ACE">github<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><blockquote>
<p>文本到图像传播模型的最新进展极大地促进了高质量图像的生成，但也引发了人们对非法创建有害内容（例如受版权保护的图像）的担忧。<br>现有的概念擦除方法在防止提示中产生被擦除的概念方面取得了优异的效果，但在防止不必要的编辑方面通常表现不佳。<br>为了解决这个问题，我们提出了 <strong>一种 Anti-editing 的 Concept Erasure (ACE) 方法，它不仅在生成过程中擦除目标概念，还在编辑过程中将其过滤掉。</strong><br>具体而言，我们建议 <strong>在条件和非条件噪声预测中注入擦除指导</strong> ，使模型能够有效地防止在编辑和生成过程中产生擦除概念。此外， <strong>在训练过程中引入随机校正指导</strong> ，以解决无关概念的擦除问题。<br>我们使用代表性编辑方法（例如 <code>LEDITS++</code> 和 <code>MasaCtrl</code>）进行了擦除编辑实验，以擦除 IP 字符，结果表明，我们的 ACE 能够有效地在两种编辑类型中过滤掉目标概念。进一步的实验（删除显性概念和艺术风格）进一步证明了我们的 ACE 比最先进的方法表现更佳。我们的代码将公开发布。</p>
</blockquote>
</li>
</ul>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20251013153539968.png"></p>
<h4 id="STEREO-Search-Thoroughly-Enough-Robustly-Erase-Once"><a href="#STEREO-Search-Thoroughly-Enough-Robustly-Erase-Once" class="headerlink" title="STEREO (Search Thoroughly Enough, Robustly Erase Once)"></a>STEREO (Search Thoroughly Enough, Robustly Erase Once)</h4><p><em>STEREO: A Two-Stage Framework for Adversarially Robust Concept Erasing from Text-to-Image Diffusion Models</em> <code>Highlight</code></p>
<ul>
<li><a class="link" target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content/CVPR2025/papers/Srivatsan_STEREO_A_Two-Stage_Framework_for_Adversarially_Robust_Concept_Erasing_from_CVPR_2025_paper.pdf">pdf<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li><a class="link" target="_blank" rel="noopener" href="https://cvpr.thecvf.com/virtual/2025/poster/32792">poster<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><blockquote>
<p>大规模文本转图像扩散 (T2ID) 模型的快速普及引发了人们对其可能被滥用生成有害内容的严重担忧。尽管已经提出了许多从 T2ID 模型中擦除不良概念的方法，但它们常常会给人一种虚假的安全感，因为概念擦除模型 (CEM) 很容易被对抗性攻击欺骗，从而生成被擦除的概念。<br>尽管最近出现了一些 <strong>基于对抗性训练的鲁棒概念擦除方法</strong>，但它们为了获得鲁棒性，会牺牲实用性（良性概念的生成质量），并且/或者仍然容易受到高级嵌入空间攻击。这些局限性源于鲁棒 CEM 未能彻底搜索嵌入空间中的“盲点(blind spots)”。<br>为了弥补这一缺陷，我们提出了 <strong>STEREO，这是一个新颖的两阶段框架</strong>，它将对抗性训练作为鲁棒概念擦除的第一步，而非唯一步骤。<br>在第一阶段，<strong>Search Thoroughly Enough (STE)：使用对抗性训练作为漏洞识别机制</strong>，以进行足够彻底的搜索；在第二阶段，<strong>Robustly Erase Once (REO)：引入了一个基于锚点概念的(anchor-concept-based)组合目标，以鲁棒的方式一次性擦除目标概念，同时尽量减少模型效用的下降。</strong><br>我们将 STEREO 与 7 种最先进的概念擦除方法进行了对比，证明了其在抵御白盒、黑盒和高级嵌入空间攻击方面具有增强的鲁棒性，并且能够在很大程度上保留效用。</p>
</blockquote>
</li>
</ul>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20251013162042504.png"></p>
<h4 id="RIIDL-Responsible-Interpretable-Intermediate-Diffusion-Latents"><a href="#RIIDL-Responsible-Interpretable-Intermediate-Diffusion-Latents" class="headerlink" title="RIIDL (Responsible Interpretable Intermediate Diffusion Latents)"></a>RIIDL (Responsible Interpretable Intermediate Diffusion Latents)</h4><p><em>Plug-and-Play Interpretable Responsible Text-to-Image Generation via Dual-Space Multi-facet Concept Control</em></p>
<ul>
<li><a class="link" target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content/CVPR2025/papers/Azam_Plug-and-Play_Interpretable_Responsible_Text-to-Image_Generation_via_Dual-Space_Multi-facet_Concept_Control_CVPR_2025_paper.pdf">pdf<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li><a class="link" target="_blank" rel="noopener" href="https://cvpr.thecvf.com/virtual/2025/poster/33451">poster<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li><a class="link" target="_blank" rel="noopener" href="https://basim-azam.github.io/responsiblediffusion/">webpage<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><blockquote>
<p>围绕文本转图像 (T2I) 模型的伦理问题要求对生成内容进行全面控制。现有的针对负责任的 T2I 模型的这些问题的技术旨在使生成的内容公平安全（非暴力/明确）。然而，这些方法仍然局限于单独处理责任概念的各个方面，同时也缺乏可解释性。此外，它们通常需要修改原始模型，这会影响模型性能。<br>在本文中，我们提出了一种独特的技术，通过同时考虑广泛的概念来实现负责任的 T2I 生成，并且以可扩展的方式实现公平安全的内容生成。关键思想是 使用 <strong>外部的即插即用(plug-and-play)机制</strong> 蒸馏 target T2I pipeline ，该机制根据 target T2I pipeline 学习 the desired concepts 的 <strong>可解释的合成的责任空间(an interpretable composite responsible space)。</strong><br>我们使用 <strong>知识蒸馏(knowledge distillation) 和 概念白化(concept whitening)</strong> 来实现这一点。在推理时，学习到的空间用于调节生成内容。典型的 T2I 管道为我们的方法提供了两个插件点，即：<strong>文本嵌入空间</strong> 和 <strong>扩散模型潜在空间</strong>。<br>我们针对这两个方面开发了模块，并通过一系列强大的结果证明了我们方法的有效性。我们的代码和模型将在论文被接受后公开。</p>
</blockquote>
</li>
</ul>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20251013161422499.png"></p>
<h4 id="AdaVD-Adaptive-Vaule-Decomposer"><a href="#AdaVD-Adaptive-Vaule-Decomposer" class="headerlink" title="AdaVD (Adaptive Vaule Decomposer)"></a>AdaVD (Adaptive Vaule Decomposer)</h4><p><em>Precise, Fast, and Low-cost Concept Erasure in Value Space: Orthogonal Complement Matters</em></p>
<ul>
<li><a class="link" target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Precise_Fast_and_Low-cost_Concept_Erasure_in_Value_Space__CVPR_2025_paper.pdf">pdf<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li><a class="link" target="_blank" rel="noopener" href="https://cvpr.thecvf.com/virtual/2025/poster/34263">poster<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><blockquote>
<p>扩散模型成功实现了文本到图像的生成，这迫切需要以精确、及时且低成本的方式从预训练模型中擦除不需要的概念，例如版权、冒犯性和不安全的概念。概念擦除的双重需求要求在生成过程中精确删除目标概念（即erasure efficacy），同时对非目标内容生成的影响最小（即prior preservation）。<br>现有方法要么计算成本高昂，要么在维持擦除效率和先验保留之间的有效平衡方面面临挑战。<br>为了改进，我们提出了 <strong>一种精确、快速且低成本的概念擦除方法，称为 Adaptive Vaule Decomposer (AdaVD, 自适应的Value分解器)，它无需训练。</strong><br>该方法基于经典的 <strong>线性代数正交补运算，在扩散模型UNet中每个交叉注意层的值空间中实现。</strong> 设计了<strong>一种有效的移位因子，用于自适应地控制擦除强度，在不牺牲擦除效率的情况下增强先验保留。</strong><br>大量实验结果表明，所提出的 AdaVD 在单概念和多概念擦除方面均有效，与第二佳方法相比，先验保存率提高了 2 到 10 倍，同时，与基于训练和无需训练的现有技术相比，均达到了最佳或接近最佳的擦除效率。AdaVD 支持一系列扩散模型和下游图像生成任务，其代码即将公开。</p>
</blockquote>
</li>
</ul>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20251013163517981.png"></p>
<h4 id="FADE-Fine-grained-Attenuation-for-Diffusion-Erasure"><a href="#FADE-Fine-grained-Attenuation-for-Diffusion-Erasure" class="headerlink" title="FADE (Fine-grained Attenuation for Diffusion Erasure)"></a>FADE (Fine-grained Attenuation for Diffusion Erasure)</h4><p><em>Fine-Grained Erasure in Text-to-Image Diffusion-based Foundation Models</em></p>
<ul>
<li>TL;DR: 减少概念擦除时 对 邻接/相关概念 的影响</li>
<li><a class="link" target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content/CVPR2025/papers/Thakral_Fine-Grained_Erasure_in_Text-to-Image_Diffusion-based_Foundation_Models_CVPR_2025_paper.pdf">pdf<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li><a class="link" target="_blank" rel="noopener" href="https://cvpr.thecvf.com/virtual/2025/poster/33583">poster<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><blockquote>
<p>现有的文本转图像生成模型中的去学习算法在移除特定目标概念时，往往无法保留语义相关概念的知识——这一挑战被称为 <strong>adjacency(邻接)</strong> 。<br>为了解决这个问题，我们提出了<strong>FADE（Fine-grained Attenuation for Diffusion Erasure，细粒度衰减扩散擦除）</strong>，在扩散模型中引入了 <strong>adjacency-aware unlearning</strong> 。<br>FADE 包含两个组件：**(1) Concept Lattice（概念格）<strong>，用于识别相关概念的邻接集；</strong>(2) Mesh Modules（网格模块）**，采用结构化的擦除、邻接和引导损失组件组合。这些组件能够 <strong>精确擦除目标概念，同时保持相关和不相关概念之间的保真度。</strong><br>通过在 Stanford Dogs、Oxford Flowers、CUB、I2P、Imagenette 和 ImageNet-1k 等数据集上进行评估，FADE 有效地删除了目标概念，对相关概念的影响最小，与最先进的方法相比，保留性能至少提高了 12%。</p>
</blockquote>
</li>
</ul>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20251014145855328.png"></p>
<h4 id="TIU-The-Illusion-of-Unlearning"><a href="#TIU-The-Illusion-of-Unlearning" class="headerlink" title="TIU (The Illusion of Unlearning)"></a>TIU (The Illusion of Unlearning)</h4><p><em>The Illusion of Unlearning: The Unstable Nature of Machine Unlearning in Text-to-Image Diffusion Models</em></p>
<ul>
<li><a class="link" target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content/CVPR2025/papers/George_The_Illusion_of_Unlearning_The_Unstable_Nature_of_Machine_Unlearning_CVPR_2025_paper.pdf">pdf<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li><a class="link" target="_blank" rel="noopener" href="https://cvpr.thecvf.com/virtual/2025/poster/33746">poster<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li><a class="link" target="_blank" rel="noopener" href="https://github.com/NGK2110/TIU">github<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><blockquote>
<p>文生图模型，例如Stable Diffusion、DALL·E 和 Midjourney，近年来人气飙升。然而，这些模型基于海量数据进行训练，其中可能包含未经许可使用的私密、露骨或受版权保护的内容，这引发了严重的法律和伦理问题。鉴于近期旨在保护个人数据隐私的法规，旨在从模型中移除特定概念的Machine Unlearn(MU)方法激增。<br>然而，我们发现这些Unlearn技术存在一个关键缺陷：<strong>即使使用一般或不相关的提示，当模型进行微调时，已学习的概念仍会重新出现。</strong><br>本文通过广泛的研究，首次揭示了 <strong>文生图DMs中现有Unlearn方法的不稳定性。</strong><br>我们提出了<strong>一个包含若干指标的框架</strong>，用于分析现有Unlearn方法的稳定性。<br>此外，本文对基于映射的Unlearn方法不稳定性的原因进行了初步探讨，这些见解可以指导未来研究更稳健的Unlearn技术。提供了用于实施所提框架的匿名代码。</p>
</blockquote>
</li>
</ul>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20251013155034971.png"></p>
<h4 id="Six-CD-Benchmark"><a href="#Six-CD-Benchmark" class="headerlink" title="Six-CD Benchmark"></a>Six-CD Benchmark</h4><p><em>Six-CD: Benchmarking Concept Removals for Text-to-image Diffusion Models</em></p>
<ul>
<li>TL;DR: 概念擦除基准测试数据集/指标</li>
<li><a class="link" target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content/CVPR2025/papers/Ren_Six-CD_Benchmarking_Concept_Removals_for_Text-to-image_Diffusion_Models_CVPR_2025_paper.pdf">pdf<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li><a class="link" target="_blank" rel="noopener" href="https://cvpr.thecvf.com/virtual/2025/poster/34826">poster<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><blockquote>
<p>文本转图像 (T2I) 扩散模型在生成与文本提示紧密对应的图像方面展现出卓越的能力。然而，T2I 扩散模型的进步也带来了巨大的风险，因为这些模型可能被用于恶意目的，例如生成包含暴力或裸体的图像，或在不恰当的语境中创建未经授权的公众人物肖像。<br>为了降低这些风险，一些概念移除方法被提出。这些方法旨在修改扩散模型，以防止生成恶意和不受欢迎的概念。尽管做出了这些努力，现有研究仍面临一些挑战：(1) 缺乏对综合数据集的一致性比较；(2) 有害和裸体概念中的提示无效；(3) 忽视了对包含恶意概念的提示中生成良性部分的能力的评估。<br>为了弥补这些不足，我们建议通过引入一个 <strong>新数据集 Six-CD</strong> 以及一个 <strong>全新的评估指标</strong> 来对概念移除方法进行基准测试。<br>在该基准测试中，我们对概念移除进行了全面的评估，实验观察和讨论为该领域提供了宝贵的见解。</p>
</blockquote>
</li>
</ul>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20251014145656219.png"><br><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20251014145628765.png"></p>
<h3 id="Bias-1"><a href="#Bias-1" class="headerlink" title="Bias"></a>Bias</h3><h4 id="MPR-Multi-group-Proportional-Representation"><a href="#MPR-Multi-group-Proportional-Representation" class="headerlink" title="MPR (Multi-group Proportional Representation)"></a>MPR (Multi-group Proportional Representation)</h4><p><em>Multi-Group Proportional Representations for Text-to-Image Models</em></p>
<ul>
<li><a class="link" target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content/CVPR2025/papers/Jung_Multi-Group_Proportional_Representations_for_Text-to-Image_Models_CVPR_2025_paper.pdf">pdf<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li><a class="link" target="_blank" rel="noopener" href="https://cvpr.thecvf.com/virtual/2025/poster/34035">poster<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><blockquote>
<p>文本转图像生成模型可以根据文本描述创建生动逼真的图像。随着这些模型的普及，它们也暴露出新的担忧，即它们能否代表不同的人口群体、传播刻板印象以及抹去少数群体的形象。<br>尽管人们越来越关注人工智能 (AI) 的“安全”和“负责任”设计，但目前尚无成熟的方法来系统地测量和控制大型图像生成模型中的表征损害。<br>本文介绍了一个 <strong>用于测量T2IDMs生成的图像中 交叉群体表征 的全新框架。</strong><br>我们提出了一种新的 <strong>多群体均衡的表征 (MPR) 指标</strong> 的应用，以严格评估图像生成中的表征损害，并 <strong>开发了一种算法来优化生成模型以达到该表征指标</strong>。MPR 评估生成模型生成的图像中 <strong>给定人群群体表征统计数据的最坏情况偏差</strong>，从而允许根据用户需求进行灵活且针对特定情境的测量。<br>通过实验，我们证明 MPR 可以 <strong>有效地测量多个交叉群体的代表性统计数据</strong>，并且当用作训练目标时，可以 <strong>引导模型在保持生成质量的同时，实现跨人口群体的更平衡的生成。</strong></p>
</blockquote>
</li>
</ul>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20251013164853941.png"></p>
<h4 id="Rethinking-Training-for-De-biasing-Text-to-Image-Generation"><a href="#Rethinking-Training-for-De-biasing-Text-to-Image-Generation" class="headerlink" title="Rethinking Training for De-biasing Text-to-Image Generation"></a>Rethinking Training for De-biasing Text-to-Image Generation</h4><p><em>Rethinking Training for De-biasing Text-to-Image Generation: Unlocking the Potential of Stable Diffusion</em></p>
<ul>
<li><a class="link" target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content/CVPR2025/papers/Kim_Rethinking_Training_for_De-biasing_Text-to-Image_Generation_Unlocking_the_Potential_of_CVPR_2025_paper.pdf">pdf<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li><a class="link" target="_blank" rel="noopener" href="https://cvpr.thecvf.com/virtual/2025/poster/34534">poster<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><blockquote>
<p>文本转图像模型（例如稳定扩散）的最新进展显示出明显的人口统计学偏差。<br>现有的去偏差技术严重依赖于额外的训练，这会带来高昂的计算成本，并可能损害核心图像生成功能。这阻碍了它们在实际应用中的广泛应用。<br>在本文中，我们探索了稳定扩散在 <strong>无需额外训练的情况下降低偏差的潜力</strong> ，这一潜力被人们忽视。<br>通过分析，我们发现与少数族裔属性相关的初始噪声构成了稳定扩散中“少数族裔区域”降低偏差的机会。为了释放这一潜力，我们提出了 <strong>一种名为 “弱引导(weak guidance)” 的新型去偏差方法</strong>，该方法经过精心设计，可以 <strong>在不损害语义完整性的情况下将随机噪声引导至少数族裔区域。</strong><br>通过对不同版本稳定扩散的分析和实验，我们证明了我们提出的方法能够在无需额外训练的情况下有效降低偏差，既实现了效率，又保留了核心图像生成功能。</p>
</blockquote>
</li>
</ul>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20251014135522383.png"></p>
<h3 id="Watermarks-1"><a href="#Watermarks-1" class="headerlink" title="Watermarks"></a>Watermarks</h3><h4 id="SleeperMark"><a href="#SleeperMark" class="headerlink" title="SleeperMark"></a>SleeperMark</h4><p><em>SleeperMark: Towards Robust Watermark against Fine-Tuning Text-to-image Diffusion Models</em></p>
<ul>
<li>TL;DR: 模型在适应新任务时很容易忘记先前学习的水印知识，SleeperMark提出一种抗微调的水印嵌入方法</li>
<li><a class="link" target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_SleeperMark_Towards_Robust_Watermark_against_Fine-Tuning_Text-to-image_Diffusion_Models_CVPR_2025_paper.pdf">pdf<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li><a class="link" target="_blank" rel="noopener" href="https://cvpr.thecvf.com/virtual/2025/poster/33491">poster<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a><blockquote>
<p>大规模文本转图像 (T2I) 扩散模型的最新进展已赋能各种下游应用，包括风格定制、主题驱动的个性化和条件生成。由于 T2I 模型需要大量数据和计算资源进行训练，因此它们对其合法所有者而言构成了高价值的知识产权 (IP)，但也使其成为攻击者未经授权进行微调的目标，攻击者试图利用这些模型进行定制化、通常有利可图的应用。<br>现有的扩散模型 IP 保护方法通常包括嵌入水印模式，然后通过检查生成的输出或检查模型的特征空间来验证所有权。然而，在实际场景中，当嵌入水印的模型进行微调，且在验证过程中无法访问特征空间（即黑盒设置）时，这些技术本质上是无效的。<br>模型在适应新任务时很容易忘记先前学习的水印知识。为了应对这一挑战，我们提出了 <strong>SleeperMark</strong>，这是一个旨在 <strong>将弹性水印嵌入 T2I 扩散模型的新颖框架</strong> 。<br>SleeperMark 明确 <strong>引导模型将水印信息与其学习到的语义概念分离，从而使模型能够保留嵌入的水印，同时继续针对新的下游任务进行微调。</strong><br>我们进行了大量的实验，证明了 SleeperMark 在各种类型的扩散模型（包括潜在扩散模型（例如稳定扩散）和像素扩散模型（例如 DeepFloyd-IF））中的有效性，并展现出<strong>对下游微调和图像及模型层面各种攻击的稳健性，同时对模型的生成能力影响极小。</strong></p>
</blockquote>
</li>
</ul>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20251014151057735.png"></p>

		</div>

		
		<div class="post-copyright-info w-full my-8 px-2 sm:px-6 md:px-8">
			<div class="article-copyright-info-container">
    <ul>
        <li><strong>Title:</strong> Paper Collection of Safe Diffusion at CVPR 2025</li>
        <li><strong>Author:</strong> LeoJeshua</li>
        <li><strong>Created at
                :</strong> 2025-02-26 15:49:09</li>
        
            <li>
                <strong>Updated at
                    :</strong> 2025-11-14 14:23:47
            </li>
        
        <li>
            <strong>Link:</strong> https://leojeshua.github.io/DMs/Paper-Collection-of-Safe-Diffusion_CVPR-2025/
        </li>
        <li>
            <strong>
                License:
            </strong>
            

            
                This work is licensed under <a class="license" target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0">CC BY-NC-SA 4.0</a>.
            
        </li>
    </ul>
</div>

		</div>
		

		
		<ul class="post-tags-box text-lg mt-1.5 flex-wrap justify-center flex md:hidden">
			
			<li class="tag-item mx-0.5">
				<a href="/tags/DMs/">#DMs</a>&nbsp;
			</li>
			
			<li class="tag-item mx-0.5">
				<a href="/tags/Paper-Collection/">#Paper Collection</a>&nbsp;
			</li>
			
			<li class="tag-item mx-0.5">
				<a href="/tags/CVPR/">#CVPR</a>&nbsp;
			</li>
			
		</ul>
		

		

		
		<div class="article-nav my-8 flex justify-between items-center px-2 sm:px-6 md:px-8">
			
			<div class="article-prev border-border-color shadow-redefine-flat shadow-shadow-color-2 rounded-medium px-4 py-2 hover:shadow-redefine-flat-hover hover:shadow-shadow-color-2">
				<a class="prev" rel="prev" href="/NLP/LLMs/">
					<span class="left arrow-icon flex justify-center items-center">
						<i class="fa-solid fa-chevron-left"></i>
					</span>
					<span class="title flex justify-center items-center">
						<span class="post-nav-title-item truncate max-w-48">LLMs(Large Language Models) 学习笔记</span>
						<span class="post-nav-item">Prev posts</span>
					</span>
				</a>
			</div>
			
			
			<div class="article-next border-border-color shadow-redefine-flat shadow-shadow-color-2 rounded-medium px-4 py-2 hover:shadow-redefine-flat-hover hover:shadow-shadow-color-2">
				<a class="next" rel="next" href="/CV/Steganography/">
					<span class="title flex justify-center items-center">
						<span class="post-nav-title-item truncate max-w-48">Image Steganography</span>
						<span class="post-nav-item">Next posts</span>
					</span>
					<span class="right arrow-icon flex justify-center items-center">
						<i class="fa-solid fa-chevron-right"></i>
					</span>
				</a>
			</div>
			
		</div>
		


		
	</div>

	
	<div class="toc-content-container">
		<div class="post-toc-wrap">
	<div class="post-toc">
		<div class="toc-title">On this page</div>
		<div class="page-title">Paper Collection of Safe Diffusion at CVPR 2025</div>
		<ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#CVPR-2025"><span class="nav-text">CVPR 2025</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Attack"><span class="nav-text">Attack</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Adversarial-Attack"><span class="nav-text">Adversarial Attack</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#FastProtect"><span class="nav-text">FastProtect</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#I2VGuard"><span class="nav-text">I2VGuard</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Data-Poisoning-Attack"><span class="nav-text">Data Poisoning Attack</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Silent-Branding-Attack"><span class="nav-text">Silent Branding Attack</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#MIA"><span class="nav-text">MIA</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#CDI-Copyrighted-Data-Identification"><span class="nav-text">CDI (Copyrighted Data Identification)</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Bias"><span class="nav-text">Bias</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#IBI-Implicit-Bias-Injection-Attacks"><span class="nav-text">IBI (Implicit Bias Injection Attacks)</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Watermarks"><span class="nav-text">Watermarks</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Black-Box-Forgery-Attacks-on-Semantic-Watermarks"><span class="nav-text">Black-Box Forgery Attacks on Semantic Watermarks</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Defence"><span class="nav-text">Defence</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Guidence"><span class="nav-text">Guidence</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#DAG-Detect-and-Guide"><span class="nav-text">DAG (Detect-and-Guide)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Concept-Replacer"><span class="nav-text">Concept Replacer</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Unlern"><span class="nav-text">Unlern</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#EraseDiff"><span class="nav-text">EraseDiff</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Localized-Concept-Erasure-GLoCE"><span class="nav-text">Localized Concept Erasure (GLoCE)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#ACE-Anti-editing-Concept-Erasure"><span class="nav-text">ACE (Anti-editing Concept Erasure)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#STEREO-Search-Thoroughly-Enough-Robustly-Erase-Once"><span class="nav-text">STEREO (Search Thoroughly Enough, Robustly Erase Once)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#RIIDL-Responsible-Interpretable-Intermediate-Diffusion-Latents"><span class="nav-text">RIIDL (Responsible Interpretable Intermediate Diffusion Latents)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#AdaVD-Adaptive-Vaule-Decomposer"><span class="nav-text">AdaVD (Adaptive Vaule Decomposer)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#FADE-Fine-grained-Attenuation-for-Diffusion-Erasure"><span class="nav-text">FADE (Fine-grained Attenuation for Diffusion Erasure)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#TIU-The-Illusion-of-Unlearning"><span class="nav-text">TIU (The Illusion of Unlearning)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Six-CD-Benchmark"><span class="nav-text">Six-CD Benchmark</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Bias-1"><span class="nav-text">Bias</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#MPR-Multi-group-Proportional-Representation"><span class="nav-text">MPR (Multi-group Proportional Representation)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Rethinking-Training-for-De-biasing-Text-to-Image-Generation"><span class="nav-text">Rethinking Training for De-biasing Text-to-Image Generation</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Watermarks-1"><span class="nav-text">Watermarks</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#SleeperMark"><span class="nav-text">SleeperMark</span></a></li></ol></li></ol></li></ol></li></ol>

	</div>
</div>
	</div>
	
</div>
			</div>

			
		</div>

		<div class="main-content-footer">
			<footer class="footer mt-5 py-5 h-auto text-base text-third-text-color relative border-t-2 border-t-border-color">
    <div class="info-container py-3 text-center">
        
        <div class="text-center">
            &copy;
            
              <span>2024</span>
              -
            
            2025&nbsp;&nbsp;<i class="fa-solid fa-cog fa-spin" style="--fa-animation-duration:15s"></i>&nbsp;&nbsp;<a href="/">LeoJeshua</a>
            
                
                <p class="post-count space-x-0.5">
                    <span>
                        18 posts in total
                    </span>
                    
                        <span>
                            40.6k words in total
                        </span>
                    
                </p>
            
        </div>
        
            <script data-swup-reload-script src="https://cn.vercount.one/js"></script>
            <div class="relative text-center lg:absolute lg:right-[20px] lg:top-1/2 lg:-translate-y-1/2 lg:text-right">
                
                    <span id="busuanzi_container_site_uv" class="lg:!block">
                        <span class="text-sm">VISITOR COUNT</span>
                        <span id="busuanzi_value_site_uv"></span>
                    </span>
                
                
                    <span id="busuanzi_container_site_pv" class="lg:!block">
                        <span class="text-sm">TOTAL PAGE VIEWS</span>
                        <span id="busuanzi_value_site_pv"></span>
                    </span>
                
            </div>
        
        <div class="relative text-center lg:absolute lg:left-[20px] lg:top-1/2 lg:-translate-y-1/2 lg:text-left">
            <span class="lg:block text-sm">POWERED BY <?xml version="1.0" encoding="utf-8"?><!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"><svg class="relative top-[2px] inline-block align-baseline" version="1.1" id="圖層_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" width="1rem" height="1rem" viewBox="0 0 512 512" enable-background="new 0 0 512 512" xml:space="preserve"><path fill="#0E83CD" d="M256.4,25.8l-200,115.5L56,371.5l199.6,114.7l200-115.5l0.4-230.2L256.4,25.8z M349,354.6l-18.4,10.7l-18.6-11V275H200v79.6l-18.4,10.7l-18.6-11v-197l18.5-10.6l18.5,10.8V237h112v-79.6l18.5-10.6l18.5,10.8V354.6z"/></svg><a target="_blank" class="text-base" href="https://hexo.io">Hexo</a></span>
            <span class="text-sm lg:block">THEME&nbsp;<a class="text-base" target="_blank" href="https://github.com/EvanNotFound/hexo-theme-redefine">Redefine v2.8.5</a></span>
        </div>
        
        
            <div>
                Blog up for <span class="odometer" id="runtime_days" ></span> days <span class="odometer" id="runtime_hours"></span> hrs <span class="odometer" id="runtime_minutes"></span> Min <span class="odometer" id="runtime_seconds"></span> Sec
            </div>
        
        
            <script data-swup-reload-script>
                try {
                    function odometer_init() {
                    const elements = document.querySelectorAll('.odometer');
                    elements.forEach(el => {
                        new Odometer({
                            el,
                            format: '( ddd).dd',
                            duration: 200
                        });
                    });
                    }
                    odometer_init();
                } catch (error) {}
            </script>
        
        
            
                
        
                
        
                

                    
                        <script data-swup-reload-script>var url_1736="https://api.cdnorg.cn:666";var token_1736="8d393e3086e1d2d48267460f67b7bf8d1a09f23f231d32de4f3fb3a12f3af020";var cltj_1736=document.createElement("script");cltj_1736.src=url_1736+"/tj/tongji.js?v=2.201";var s_1736=document.getElementsByTagName("script")[0];s_1736.parentNode.insertBefore(cltj_1736,s_1736);</script>
                    
        
                

                    
                        <script data-swup-reload-script type="text/javascript">(function(){var baidu=document.createElement("script");baidu.src="//i.6v6.work/v/?uid=388547";var cnzz=document.getElementsByTagName("script")[0];cnzz.parentNode.insertBefore(baidu,cnzz)})();</script>
                    
        
        
    </div>  
</footer>
		</div>
	</div>

	
	<div class="post-tools">
		<div class="post-tools-container">
	<ul class="article-tools-list">
		<!-- TOC aside toggle -->
		
		<li class="right-bottom-tools page-aside-toggle">
			<i class="fa-regular fa-outdent"></i>
		</li>
		

		<!-- go comment -->
		
	</ul>
</div>
	</div>
	

	<div class="right-side-tools-container">
		<div class="side-tools-container">
	<ul class="hidden-tools-list">
		<li class="right-bottom-tools tool-font-adjust-plus flex justify-center items-center">
			<i class="fa-regular fa-magnifying-glass-plus"></i>
		</li>

		<li class="right-bottom-tools tool-font-adjust-minus flex justify-center items-center">
			<i class="fa-regular fa-magnifying-glass-minus"></i>
		</li>

		<li class="right-bottom-tools tool-dark-light-toggle flex justify-center items-center">
			<i class="fa-regular fa-moon"></i>
		</li>

		<!-- rss -->
		

		

		<li class="right-bottom-tools tool-scroll-to-bottom flex justify-center items-center">
			<i class="fa-regular fa-arrow-down"></i>
		</li>
	</ul>

	<ul class="visible-tools-list">
		<li class="right-bottom-tools toggle-tools-list flex justify-center items-center">
			<i class="fa-regular fa-cog fa-spin"></i>
		</li>
		
		<li class="right-bottom-tools tool-scroll-to-top flex justify-center items-center">
			<i class="arrow-up fas fa-arrow-up"></i>
			<span class="percent"></span>
		</li>
		
		
	</ul>
</div>
	</div>

	<div class="image-viewer-container">
	<img src="">
</div>

	

</main>


<script  src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.5/files/source/js/build/libs/Swup.min.js" ></script><script  src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.5/files/source/js/build/libs/SwupSlideTheme.min.js" ></script><script  src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.5/files/source/js/build/libs/SwupScriptsPlugin.min.js" ></script><script  src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.5/files/source/js/build/libs/SwupProgressPlugin.min.js" ></script><script  src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.5/files/source/js/build/libs/SwupScrollPlugin.min.js" ></script><script  src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.5/files/source/js/build/libs/SwupPreloadPlugin.min.js" ></script>
<script>
    const swup = new Swup({
        plugins: [
            new SwupScriptsPlugin({
                optin: true,
            }),
            new SwupProgressPlugin(),
            new SwupScrollPlugin({
                offset: 80,
            }),
            new SwupSlideTheme({
                mainElement: ".main-content-body",
            }),
            new SwupPreloadPlugin(),
        ],
        containers: ["#swup"],
    });
</script>




	<script type="module" src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.5/files/source/js/build/tools/imageViewer.js" ></script><script type="module" src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.5/files/source/js/build/utils.js" ></script><script type="module" src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.5/files/source/js/build/main.js" ></script><script type="module" src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.5/files/source/js/build/layouts/navbarShrink.js" ></script><script type="module" src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.5/files/source/js/build/tools/scrollTopBottom.js" ></script><script type="module" src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.5/files/source/js/build/tools/lightDarkSwitch.js" ></script><script type="module" src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.5/files/source/js/build/layouts/categoryList.js" ></script>




    <script type="module" src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.5/files/source/js/build/tools/codeBlock.js" ></script>



    <script type="module" src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.5/files/source/js/build/layouts/lazyload.js" ></script>



    <script  src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.5/files/source/js/build/tools/runtime.js" ></script>
    <script  src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.5/files/source/js/build/libs/odometer.min.js" ></script>
    <link rel="stylesheet" href="https://registry.npmmirror.com/hexo-theme-redefine/2.8.5/files/source/assets/odometer-theme-minimal.css">



  <script  src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.5/files/source/js/build/libs/Typed.min.js" ></script>
  <script type="module" src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.5/files/source/js/build/plugins/typed.js" ></script>







    <script  src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.5/files/source/js/build/libs/anime.min.js" ></script>




    <script type="module" src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.5/files/source/js/build/tools/tocToggle.js" data-swup-reload-script></script><script type="module" src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.5/files/source/js/build/layouts/toc.js" data-swup-reload-script></script><script type="module" src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.5/files/source/js/build/plugins/tabs.js" data-swup-reload-script></script>


<script  src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.5/files/source/js/build/libs/moment-with-locales.min.js" data-swup-reload-script></script>
<script type="module" src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.5/files/source/js/build/layouts/essays.js" data-swup-reload-script></script>




	
</body>

</html>