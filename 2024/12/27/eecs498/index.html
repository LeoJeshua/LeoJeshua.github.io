<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="keywords" content="Hexo Theme Redefine">
    
    <meta name="author" content="LIU JIAXU (刘家旭)">
    <!-- preconnect -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>

    
        
        
        
            <link rel="preconnect" href="https://registry.npmmirror.com" crossorigin>
        
    
    <!--- Seo Part-->
    
    <link rel="canonical" href="https://leojeshua.github.io/2024/12/27/eecs498/"/>
    <meta name="robots" content="index,follow">
    <meta name="googlebot" content="index,follow">
    <meta name="revisit-after" content="1 days">
    
    
    
        
        <meta name="description" content="Hexo Theme Redefine, Redefine Your Hexo Journey.">
<meta property="og:type" content="article">
<meta property="og:title" content="Notes of &quot;EECS498-007&#x2F;598-005 Deep Learning for Computer Vision (2019)&quot;">
<meta property="og:url" content="https://leojeshua.github.io/2024/12/27/eecs498/index.html">
<meta property="og:site_name" content="The Blog of LIU JIAXU">
<meta property="og:description" content="Hexo Theme Redefine, Redefine Your Hexo Journey.">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://leojeshua.github.io/images/redefine-og.webp">
<meta property="article:published_time" content="2024-12-27T10:54:58.000Z">
<meta property="article:modified_time" content="2025-01-12T05:49:12.495Z">
<meta property="article:author" content="LIU JIAXU">
<meta property="article:tag" content="CV">
<meta property="article:tag" content="Notes">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://leojeshua.github.io/images/redefine-og.webp">
    
    
    <!--- Icon Part-->
    <link rel="icon" type="image/png" href="/images/avatar.png" sizes="192x192">
    <link rel="apple-touch-icon" sizes="180x180" href="/images/avatar.png">
    <meta name="theme-color" content="#A31F34">
    <link rel="shortcut icon" href="/images/avatar.png">
    <!--- Page Info-->
    
    <title>
        
            Notes of &#34;EECS498-007/598-005 Deep Learning for Computer Vision (2019)&#34; | Academic Blog of LIU JIAXU
        
    </title>

    <link rel="stylesheet" href="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/fonts/Chillax/chillax.css">

    <!--- Inject Part-->
    
        
            
    
            
    

    
<link rel="stylesheet" href="/css/style.css">


    
        <link rel="stylesheet" href="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/css/build/tailwind.css">
    

    <link rel="stylesheet" href="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/fonts/GeistMono/geist-mono.css">
    <link rel="stylesheet" href="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/fonts/Geist/geist.css">
    <!--- Font Part-->
    
    
    
    
    
    

    <script id="hexo-configurations">
    window.config = {"hostname":"leojeshua.github.io","root":"/","language":"en"};
    window.theme = {"articles":{"style":{"font_size":"16px","line_height":1.5,"image_border_radius":"2px","image_alignment":"center","image_caption":false,"link_icon":true,"delete_mask":false,"title_alignment":"left","headings_top_spacing":{"h1":"3.2rem","h2":"2.5rem","h3":"1.8rem","h4":"1.3rem","h5":"1.2rem","h6":"1.1rem"}},"word_count":{"enable":true,"count":true,"min2read":true},"author_label":{"enable":true,"auto":false,"list":[]},"code_block":{"copy":true,"style":"mac","highlight_theme":{"light":"github","dark":"vs2015"},"font":{"enable":false,"family":null,"url":null}},"toc":{"enable":true,"max_depth":4,"number":false,"expand":true,"init_open":true},"copyright":{"enable":true,"default":"cc_by_nc_sa"},"lazyload":true,"pangu_js":false,"recommendation":{"enable":false,"title":"推荐阅读","limit":3,"mobile_limit":2,"placeholder":"/images/wallhaven-wqery6-light.webp","skip_dirs":[]}},"colors":{"primary":"#A31F34","secondary":null,"default_mode":"light"},"global":{"fonts":{"chinese":{"enable":false,"family":null,"url":null},"english":{"enable":false,"family":null,"url":null},"title":{"enable":false,"family":null,"url":null}},"content_max_width":"1200px","sidebar_width":"30%","hover":{"shadow":true,"scale":false},"scroll_progress":{"bar":false,"percentage":true},"website_counter":{"url":"https://cn.vercount.one/js","enable":true,"site_pv":true,"site_uv":true,"post_pv":true},"single_page":true,"preloader":{"enable":false,"custom_message":null},"open_graph":{"enable":true,"image":"/images/redefine-og.webp","description":"Hexo Theme Redefine, Redefine Your Hexo Journey."},"google_analytics":{"enable":false,"id":null}},"home_banner":{"enable":true,"style":"static","image":{"light":"/images/wallhaven-wqery6-light.webp","dark":"/images/wallhaven-wqery6-dark.webp"},"title":"从-1开始的科研训练之路","subtitle":{"text":["If you shed tears when you miss the sun, you also miss the stars.","Reading maketh a full man; conference a ready man; and writing an exact man. (Francis Bacon)","Who drives me forward like fate? The Myself striding on my back."],"hitokoto":{"enable":false,"show_author":false,"api":"https://v1.hitokoto.cn"},"typing_speed":100,"backing_speed":80,"starting_delay":500,"backing_delay":1500,"loop":true,"smart_backspace":true},"text_color":{"light":"#fff","dark":"#d1d1b6"},"text_style":{"title_size":"2.8rem","subtitle_size":"1.5rem","line_height":1.2},"custom_font":{"enable":false,"family":null,"url":null},"social_links":{"enable":true,"style":"default","links":{"github":"https://github.com/LeoJeshua","instagram":null,"zhihu":null,"twitter":null,"email":"jiaxu.liu.ai@gmail.com"},"qrs":{"weixin":null}}},"plugins":{"feed":{"enable":false},"aplayer":{"enable":false,"type":"fixed","audios":[{"name":null,"artist":null,"url":null,"cover":null,"lrc":null}]},"mermaid":{"enable":false,"version":"11.4.1"}},"version":"2.8.2","navbar":{"auto_hide":true,"color":{"left":"#f78736","right":"#367df7","transparency":35},"width":{"home":"1200px","pages":"1000px"},"links":{"Home":{"path":"/","icon":"fa-regular fa-house"},"Archives":{"path":"/archives","icon":"fa-regular fa-archive"},"Categories":{"path":"/categories/","icon":"fa-regular fa-folder"},"Tags":{"icon":"fa-regular fa-tags","path":"/tags/"}},"search":{"enable":false,"preload":true}},"page_templates":{"friends_column":2,"tags_style":"cloud"},"home":{"sidebar":{"enable":true,"position":"right","first_item":"menu","announcement":"Aspiring to contribute to cutting-edge AI security research with a focus on offensive strategies to uncover and mitigate AI vulnerabilities.","show_on_mobile":true,"links":null},"article_date_format":"auto","excerpt_length":200,"categories":{"enable":true,"limit":3},"tags":{"enable":true,"limit":3}},"footerStart":"2024/12/20 21:33:00"};
    window.lang_ago = {"second":"%s seconds ago","minute":"%s minutes ago","hour":"%s hours ago","day":"%s days ago","week":"%s weeks ago","month":"%s months ago","year":"%s years ago"};
    window.data = {"masonry":false};
  </script>
    
    <!--- Fontawesome Part-->
    <link rel="stylesheet" href="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/fontawesome/fontawesome.min.css">
    <link rel="stylesheet" href="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/fontawesome/brands.min.css">
    <link rel="stylesheet" href="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/fontawesome/solid.min.css">
    <link rel="stylesheet" href="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/fontawesome/regular.min.css">
    
    
    
    
<meta name="generator" content="Hexo 7.3.0"><style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}
</style></head>



<body>
	<div class="progress-bar-container">
	

	
	<span class="pjax-progress-bar"></span>
	<!--        <span class="swup-progress-icon">-->
	<!--            <i class="fa-solid fa-circle-notch fa-spin"></i>-->
	<!--        </span>-->
	
</div>

<main class="page-container" id="swup">

	

	<div class="main-content-container flex flex-col justify-between min-h-dvh">
		<div class="main-content-header">
			<header class="navbar-container px-6 md:px-12">
    <div class="navbar-content transition-navbar ">
        <div class="left">
            
            <a class="logo-title" href="/">
                
                Academic Blog of LIU JIAXU
                
            </a>
        </div>

        <div class="right">
            <!-- PC -->
            <div class="desktop">
                <ul class="navbar-list">
                    
                        
                            

                            <li class="navbar-item">
                                <!-- Menu -->
                                <a class=""
                                   href="/"
                                        >
                                    <i class="fa-regular fa-house fa-fw"></i>
                                    HOME
                                    
                                </a>

                                <!-- Submenu -->
                                
                            </li>
                    
                        
                            

                            <li class="navbar-item">
                                <!-- Menu -->
                                <a class=""
                                   href="/archives"
                                        >
                                    <i class="fa-regular fa-archive fa-fw"></i>
                                    ARCHIVES
                                    
                                </a>

                                <!-- Submenu -->
                                
                            </li>
                    
                        
                            

                            <li class="navbar-item">
                                <!-- Menu -->
                                <a class=""
                                   href="/categories/"
                                        >
                                    <i class="fa-regular fa-folder fa-fw"></i>
                                    CATEGORIES
                                    
                                </a>

                                <!-- Submenu -->
                                
                            </li>
                    
                        
                            

                            <li class="navbar-item">
                                <!-- Menu -->
                                <a class=""
                                   href="/tags/"
                                        >
                                    <i class="fa-regular fa-tags fa-fw"></i>
                                    TAGS
                                    
                                </a>

                                <!-- Submenu -->
                                
                            </li>
                    
                    
                </ul>
            </div>
            <!-- Mobile -->
            <div class="mobile">
                
                <div class="icon-item navbar-bar">
                    <div class="navbar-bar-middle"></div>
                </div>
            </div>
        </div>
    </div>

    <!-- Mobile sheet -->
    <div class="navbar-drawer h-dvh w-full absolute top-0 left-0 bg-background-color flex flex-col justify-between">
        <ul class="drawer-navbar-list flex flex-col px-4 justify-center items-start">
            
                
                    

                    <li class="drawer-navbar-item text-base my-1.5 flex flex-col w-full">
                        
                        <a class="py-1.5 px-2 flex flex-row items-center justify-between gap-1 hover:!text-primary active:!text-primary text-2xl font-semibold group border-b border-border-color hover:border-primary w-full "
                           href="/"
                        >
                            <span>
                                HOME
                            </span>
                            
                                <i class="fa-regular fa-house fa-sm fa-fw"></i>
                            
                        </a>
                        

                        
                    </li>
            
                
                    

                    <li class="drawer-navbar-item text-base my-1.5 flex flex-col w-full">
                        
                        <a class="py-1.5 px-2 flex flex-row items-center justify-between gap-1 hover:!text-primary active:!text-primary text-2xl font-semibold group border-b border-border-color hover:border-primary w-full "
                           href="/archives"
                        >
                            <span>
                                ARCHIVES
                            </span>
                            
                                <i class="fa-regular fa-archive fa-sm fa-fw"></i>
                            
                        </a>
                        

                        
                    </li>
            
                
                    

                    <li class="drawer-navbar-item text-base my-1.5 flex flex-col w-full">
                        
                        <a class="py-1.5 px-2 flex flex-row items-center justify-between gap-1 hover:!text-primary active:!text-primary text-2xl font-semibold group border-b border-border-color hover:border-primary w-full "
                           href="/categories/"
                        >
                            <span>
                                CATEGORIES
                            </span>
                            
                                <i class="fa-regular fa-folder fa-sm fa-fw"></i>
                            
                        </a>
                        

                        
                    </li>
            
                
                    

                    <li class="drawer-navbar-item text-base my-1.5 flex flex-col w-full">
                        
                        <a class="py-1.5 px-2 flex flex-row items-center justify-between gap-1 hover:!text-primary active:!text-primary text-2xl font-semibold group border-b border-border-color hover:border-primary w-full "
                           href="/tags/"
                        >
                            <span>
                                TAGS
                            </span>
                            
                                <i class="fa-regular fa-tags fa-sm fa-fw"></i>
                            
                        </a>
                        

                        
                    </li>
            

            
            
        </ul>

        <div class="statistics flex justify-around my-2.5">
    <a class="item tag-count-item flex flex-col justify-center items-center w-20" href="/tags">
        <div class="number text-2xl sm:text-xl text-second-text-color font-semibold">12</div>
        <div class="label text-third-text-color text-sm">Tags</div>
    </a>
    <a class="item tag-count-item flex flex-col justify-center items-center w-20" href="/categories">
        <div class="number text-2xl sm:text-xl text-second-text-color font-semibold">10</div>
        <div class="label text-third-text-color text-sm">Categories</div>
    </a>
    <a class="item tag-count-item flex flex-col justify-center items-center w-20" href="/archives">
        <div class="number text-2xl sm:text-xl text-second-text-color font-semibold">7</div>
        <div class="label text-third-text-color text-sm">Posts</div>
    </a>
</div>
    </div>

    <div class="window-mask"></div>

</header>


		</div>

		<div class="main-content-body transition-fade-up">
			

			<div class="main-content">
				<div class="post-page-container flex relative justify-between box-border w-full h-full">
	<div class="article-content-container">

		<div class="article-title relative w-full">
			
			
			
			<img src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20241227205140.png" alt="Notes of &#34;EECS498-007/598-005 Deep Learning for Computer Vision (2019)&#34;" class="w-full h-60 sm:h-72 md:h-80 object-cover sm:rounded-t-large dark:brightness-75" />
			
			<div class="w-full flex items-center absolute bottom-0 justify-start">
				<h1 class="article-title-cover text-center mx-6 my-6 text-second-text-color bg-background-color-transparent px-4 py-3 text-3xl sm:text-4xl md:text-5xl font-semibold backdrop-blur-lg rounded-xl border border-border-color ">Notes of &#34;EECS498-007/598-005 Deep Learning for Computer Vision (2019)&#34;</h1>
			</div>
			
		</div>

		
		<div class="article-header flex flex-row gap-2 items-center px-2 sm:px-6 md:px-8">
			<div class="avatar w-[46px] h-[46px] flex-shrink-0 rounded-medium border border-border-color p-[1px]">
				<img src="/images/avatar.png">
			</div>
			<div class="info flex flex-col justify-between">
				<div class="author flex items-center">
					<span class="name text-default-text-color text-lg font-semibold">LIU JIAXU (刘家旭)</span>
					
					<span class="author-label ml-1.5 text-xs px-2 py-0.5 rounded-small text-third-text-color border border-shadow-color-1">Lv1</span>
					
				</div>
				<div class="meta-info">
					<div class="article-meta-info">
    <span class="article-date article-meta-item">
        <i class="fa-regular fa-pen-fancy"></i>&nbsp;
        <span class="desktop">2024-12-27 18:54:58</span>
        <span class="mobile">2024-12-27 18:54:58</span>
        <span class="hover-info">Created</span>
    </span>
    
        <span class="article-date article-meta-item">
            <i class="fa-regular fa-wrench"></i>&nbsp;
            <span class="desktop">2025-01-12 13:49:12</span>
            <span class="mobile">2025-01-12 13:49:12</span>
            <span class="hover-info">Updated</span>
        </span>
    

    
        <span class="article-categories article-meta-item">
            <i class="fa-regular fa-folders"></i>&nbsp;
            <ul>
                
                
                    
                        
                        <li>
                            <a href="/categories/AI/">AI</a>&nbsp;
                        </li>
                    
                    
                
                    
                        
                            <li>></li>
                        
                        <li>
                            <a href="/categories/AI/Foundations/">Foundations</a>&nbsp;
                        </li>
                    
                    
                
                    
                        
                            <li>></li>
                        
                        <li>
                            <a href="/categories/AI/Foundations/Computer-Vision/">Computer Vision</a>&nbsp;
                        </li>
                    
                    
                
            </ul>
        </span>
    
    
        <span class="article-tags article-meta-item">
            <i class="fa-regular fa-tags"></i>&nbsp;
            <ul>
                
                    <li>
                        <a href="/tags/CV/">CV</a>&nbsp;
                    </li>
                
                    <li>
                        | <a href="/tags/Notes/">Notes</a>&nbsp;
                    </li>
                
            </ul>
        </span>
    

    
    
        <span class="article-wordcount article-meta-item">
            <i class="fa-regular fa-typewriter"></i>&nbsp;<span>3.2k Words</span>
        </span>
    
    
        <span class="article-min2read article-meta-item">
            <i class="fa-regular fa-clock"></i>&nbsp;<span>14 Mins</span>
        </span>
    
    
        <span class="article-pv article-meta-item">
            <i class="fa-regular fa-eye"></i>&nbsp;<span id="busuanzi_value_page_pv"></span>
        </span>
    
</div>

				</div>
			</div>
		</div>
		

		


		<div class="article-content markdown-body px-2 sm:px-6 md:px-8 pb-8">
			<p><strong>EECS 498-007/598-005课程简介</strong></p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20241228143409.png" alt="20241228143409"></p>
<ul>
<li><p>Basic Info：</p>
<ul>
<li>course page: <a class="link" target="_blank" rel="noopener" href="https://web.eecs.umich.edu/~justincj/teaching/eecs498/FA2019/">EECS 498-007/598-005 Deep Learning for Computer Vision<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li>vedio: <a class="link" target="_blank" rel="noopener" href="https://www.youtube.com/playlist?list=PL5-TkQAfAZFbzxjBHtzdVCWE0Zbhomg7r">[Youtube (official)]<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a> <a class="link" target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV13P4y1t7gM">[Bilibili]<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li>Instructor: <a class="link" target="_blank" rel="noopener" href="https://web.eecs.umich.edu/~justincj/">Justin Johnson<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a> (the student of <a class="link" target="_blank" rel="noopener" href="https://profiles.stanford.edu/fei-fei-li/">Fei-Fei Li<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>, as well as one of the lecturers of CS231n)</li>
</ul>
</li>
<li><p>This course can be considered as an expanded version of <a class="link" target="_blank" rel="noopener" href="http://cs231n.stanford.edu/">CS231n: CNN for Visual Recognition [2016 Open Course]<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a>, </p>
</li>
<li><p>Background</p>
<blockquote>
<p>Computer Vision has become ubiquitous in our society, with applications in search, image understanding, apps, mapping, medicine, drones, and self-driving cars. Core to many of these applications are <strong>visual recognition tasks such as image classification and object detection</strong>. Recent developments in neural network approaches have greatly advanced the performance of these state-of-the-art visual recognition systems. </p>
</blockquote>
</li>
<li><p>Description</p>
<blockquote>
<p>This course is a deep dive into details of <strong>neural-network based deep learning methods for computer vision</strong>. During this course, students will learn to implement, train and debug their own neural networks and gain a detailed understanding of cutting-edge research in computer vision. We will cover <strong>learning algorithms</strong>, <strong>neural network architectures</strong>, and <strong>practical engineering tricks for training</strong> and <strong>fine-tuning networks</strong> for visual recognition tasks.</p>
</blockquote>
</li>
</ul>
<h1 id="lecture-1-Course-Introduction（介绍）"><a href="#lecture-1-Course-Introduction（介绍）" class="headerlink" title="lecture 1: Course Introduction（介绍）"></a>lecture 1: Course Introduction（介绍）</h1><p>slide: <a class="link" target="_blank" rel="noopener" href="https://web.eecs.umich.edu/~justincj/slides/eecs498/498_FA2019_lecture01.pdf">https://web.eecs.umich.edu/~justincj/slides/eecs498/498_FA2019_lecture01.pdf<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<ul>
<li>Computer vision overview</li>
<li>Historical context</li>
<li>Course logistics</li>
</ul>
<h1 id="lecture-2-Image-Classification（图像分类）"><a href="#lecture-2-Image-Classification（图像分类）" class="headerlink" title="lecture 2: Image Classification（图像分类）"></a>lecture 2: Image Classification（图像分类）</h1><p>slide: <a class="link" target="_blank" rel="noopener" href="https://web.eecs.umich.edu/~justincj/slides/eecs498/498_FA2019_lecture02.pdf">https://web.eecs.umich.edu/~justincj/slides/eecs498/498_FA2019_lecture02.pdf<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<ul>
<li>Data-driven approach</li>
<li>K-Nearest Neighbor</li>
<li>Hyperparameters</li>
<li>Cross-validation</li>
</ul>
<h1 id="lecture-3-Linear-Classifiers（线性分类器）"><a href="#lecture-3-Linear-Classifiers（线性分类器）" class="headerlink" title="lecture 3: Linear Classifiers（线性分类器）"></a>lecture 3: Linear Classifiers（线性分类器）</h1><p>slide: <a class="link" target="_blank" rel="noopener" href="https://web.eecs.umich.edu/~justincj/slides/eecs498/498_FA2019_lecture03.pdf">https://web.eecs.umich.edu/~justincj/slides/eecs498/498_FA2019_lecture03.pdf<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<ul>
<li>Softmax / SVM classifiers</li>
<li>L2 regularization</li>
</ul>
<h1 id="lecture-4-Optimization（优化）"><a href="#lecture-4-Optimization（优化）" class="headerlink" title="lecture 4: Optimization（优化）"></a>lecture 4: Optimization（优化）</h1><p>slide: <a class="link" target="_blank" rel="noopener" href="https://web.eecs.umich.edu/~justincj/slides/eecs498/498_FA2019_lecture04.pdf">https://web.eecs.umich.edu/~justincj/slides/eecs498/498_FA2019_lecture04.pdf<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<ul>
<li>Stochastic Gradient Descent</li>
<li>Momentum, AdaGrad, Adam</li>
<li>Second-order optimizers</li>
</ul>
<h1 id="lecture-5-Neural-Networks（神经网络）"><a href="#lecture-5-Neural-Networks（神经网络）" class="headerlink" title="lecture 5: Neural Networks（神经网络）"></a>lecture 5: Neural Networks（神经网络）</h1><p>slide: <a class="link" target="_blank" rel="noopener" href="https://web.eecs.umich.edu/~justincj/slides/eecs498/498_FA2019_lecture05.pdf">https://web.eecs.umich.edu/~justincj/slides/eecs498/498_FA2019_lecture05.pdf<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<ul>
<li>Feature transforms</li>
<li>Fully-connected networks</li>
<li>Universal approximation</li>
<li>Convexity</li>
</ul>
<h1 id="lecture-6-Backpropagation（反向传播BP）"><a href="#lecture-6-Backpropagation（反向传播BP）" class="headerlink" title="lecture 6: Backpropagation（反向传播BP）"></a>lecture 6: Backpropagation（反向传播BP）</h1><p>slide: <a class="link" target="_blank" rel="noopener" href="https://web.eecs.umich.edu/~justincj/slides/eecs498/498_FA2019_lecture06.pdf">https://web.eecs.umich.edu/~justincj/slides/eecs498/498_FA2019_lecture06.pdf<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<ul>
<li>Computational Graphs</li>
<li>Backpropagation</li>
<li>Matrix multiplication example</li>
</ul>
<h1 id="lecture-7-Convolutional-Networks（CNN）"><a href="#lecture-7-Convolutional-Networks（CNN）" class="headerlink" title="lecture 7: Convolutional Networks（CNN）"></a>lecture 7: Convolutional Networks（CNN）</h1><p>slide: <a class="link" target="_blank" rel="noopener" href="https://web.eecs.umich.edu/~justincj/slides/eecs498/498_FA2019_lecture07.pdf">https://web.eecs.umich.edu/~justincj/slides/eecs498/498_FA2019_lecture07.pdf<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<ul>
<li>Convolution</li>
<li>Pooling</li>
<li>Batch Normalization</li>
</ul>
<p>Components of a CNN：<br><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20241228132723.png" alt="20241228132723"></p>
<h2 id="7-1-Fully-Connected-Layer"><a href="#7-1-Fully-Connected-Layer" class="headerlink" title="7.1 Fully-Connected Layer"></a>7.1 Fully-Connected Layer</h2><p>在卷积神经网络(CNN)出现之前，人们将图片flatten成一维向量，然后使用全连接神经网络(FCN)进行图像分类。</p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20241228131725.png" alt="20241228131725"></p>
<p>缺点：</p>
<ul>
<li>计算量大，参数量多，容易过拟合</li>
<li>无法捕捉到图像的空间特征</li>
</ul>
<h2 id="7-2-Convolution-Layer"><a href="#7-2-Convolution-Layer" class="headerlink" title="7.2 Convolution Layer"></a>7.2 Convolution Layer</h2><p>借鉴人眼 <code>感受野(Receptive Fields)</code> 的概念，使用<code>卷积核(filter)</code>对<code>input image</code>进行卷积操作，得到特征提取的结果。</p>
<p><strong>卷积层的目的：提取input image的特定特征（如边缘、形状、纹理等）</strong><br><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20241228173104.png" alt="20241228173104"></p>
<h3 id="7-2-1-卷积核-filter"><a href="#7-2-1-卷积核-filter" class="headerlink" title="7.2.1 卷积核 (filter)"></a>7.2.1 卷积核 (filter)</h3><p><strong>filter的深度（通道数） = input image的深度（通道数）</strong></p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20241228132216.png" alt="20241228132216"></p>
<h3 id="7-2-2-卷积操作-Convolve"><a href="#7-2-2-卷积操作-Convolve" class="headerlink" title="7.2.2 卷积操作 (Convolve)"></a>7.2.2 卷积操作 (Convolve)</h3><p><code>filter</code> * <code>input image上对应chunk</code> + <code>bias</code> = 卷积结果（特征图/激活图上的一个点）。</p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20241228162241.png" alt="20241228162241"></p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20241228175551.png" alt="20241228175551"></p>
<ul>
<li>卷积结果表示 该chunk与filter的匹配程度，<strong>值越大表示匹配程度越高</strong></li>
<li>后面的图示中通常会省略bias，但 <strong>计算中不要忘记bias项</strong></li>
</ul>
<h4 id="边缘填充-Padding"><a href="#边缘填充-Padding" class="headerlink" title="边缘填充 (Padding)"></a>边缘填充 (Padding)</h4><p>在进行卷积操作时，边缘像素块没有得到很好的利用</p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20241228174739.png" alt="20241228174739"></p>
<p>解决方法：在边缘填充0 (zero-padding)，使得卷积操作可以覆盖到边缘像素块。<br><strong>填充像素的大小P = (卷积核的大小K - 1) / 2</strong><br>eg: 3x3卷积核(K=3) -&gt; 填充像素大小P=(3-1)/2=1</p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20241228175052.png" alt="20241228175052"></p>
<h4 id="跨步卷积-Strided-Convolution"><a href="#跨步卷积-Strided-Convolution" class="headerlink" title="跨步卷积 (Strided Convolution)"></a>跨步卷积 (Strided Convolution)</h4><p>单步卷积的问题：</p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20241228175930.png" alt="20241228175930"></p>
<ul>
<li>对于大图像，我们需要很多卷积层才能“看到”整个图像</li>
<li>计算量大</li>
</ul>
<p>解决方案：<strong>下采样(Downsampling)</strong> ，包括各种使spatial size减小的方法，如<code>跨步卷积</code>、<code>池化</code>等。<br><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20241228180542.png" alt="20241228180542"></p>
<p>输出图像大小：<strong>output_size = (input_size - filter_size + 2*padding) / stride + 1</strong></p>
<h3 id="7-2-3-特征图-激活图-Feature-Map-Activation-Map"><a href="#7-2-3-特征图-激活图-Feature-Map-Activation-Map" class="headerlink" title="7.2.3 特征图/激活图 (Feature Map/Activation Map)"></a>7.2.3 特征图/激活图 (Feature Map/Activation Map)</h3><p><strong>Feature Map/Activation Map的个数 = filter的个数</strong></p>
<p>使用filter对input image进行卷积操作<br>-&gt; 得到<code>特征图(feature map)</code><br>-&gt; 再经过激活函数得到<code>激活图(activation map)</code></p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20241228163005.png" alt="20241228163005"><br>使用另一个filter进行卷积操作，得到另一张<code>Feature Map/Activation Map</code>。<br><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20241228163530.png" alt="20241228163530"></p>
<h4 id="视角1：多个单通道-Feature-Map-Activation-Map"><a href="#视角1：多个单通道-Feature-Map-Activation-Map" class="headerlink" title="视角1：多个单通道 Feature Map/Activation Map"></a>视角1：多个单通道 Feature Map/Activation Map</h4><p>eg: 6个filter -&gt; 得到 6个 <code>通道数为1的 Feature Map/Activation Map</code><br><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20241228165106.png" alt="20241228165106"></p>
<h4 id="视角2：一个多通道-Feature-Map-Activation-Map"><a href="#视角2：一个多通道-Feature-Map-Activation-Map" class="headerlink" title="视角2：一个多通道 Feature Map/Activation Map"></a>视角2：一个多通道 Feature Map/Activation Map</h4><p>eg: 6个filter -&gt; 得到 1个 <code>通道数为6的 Feature Map/Activation Map</code><br><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20241228165634.png" alt="20241228165634"></p>
<h3 id="7-2-4-卷积层的训练设置"><a href="#7-2-4-卷积层的训练设置" class="headerlink" title="7.2.4 卷积层的训练设置"></a>7.2.4 卷积层的训练设置</h3><h4 id="批量输入"><a href="#批量输入" class="headerlink" title="批量输入"></a>批量输入</h4><p>batch_size = N &gt; 1<br>N张 <code>input image</code> -&gt; 得到 N张 <code>Feature Map/Activation Map</code></p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20241228171540.png" alt="20241228171540"></p>
<h4 id="参数量和计算量"><a href="#参数量和计算量" class="headerlink" title="参数量和计算量"></a>参数量和计算量</h4><p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20241228183129.png" alt="20241228183129"></p>
<h4 id="超参的一般选择"><a href="#超参的一般选择" class="headerlink" title="超参的一般选择"></a>超参的一般选择</h4><p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20241228182211.png" alt="20241228182211"></p>
<ul>
<li>1x1卷积核：改变通道数（不改变spatial size大小）。可以用于降低参数量。</li>
<li>跨步卷积：stride &gt; 1，用于下采样。</li>
</ul>
<h4 id="PyTorch实现"><a href="#PyTorch实现" class="headerlink" title="PyTorch实现"></a>PyTorch实现</h4><p>2D卷积<br><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20241228182600.png" alt="20241228182600"></p>
<p>1D和3D卷积<br><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20241228182624.png" alt="20241228182624"></p>
<h3 id="7-2-5-线性卷积层的问题"><a href="#7-2-5-线性卷积层的问题" class="headerlink" title="7.2.5 线性卷积层的问题"></a>7.2.5 线性卷积层的问题</h3><p><strong>多个线性卷积层叠加 == 一个线性卷积层</strong></p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20241228172728.png" alt="20241228172728"></p>
<p>解决思路：和全连接层一样，需要非线性的引入（如Activation Function，Pooling Layer）。</p>
<h2 id="7-3-Activation-Function"><a href="#7-3-Activation-Function" class="headerlink" title="7.3 Activation Function"></a>7.3 Activation Function</h2><p>目的：引入非线性，使神经网络可以学习到更复杂的模式。<br><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20241228172836.png" alt="20241228172836"></p>
<h2 id="7-4-Pooling-Layer"><a href="#7-4-Pooling-Layer" class="headerlink" title="7.4 Pooling Layer"></a>7.4 Pooling Layer</h2><ul>
<li>下采样的另一种方式，减小参数量</li>
<li>同时也能引入非线性</li>
</ul>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20241228173624.png" alt="20241228173624"></p>
<h3 id="7-4-1-Types-of-Pooling"><a href="#7-4-1-Types-of-Pooling" class="headerlink" title="7.4.1 Types of Pooling"></a>7.4.1 Types of Pooling</h3><ul>
<li><code>Max Pooling</code>：取池化窗口内的最大值<br><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20241228183602.png" alt="20241228183602"></li>
<li><code>Average Pooling</code>：取池化窗口内的平均值</li>
<li><code>Global Average Pooling</code>：取整个feature map的平均值 （2014年，GoogLeNet提出）</li>
</ul>
<h3 id="7-4-2-参数量-0"><a href="#7-4-2-参数量-0" class="headerlink" title="7.4.2 参数量 = 0"></a>7.4.2 参数量 = 0</h3><p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20241228183537.png" alt="20241228183537"></p>
<h2 id="7-5-2015-Normalization"><a href="#7-5-2015-Normalization" class="headerlink" title="7.5 (2015) Normalization"></a>7.5 (2015) Normalization</h2><p>Problem: Deep Networks are very hard to train!<br>Solution: Normalising the input data (<code>mean 0, variance 1</code>) </p>
<ul>
<li><strong>makes the data distribution more consistent</strong></li>
<li>and <strong>speeds up training</strong></li>
</ul>
<p><em>Ioffe and Szegedy, “Batch normalization: Accelerating deep network training by reducing internal covariate shift”, ICML2015</em> <a class="link" target="_blank" rel="noopener" href="https://arxiv.org/abs/1502.03167">[link]<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20241228181834.png" alt="20241228181834"></p>
<p><strong>Types of Normlization：</strong><br><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20241228131442.png" alt="20241228131442"></p>
<h3 id="Batch-Normalization"><a href="#Batch-Normalization" class="headerlink" title="Batch Normalization"></a>Batch Normalization</h3><p>对 <code>同一batch的不同图像(size=N)</code> 进行归一化，使得 <code>图像</code> 之间分布一致。</p>
<ul>
<li><strong>归一化输入</strong>：对于每一层的输入，Batch Normalization <strong>通过计算小批量的平均值和标准差，将输入标准化为 均值为0、方差为1的分布</strong> 。这有助于缓解深层神经网络中的“ <code>内部协变量偏移(internal covariate shift)</code> ”问题，从而稳定学习过程。<br><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20241228183955.png" alt="20241228183955"></li>
<li><strong>可学习参数</strong>：在标准化的基础上，Batch Normalization 引入了两个可学习的参数，即 <code>尺度参数（gamma）</code> 和 <code>偏移参数（beta）</code> 。这允许网络在标准化后能够 <strong>恢复适当的表示能力，以便于学习复杂特征</strong>。<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="1.294ex" height="1.857ex" role="img" focusable="false" viewBox="0 -810 572 821"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mover"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(313.8,16) translate(-250 0)"><path data-c="5E" d="M112 560L249 694L257 686Q387 562 387 560L361 531Q359 532 303 581L250 627L195 580Q182 569 169 557T148 538L140 532Q138 530 125 546L112 560Z"></path></g></g></g></g></g></svg></mjx-container> 是标准化后的输入，则标准化后的输出可以表达为： <mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="17.573ex" height="2.398ex" role="img" focusable="false" viewBox="0 -810 7767.4 1060"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mtext"><path data-c="42" d="M131 622Q124 629 120 631T104 634T61 637H28V683H229H267H346Q423 683 459 678T531 651Q574 627 599 590T624 512Q624 461 583 419T476 360L466 357Q539 348 595 302T651 187Q651 119 600 67T469 3Q456 1 242 0H28V46H61Q103 47 112 49T131 61V622ZM511 513Q511 560 485 594T416 636Q415 636 403 636T371 636T333 637Q266 637 251 636T232 628Q229 624 229 499V374H312L396 375L406 377Q410 378 417 380T442 393T474 417T499 456T511 513ZM537 188Q537 239 509 282T430 336L329 337H229V200V116Q229 57 234 52Q240 47 334 47H383Q425 47 443 53Q486 67 511 104T537 188Z"></path><path data-c="4E" d="M42 46Q74 48 94 56T118 69T128 86V634H124Q114 637 52 637H25V683H232L235 680Q237 679 322 554T493 303L578 178V598Q572 608 568 613T544 627T492 637H475V683H483Q498 680 600 680Q706 680 715 683H724V637H707Q634 633 622 598L621 302V6L614 0H600Q585 0 582 3T481 150T282 443T171 605V345L172 86Q183 50 257 46H274V0H265Q250 3 150 3Q48 3 33 0H25V46H42Z" transform="translate(708,0)"></path></g><g data-mml-node="mo" transform="translate(1458,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(1847,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(2419,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(3085.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mi" transform="translate(4141.6,0)"><path data-c="1D6FE" d="M31 249Q11 249 11 258Q11 275 26 304T66 365T129 418T206 441Q233 441 239 440Q287 429 318 386T371 255Q385 195 385 170Q385 166 386 166L398 193Q418 244 443 300T486 391T508 430Q510 431 524 431H537Q543 425 543 422Q543 418 522 378T463 251T391 71Q385 55 378 6T357 -100Q341 -165 330 -190T303 -216Q286 -216 286 -188Q286 -138 340 32L346 51L347 69Q348 79 348 100Q348 257 291 317Q251 355 196 355Q148 355 108 329T51 260Q49 251 47 251Q45 249 31 249Z"></path></g><g data-mml-node="mo" transform="translate(4906.8,0)"><path data-c="22C5" d="M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250Z"></path></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(5407,0)"><g data-mml-node="mover"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(313.8,16) translate(-250 0)"><path data-c="5E" d="M112 560L249 694L257 686Q387 562 387 560L361 531Q359 532 303 581L250 627L195 580Q182 569 169 557T148 538L140 532Q138 530 125 546L112 560Z"></path></g></g></g><g data-mml-node="mo" transform="translate(6201.2,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mi" transform="translate(7201.4,0)"><path data-c="1D6FD" d="M29 -194Q23 -188 23 -186Q23 -183 102 134T186 465Q208 533 243 584T309 658Q365 705 429 705H431Q493 705 533 667T573 570Q573 465 469 396L482 383Q533 332 533 252Q533 139 448 65T257 -10Q227 -10 203 -2T165 17T143 40T131 59T126 65L62 -188Q60 -194 42 -194H29ZM353 431Q392 431 427 419L432 422Q436 426 439 429T449 439T461 453T472 471T484 495T493 524T501 560Q503 569 503 593Q503 611 502 616Q487 667 426 667Q384 667 347 643T286 582T247 514T224 455Q219 439 186 308T152 168Q151 163 151 147Q151 99 173 68Q204 26 260 26Q302 26 349 51T425 137Q441 171 449 214T457 279Q457 337 422 372Q380 358 347 358H337Q258 358 258 389Q258 396 261 403Q275 431 353 431Z"></path></g></g></g></svg></mjx-container><br><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20241228184140.png" alt="20241228184140"></li>
</ul>
<p><strong>注：在训练和测试时，Batch Normalization的计算方式不同</strong></p>
<ul>
<li>训练时的<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.489ex;" xmlns="http://www.w3.org/2000/svg" width="1.364ex" height="1.489ex" role="img" focusable="false" viewBox="0 -442 603 658"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D707" d="M58 -216Q44 -216 34 -208T23 -186Q23 -176 96 116T173 414Q186 442 219 442Q231 441 239 435T249 423T251 413Q251 401 220 279T187 142Q185 131 185 107V99Q185 26 252 26Q261 26 270 27T287 31T302 38T315 45T327 55T338 65T348 77T356 88T365 100L372 110L408 253Q444 395 448 404Q461 431 491 431Q504 431 512 424T523 412T525 402L449 84Q448 79 448 68Q448 43 455 35T476 26Q485 27 496 35Q517 55 537 131Q543 151 547 152Q549 153 557 153H561Q580 153 580 144Q580 138 575 117T555 63T523 13Q510 0 491 -8Q483 -10 467 -10Q446 -10 429 -4T402 11T385 29T376 44T374 51L368 45Q362 39 350 30T324 12T288 -4T246 -11Q199 -11 153 12L129 -85Q108 -167 104 -180T92 -202Q76 -216 58 -216Z"></path></g></g></g></svg></mjx-container>和<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="1.292ex" height="1ex" role="img" focusable="false" viewBox="0 -431 571 442"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D70E" d="M184 -11Q116 -11 74 34T31 147Q31 247 104 333T274 430Q275 431 414 431H552Q553 430 555 429T559 427T562 425T565 422T567 420T569 416T570 412T571 407T572 401Q572 357 507 357Q500 357 490 357T476 358H416L421 348Q439 310 439 263Q439 153 359 71T184 -11ZM361 278Q361 358 276 358Q152 358 115 184Q114 180 114 178Q106 141 106 117Q106 67 131 47T188 26Q242 26 287 73Q316 103 334 153T356 233T361 278Z"></path></g></g></g></svg></mjx-container>是根据当前batch计算的<br><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20241228184040.png" alt="20241228184040"></li>
<li>而 <strong>测试时的<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.489ex;" xmlns="http://www.w3.org/2000/svg" width="1.364ex" height="1.489ex" role="img" focusable="false" viewBox="0 -442 603 658"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D707" d="M58 -216Q44 -216 34 -208T23 -186Q23 -176 96 116T173 414Q186 442 219 442Q231 441 239 435T249 423T251 413Q251 401 220 279T187 142Q185 131 185 107V99Q185 26 252 26Q261 26 270 27T287 31T302 38T315 45T327 55T338 65T348 77T356 88T365 100L372 110L408 253Q444 395 448 404Q461 431 491 431Q504 431 512 424T523 412T525 402L449 84Q448 79 448 68Q448 43 455 35T476 26Q485 27 496 35Q517 55 537 131Q543 151 547 152Q549 153 557 153H561Q580 153 580 144Q580 138 575 117T555 63T523 13Q510 0 491 -8Q483 -10 467 -10Q446 -10 429 -4T402 11T385 29T376 44T374 51L368 45Q362 39 350 30T324 12T288 -4T246 -11Q199 -11 153 12L129 -85Q108 -167 104 -180T92 -202Q76 -216 58 -216Z"></path></g></g></g></svg></mjx-container>和<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="1.292ex" height="1ex" role="img" focusable="false" viewBox="0 -431 571 442"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D70E" d="M184 -11Q116 -11 74 34T31 147Q31 247 104 333T274 430Q275 431 414 431H552Q553 430 555 429T559 427T562 425T565 422T567 420T569 416T570 412T571 407T572 401Q572 357 507 357Q500 357 490 357T476 358H416L421 348Q439 310 439 263Q439 153 359 71T184 -11ZM361 278Q361 358 276 358Q152 358 115 184Q114 180 114 178Q106 141 106 117Q106 67 131 47T188 26Q242 26 287 73Q316 103 334 153T356 233T361 278Z"></path></g></g></g></svg></mjx-container>是根据训练集计算的固定值</strong><br><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20241228184107.png" alt="20241228184107"></li>
</ul>
<h3 id="Layer-Normalization"><a href="#Layer-Normalization" class="headerlink" title="Layer Normalization"></a>Layer Normalization</h3><p>对 <code>同一图像的不同通道/层(depth=D)</code> 进行归一化，使得 <code>通道/层</code> 之间分布一致。<br><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20241228184247.png" alt="20241228184247"></p>
<h3 id="Instance-Normalization"><a href="#Instance-Normalization" class="headerlink" title="Instance Normalization"></a>Instance Normalization</h3><p>对 <code>同一通道/层的不同空间维度(H/W)</code> 进行归一化，使得 <code>空间维度</code> 之间分布一致。<br><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20241228184259.png" alt="20241228184259"></p>
<h3 id="Group-Normalization"><a href="#Group-Normalization" class="headerlink" title="Group Normalization"></a>Group Normalization</h3><p>对 <code>同一图像的多个通道/通道组(group)</code> 进行归一化，使得 <code>通道组</code> 之间分布一致。<br><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20241228184329.png" alt="20241228184329"></p>
<h1 id="lecture-8-CNN-Architectures（CNN经典结构）"><a href="#lecture-8-CNN-Architectures（CNN经典结构）" class="headerlink" title="lecture 8: CNN Architectures（CNN经典结构）"></a>lecture 8: CNN Architectures（CNN经典结构）</h1><p>slide: <a class="link" target="_blank" rel="noopener" href="https://web.eecs.umich.edu/~justincj/slides/eecs498/498_FA2019_lecture08.pdf">https://web.eecs.umich.edu/~justincj/slides/eecs498/498_FA2019_lecture08.pdf<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<ul>
<li>AlexNet, VGG, ResNet</li>
<li>Size vs Accuracy</li>
<li>Grouped and Separable Convolutions</li>
<li>Neural Architecture Search</li>
</ul>
<p>Problem: What is the right way to combine all these components?</p>
<p>pretrained models in PyTorch:</p>
<ul>
<li>AlexNet: <a class="link" target="_blank" rel="noopener" href="https://pytorch.org/vision/main/models/alexnet.html">https://pytorch.org/vision/main/models/alexnet.html<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li>VGG: <a class="link" target="_blank" rel="noopener" href="https://pytorch.org/vision/main/models/vgg.html">https://pytorch.org/vision/main/models/vgg.html<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li>GoogLeNet: <a class="link" target="_blank" rel="noopener" href="https://pytorch.org/vision/main/models/googlenet.html">https://pytorch.org/vision/main/models/googlenet.html<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
<li>ResNet: <a class="link" target="_blank" rel="noopener" href="https://pytorch.org/vision/main/models/resnet.html">https://pytorch.org/vision/main/models/resnet.html<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></li>
</ul>
<h2 id="1989-LeNet"><a href="#1989-LeNet" class="headerlink" title="(1989) LeNet"></a>(1989) LeNet</h2><ul>
<li>1989年，LeCun等人提出LeNet-1，是第一个卷积神经网络。</li>
<li>1998年，LeCun等人提出LeNet-5</li>
</ul>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20241228183836.png" alt="20241228183836"></p>
<h2 id="2012-AlexNet"><a href="#2012-AlexNet" class="headerlink" title="(2012) AlexNet"></a>(2012) AlexNet</h2><p>2012年以前，conv-nets的结构都比较简单、层数比较浅，<strong>AlexNet是第一个深度神经网络(DNN)。</strong></p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20241229182639.png" alt="20241229182639"></p>
<ul>
<li><strong>8 Layers</strong>:<br><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20241229182736.png" alt="20241229182736"><ul>
<li>5 Convolutional Layers</li>
<li>Max Pooling</li>
<li>3 Fully Connected Layers</li>
<li>ReLU Activation Function</li>
</ul>
</li>
<li>Used “Local Response Normalization” (Not used anymore)</li>
<li>Trained on two GTX580 GPUs (only 3GB of memory each! Model split over two GPUs)</li>
<li>Citations: <code>46510</code> (As of 9/30/2019)<br><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20241229182916.png" alt="20241229182916"></li>
<li>计算量低，参数量大<br><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20241229190722.png" alt="20241229190722"></li>
</ul>
<h3 id="内存-参数量-计算量"><a href="#内存-参数量-计算量" class="headerlink" title="内存/参数量/计算量"></a>内存/参数量/计算量</h3><p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20241229183040.png" alt="20241229183040"><br><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20241229183122.png" alt="20241229183122"><br>(start) 高分辨率的卷积层：</p>
<ul>
<li>内存占用大</li>
<li>计算量大</li>
<li>参数量小</li>
</ul>
<p>(end) 全连接层：</p>
<ul>
<li>内存占用小</li>
<li>计算量小</li>
<li>参数量大</li>
</ul>
<h2 id="2013-ZFNet"><a href="#2013-ZFNet" class="headerlink" title="(2013) ZFNet"></a>(2013) ZFNet</h2><p><strong>A Bigger AlexNet</strong><br><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20241229183230.png" alt="20241229183230"></p>
<ul>
<li>8 Layers<br><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20241229183320.png" alt="20241229183320"></li>
</ul>
<h2 id="2014-VGG"><a href="#2014-VGG" class="headerlink" title="(2014) VGG"></a>(2014) VGG</h2><p>VGG表示Visual Geometry Group，是提出该网络的实验室的名称。<br>2014年之前的网络都是手工设计的网络，从VGG开始，遵循一些 <strong>Design Rule</strong> 进行设计。</p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20241229183359.png" alt="20241229183359"></p>
<p><strong>网络信息：</strong></p>
<ul>
<li>16/19 Layers<br><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20241229183503.png" alt="20241229183503"><ul>
<li>VGG-16</li>
<li>VGG-19</li>
</ul>
</li>
<li>5 stages<ul>
<li>Stage 1: conv-conv-pool</li>
<li>Stage 2: conv-conv-pool</li>
<li>Stage 3: conv-conv-pool</li>
<li>Stage 4: conv-conv-conv-[conv]-pool</li>
<li>Stage 5: conv-conv-conv-[conv]-pool</li>
</ul>
</li>
<li>3 Fully Connected Layers</li>
</ul>
<p><strong>VGG的影响</strong>：</p>
<ol>
<li>证明了<strong>大的网络通常有更好的效果</strong></li>
<li>给出了<strong>几个指导性原则</strong>，减少了超参量，使得网络结构的扩展变得方便</li>
</ol>
<p><strong>VGG的效率：内存占用高，计算量大</strong><br><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20241229190503.png" alt="20241229190503"></p>
<h3 id="VGG-Design-Rules"><a href="#VGG-Design-Rules" class="headerlink" title="VGG Design Rules"></a>VGG Design Rules</h3><ul>
<li>All conv are 3x3 stride 1 pad 1（都是 <code>3x3卷积核</code>）<ul>
<li>VGG认为没有必要使用大的filter，将filter的大小固定为3x3。因为大的filter可以通过多层小filter组合得到，且参数量更少。</li>
<li>eg: 2个3x3卷积核 == 1个5x5卷积核<br><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20241229183639.png" alt="20241229183639"></li>
</ul>
</li>
<li>All max pool are 2x2 stride 2（都是 <code>2x2池化</code>）</li>
<li>After pool, double #channels （池化后，<code>通道数变成原来的2倍</code>） -&gt; 使不同大小的卷积层有相同的计算量<br><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20241229183742.png" alt="20241229183742"></li>
</ul>
<h3 id="内存-参数量-计算量-1"><a href="#内存-参数量-计算量-1" class="headerlink" title="内存/参数量/计算量"></a>内存/参数量/计算量</h3><p>Much bigger than AlexNet<br><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20241229183938.png" alt="20241229183938"></p>
<h2 id="2014-GoogLeNet"><a href="#2014-GoogLeNet" class="headerlink" title="(2014) GoogLeNet"></a>(2014) GoogLeNet</h2><p>由Google团队提出，名称中的L大写以致敬LeNet<br><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20241229184010.png" alt="20241229184010"></p>
<ul>
<li>22 Layers</li>
<li><strong>GoogLeNet核心目标 -&gt; 更高效</strong> （以便在数据中心和手机上运行）</li>
</ul>
<p>Many innovation for <strong>Effciency</strong>: reduce <code>parameter count</code>, <code>memory usage</code>, and <code>computation</code>.<br><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20241229190939.png" alt="20241229190939"></p>
<h3 id="1-Stem-network"><a href="#1-Stem-network" class="headerlink" title="1.Stem network"></a>1.Stem network</h3><p>开始时的 <code>Stem network</code> 对input进行积极的下采样 -&gt; 减少计算量<br><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20241229184129.png" alt="20241229184129"></p>
<h3 id="2-Inception-Module"><a href="#2-Inception-Module" class="headerlink" title="2.Inception Module"></a>2.Inception Module</h3><p>局部结构重复多次 -&gt; 把每种size的filter都加进去（解决超参的另一种思路）<br><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20241229184158.png" alt="20241229184158"></p>
<h3 id="3-Global-Average-Pooling"><a href="#3-Global-Average-Pooling" class="headerlink" title="3.Global Average Pooling"></a>3.Global Average Pooling</h3><p>在FC层之前进行 <code>全局平均池化(Global Average Pooling)</code>  -&gt; 减少参数量<br><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20241229184228.png" alt="20241229184228"></p>
<h3 id="4-Auxiliary-Classifier"><a href="#4-Auxiliary-Classifier" class="headerlink" title="4.Auxiliary Classifier"></a>4.Auxiliary Classifier</h3><p>使用了 <code>辅助分类器(Auxiliary Classifier)</code> ，对三个分类器的输出进行组合获得结果。（更容易反向传播获取梯度 -&gt; 更新网络）<br><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20241229184416.png" alt="20241229184416"><br>因为GoogLeNet太deep了，所以需要这种trick。但在15年batch normlization出现后，就不需要这种trick了。</p>
<h2 id="2015-ResNet"><a href="#2015-ResNet" class="headerlink" title="(2015) ResNet"></a>(2015) ResNet</h2><p>2015年的important news，席卷了imagenet数据集的所有赛道（classification，localization，detection），以及coco数据集的另一个比赛<br><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20241229184510.png" alt="20241229184510"><br><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20241229185440.png" alt="20241229185440"></p>
<p><strong>网络信息：</strong></p>
<ul>
<li><strong>18/34/50/101/152 Layers</strong><br><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20241229185348.png" alt="20241229185348"><ul>
<li>ResNet-18</li>
<li>ResNet-34</li>
<li>ResNet-50</li>
<li>ResNet-101</li>
<li>ResNet-152</li>
</ul>
</li>
<li>ResNet采用了残差结构，其中“ <code>残差块(Residual Block)</code> ”的设计 <strong>允许在不丢失特征的情况下进行高效学习。</strong><br><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20241229185156.png" alt="20241229185156"></li>
<li>借鉴了VGG和GoogLeNet的一些思想：<ol>
<li>卷积后 <code>通道数变为两倍</code>（借鉴VGG。但VGG通道数的增加通常是在池化操作之后；而ResNet则是卷积操作之后，特别是在跨过“残差块”时）</li>
<li>使用 <code>stem network</code> 进行积极的下采样（借鉴GoogLeNet）<br><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20241229184932.png" alt="20241229184932"></li>
<li>使用 <code>全局平均池化(Global Average Pooling)</code> 以减少参数量（借鉴GoogLeNet）<br><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20241229184956.png" alt="20241229184956"></li>
</ol>
</li>
<li>因此和GoogleNet一样也非常高效：<br><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20241229190248.png" alt="20241229190248"><br><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20241229190433.png" alt="20241229190433"></li>
</ul>
<h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20241229184606.png" alt="20241229184606"></p>
<ul>
<li>背景：人们发现太深的模型表现反而不如浅的模型</li>
<li>原因：<strong>欠拟合(underfitting)</strong> ，训练集和测试集的表现都不佳</li>
<li>分析：<ul>
<li>但是一个deeper model理论上可以模拟shallower model的（只需要- 复制前面的层，并让后面的层都是identity的就行）</li>
<li>因此deeper model至少应该表现和shallower mode相当</li>
</ul>
</li>
<li>猜想：这是一个优化问题 -&gt; deeper model 的优化比较难 -&gt; 需要改变网络结构，以学习 <strong>恒等函数(identity function)</strong></li>
</ul>
<h3 id="Residual-Block"><a href="#Residual-Block" class="headerlink" title="Residual Block"></a>Residual Block</h3><p>A Residual Network is a stack of <code>Residual Blocks</code>.<br><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20241229184732.png" alt="20241229184732"><br><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20241229184816.png" alt="20241229184816"></p>
<h4 id="Bottleneck-Block"><a href="#Bottleneck-Block" class="headerlink" title="Bottleneck Block"></a>Bottleneck Block</h4><p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20241229185314.png" alt="20241229185314"></p>
<ul>
<li>ResNet-50提出</li>
<li>更多的层和非线性，更少的计算量</li>
</ul>
<p>eg: 从ResNet-34到ResNet-50，在几乎不增加计算量的情况下，将性能大幅提高）<br><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20241229185348.png" alt="20241229185348"></p>
<h4 id="“Pre-Activation”-CVPR’16"><a href="#“Pre-Activation”-CVPR’16" class="headerlink" title="“Pre-Activation” [CVPR’16]"></a>“Pre-Activation” [CVPR’16]</h4><p>预激活的残差块（能真正学习到identity function）</p>
<ul>
<li>He et al. CVPR2016</li>
<li>先激活再卷积</li>
<li>稍微提升了准确率</li>
<li>但在实践中没有被使用</li>
</ul>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20241229185632.png" alt="20241229185632"><br><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20241229185713.png" alt="20241229185713"></p>
<h4 id="“ResNeXt”-CVPR’17"><a href="#“ResNeXt”-CVPR’17" class="headerlink" title="“ResNeXt” [CVPR’17]"></a>“ResNeXt” [CVPR’17]</h4><p>G个并行的残差块</p>
<ul>
<li>Xie et al. CVPR2017</li>
</ul>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20241229185913.png" alt="20241229185913"></p>
<h2 id="2016-Model-Ensembles"><a href="#2016-Model-Ensembles" class="headerlink" title="(2016) Model Ensembles"></a>(2016) Model Ensembles</h2><p>集成多个模型<br><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20241229190050.png" alt="20241229190050"><br><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/LeoJeshua/PicGo/main/images/20241229190104.png" alt="20241229190104"></p>
<h2 id="2017-SENet"><a href="#2017-SENet" class="headerlink" title="(2017) SENet"></a>(2017) SENet</h2><h1 id="lecture-9-Hardware-and-Software（深度学习硬件与软件）"><a href="#lecture-9-Hardware-and-Software（深度学习硬件与软件）" class="headerlink" title="lecture 9: Hardware and Software（深度学习硬件与软件）"></a>lecture 9: Hardware and Software（深度学习硬件与软件）</h1><p>slide: <a class="link" target="_blank" rel="noopener" href="https://web.eecs.umich.edu/~justincj/slides/eecs498/498_FA2019_lecture09.pdf">https://web.eecs.umich.edu/~justincj/slides/eecs498/498_FA2019_lecture09.pdf<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<ul>
<li>CPUs, GPUs, TPUs</li>
<li>Dynamic vs Static graphs</li>
<li>PyTorch, TensorFlow</li>
</ul>
<h1 id="lecture-10-Training-Neural-Networks-I（神经网络的训练-上）"><a href="#lecture-10-Training-Neural-Networks-I（神经网络的训练-上）" class="headerlink" title="lecture 10: Training Neural Networks I（神经网络的训练-上）"></a>lecture 10: Training Neural Networks I（神经网络的训练-上）</h1><p>slide: <a class="link" target="_blank" rel="noopener" href="https://web.eecs.umich.edu/~justincj/slides/eecs498/498_FA2019_lecture10.pdf">https://web.eecs.umich.edu/~justincj/slides/eecs498/498_FA2019_lecture10.pdf<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<ul>
<li>Activation functions</li>
<li>Data preprocessing</li>
<li>Weight initialization</li>
<li>Data augmentation</li>
<li>Regularization (Dropout, etc)</li>
</ul>
<h1 id="lecture-11-Training-Neural-Networks-II（神经网络的训练-下）"><a href="#lecture-11-Training-Neural-Networks-II（神经网络的训练-下）" class="headerlink" title="lecture 11: Training Neural Networks II（神经网络的训练-下）"></a>lecture 11: Training Neural Networks II（神经网络的训练-下）</h1><p>slide: <a class="link" target="_blank" rel="noopener" href="https://web.eecs.umich.edu/~justincj/slides/eecs498/498_FA2019_lecture11.pdf">https://web.eecs.umich.edu/~justincj/slides/eecs498/498_FA2019_lecture11.pdf<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<ul>
<li>Learning rate schedules</li>
<li>Hyperparameter optimization</li>
<li>Model ensembles</li>
<li>Transfer learning</li>
<li>Large-batch training</li>
</ul>
<h1 id="lecture-12-Recurrent-Networks（RNN）"><a href="#lecture-12-Recurrent-Networks（RNN）" class="headerlink" title="lecture 12: Recurrent Networks（RNN）"></a>lecture 12: Recurrent Networks（RNN）</h1><p>slide: <a class="link" target="_blank" rel="noopener" href="https://web.eecs.umich.edu/~justincj/slides/eecs498/498_FA2019_lecture12.pdf">https://web.eecs.umich.edu/~justincj/slides/eecs498/498_FA2019_lecture12.pdf<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<ul>
<li>RNN, LSTM, GRU</li>
<li>Language modeling</li>
<li>Sequence-to-sequence</li>
<li>Image captioning</li>
<li>Visual question answering</li>
</ul>
<h1 id="lecture-13-Attention（注意力机制）"><a href="#lecture-13-Attention（注意力机制）" class="headerlink" title="lecture 13: Attention（注意力机制）"></a>lecture 13: Attention（注意力机制）</h1><p>slide: <a class="link" target="_blank" rel="noopener" href="https://web.eecs.umich.edu/~justincj/slides/eecs498/498_FA2019_lecture13.pdf">https://web.eecs.umich.edu/~justincj/slides/eecs498/498_FA2019_lecture13.pdf<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<ul>
<li>Multimodal attention</li>
<li>Self-Attention</li>
<li>Transformers</li>
</ul>
<h1 id="lecture-14-Visualizing-and-Understanding（可视化与模型理解）"><a href="#lecture-14-Visualizing-and-Understanding（可视化与模型理解）" class="headerlink" title="lecture 14: Visualizing and Understanding（可视化与模型理解）"></a>lecture 14: Visualizing and Understanding（可视化与模型理解）</h1><p>slide: <a class="link" target="_blank" rel="noopener" href="https://web.eecs.umich.edu/~justincj/slides/eecs498/498_FA2019_lecture14.pdf">https://web.eecs.umich.edu/~justincj/slides/eecs498/498_FA2019_lecture14.pdf<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<ul>
<li>Feature visualization</li>
<li>Adversarial examples</li>
<li>DeepDream, Style transfer</li>
</ul>
<h1 id="lecture-15-Object-Detection（目标检测）"><a href="#lecture-15-Object-Detection（目标检测）" class="headerlink" title="lecture 15: Object Detection（目标检测）"></a>lecture 15: Object Detection（目标检测）</h1><p>slide: <a class="link" target="_blank" rel="noopener" href="https://web.eecs.umich.edu/~justincj/slides/eecs498/498_FA2019_lecture15.pdf">https://web.eecs.umich.edu/~justincj/slides/eecs498/498_FA2019_lecture15.pdf<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<ul>
<li>Single-stage detectors</li>
<li>Two-stage detectors</li>
</ul>
<h1 id="lecture-16-Image-Segmentation（图像分割）"><a href="#lecture-16-Image-Segmentation（图像分割）" class="headerlink" title="lecture 16: Image Segmentation（图像分割）"></a>lecture 16: Image Segmentation（图像分割）</h1><p>slide: <a class="link" target="_blank" rel="noopener" href="https://web.eecs.umich.edu/~justincj/slides/eecs498/498_FA2019_lecture16.pdf">https://web.eecs.umich.edu/~justincj/slides/eecs498/498_FA2019_lecture16.pdf<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<ul>
<li>Semantic segmentation</li>
<li>Instance segmentation</li>
<li>Keypoint estimation</li>
</ul>
<h1 id="lecture-17-3D-vision（3D计算机视觉）"><a href="#lecture-17-3D-vision（3D计算机视觉）" class="headerlink" title="lecture 17: 3D vision（3D计算机视觉）"></a>lecture 17: 3D vision（3D计算机视觉）</h1><p>slide: <a class="link" target="_blank" rel="noopener" href="https://web.eecs.umich.edu/~justincj/slides/eecs498/498_FA2019_lecture17.pdf">https://web.eecs.umich.edu/~justincj/slides/eecs498/498_FA2019_lecture17.pdf<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<ul>
<li>3D shape representations</li>
<li>Depth estimation</li>
<li>3D shape prediction</li>
<li>Voxels, Pointclouds, SDFs, Meshes</li>
</ul>
<h1 id="lecture-18-Videos（深度学习中的视频处理）"><a href="#lecture-18-Videos（深度学习中的视频处理）" class="headerlink" title="lecture 18: Videos（深度学习中的视频处理）"></a>lecture 18: Videos（深度学习中的视频处理）</h1><p>slide: <a class="link" target="_blank" rel="noopener" href="https://web.eecs.umich.edu/~justincj/slides/eecs498/498_FA2019_lecture18.pdf">https://web.eecs.umich.edu/~justincj/slides/eecs498/498_FA2019_lecture18.pdf<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<ul>
<li>Video classification</li>
<li>Early / Late fusion</li>
<li>3D CNNs</li>
<li>Two-stream networks</li>
</ul>
<h1 id="lecture-19-Generative-Models-I（生成模型-上）"><a href="#lecture-19-Generative-Models-I（生成模型-上）" class="headerlink" title="lecture 19: Generative Models I（生成模型-上）"></a>lecture 19: Generative Models I（生成模型-上）</h1><p>slide: <a class="link" target="_blank" rel="noopener" href="https://web.eecs.umich.edu/~justincj/slides/eecs498/498_FA2019_lecture19.pdf">https://web.eecs.umich.edu/~justincj/slides/eecs498/498_FA2019_lecture19.pdf<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<ul>
<li>Supervised vs Unsupervised learning</li>
<li>Discriminative vs Generative models</li>
<li>Autoregressive models</li>
<li>Variational Autoencoders</li>
</ul>
<h1 id="lecture-20-Generative-Models-II（生成模型-下）"><a href="#lecture-20-Generative-Models-II（生成模型-下）" class="headerlink" title="lecture 20: Generative Models II（生成模型-下）"></a>lecture 20: Generative Models II（生成模型-下）</h1><p>slide: <a class="link" target="_blank" rel="noopener" href="https://web.eecs.umich.edu/~justincj/slides/eecs498/498_FA2019_lecture20.pdf">https://web.eecs.umich.edu/~justincj/slides/eecs498/498_FA2019_lecture20.pdf<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<ul>
<li>More Variational Autoencoders</li>
<li>Generative Adversarial Networks</li>
</ul>
<h1 id="lecture-21-Reinforcement-Learning（强化学习）"><a href="#lecture-21-Reinforcement-Learning（强化学习）" class="headerlink" title="lecture 21: Reinforcement Learning（强化学习）"></a>lecture 21: Reinforcement Learning（强化学习）</h1><p>slide: <a class="link" target="_blank" rel="noopener" href="https://web.eecs.umich.edu/~justincj/slides/eecs498/498_FA2019_lecture21.pdf">https://web.eecs.umich.edu/~justincj/slides/eecs498/498_FA2019_lecture21.pdf<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<ul>
<li>RL problem setup</li>
<li>Bellman Equation</li>
<li>Q-Learning</li>
<li>Policy Gradient</li>
</ul>
<h1 id="lecture-22-Conclusion（课程总结）"><a href="#lecture-22-Conclusion（课程总结）" class="headerlink" title="lecture 22: Conclusion（课程总结）"></a>lecture 22: Conclusion（课程总结）</h1><p>slide: <a class="link" target="_blank" rel="noopener" href="https://web.eecs.umich.edu/~justincj/slides/eecs498/498_FA2019_lecture22.pdf">https://web.eecs.umich.edu/~justincj/slides/eecs498/498_FA2019_lecture22.pdf<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<ul>
<li>Course recap</li>
<li>The future of computer vision</li>
</ul>

		</div>

		
		<div class="post-copyright-info w-full my-8 px-2 sm:px-6 md:px-8">
			<div class="article-copyright-info-container">
    <ul>
        <li><strong>Title:</strong> Notes of &#34;EECS498-007/598-005 Deep Learning for Computer Vision (2019)&#34;</li>
        <li><strong>Author:</strong> LIU JIAXU (刘家旭)</li>
        <li><strong>Created at
                :</strong> 2024-12-27 18:54:58</li>
        
            <li>
                <strong>Updated at
                    :</strong> 2025-01-12 13:49:12
            </li>
        
        <li>
            <strong>Link:</strong> https://leojeshua.github.io/2024/12/27/eecs498/
        </li>
        <li>
            <strong>
                License:
            </strong>
            

            
                This work is licensed under <a class="license" target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0">CC BY-NC-SA 4.0</a>.
            
        </li>
    </ul>
</div>

		</div>
		

		
		<ul class="post-tags-box text-lg mt-1.5 flex-wrap justify-center flex md:hidden">
			
			<li class="tag-item mx-0.5">
				<a href="/tags/CV/">#CV</a>&nbsp;
			</li>
			
			<li class="tag-item mx-0.5">
				<a href="/tags/Notes/">#Notes</a>&nbsp;
			</li>
			
		</ul>
		

		

		
		<div class="article-nav my-8 flex justify-between items-center px-2 sm:px-6 md:px-8">
			
			<div class="article-prev border-border-color shadow-redefine-flat shadow-shadow-color-2 rounded-medium px-4 py-2 hover:shadow-redefine-flat-hover hover:shadow-shadow-color-2">
				<a class="prev" rel="prev" href="/2025/01/14/Foundation-of-Diffusion-Models/">
					<span class="left arrow-icon flex justify-center items-center">
						<i class="fa-solid fa-chevron-left"></i>
					</span>
					<span class="title flex justify-center items-center">
						<span class="post-nav-title-item">Foundation of Diffusion Models</span>
						<span class="post-nav-item">Prev posts</span>
					</span>
				</a>
			</div>
			
			
			<div class="article-next border-border-color shadow-redefine-flat shadow-shadow-color-2 rounded-medium px-4 py-2 hover:shadow-redefine-flat-hover hover:shadow-shadow-color-2">
				<a class="next" rel="next" href="/2024/12/21/Paper-Collection-of-Safe-Diffusion/">
					<span class="title flex justify-center items-center">
						<span class="post-nav-title-item">Paper Collection of Safe Diffusion</span>
						<span class="post-nav-item">Next posts</span>
					</span>
					<span class="right arrow-icon flex justify-center items-center">
						<i class="fa-solid fa-chevron-right"></i>
					</span>
				</a>
			</div>
			
		</div>
		


		
	</div>

	
	<div class="toc-content-container">
		<div class="post-toc-wrap">
    <div class="post-toc">
        <div class="toc-title">On this page</div>
        <div class="page-title">
            Notes of &#34;EECS498-007/598-005 Deep Learning for Computer Vision (2019)&#34;
        </div>
        <ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#lecture-1-Course-Introduction%EF%BC%88%E4%BB%8B%E7%BB%8D%EF%BC%89"><span class="nav-text">lecture 1: Course Introduction（介绍）</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#lecture-2-Image-Classification%EF%BC%88%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%EF%BC%89"><span class="nav-text">lecture 2: Image Classification（图像分类）</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#lecture-3-Linear-Classifiers%EF%BC%88%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB%E5%99%A8%EF%BC%89"><span class="nav-text">lecture 3: Linear Classifiers（线性分类器）</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#lecture-4-Optimization%EF%BC%88%E4%BC%98%E5%8C%96%EF%BC%89"><span class="nav-text">lecture 4: Optimization（优化）</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#lecture-5-Neural-Networks%EF%BC%88%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%89"><span class="nav-text">lecture 5: Neural Networks（神经网络）</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#lecture-6-Backpropagation%EF%BC%88%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%ADBP%EF%BC%89"><span class="nav-text">lecture 6: Backpropagation（反向传播BP）</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#lecture-7-Convolutional-Networks%EF%BC%88CNN%EF%BC%89"><span class="nav-text">lecture 7: Convolutional Networks（CNN）</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#7-1-Fully-Connected-Layer"><span class="nav-text">7.1 Fully-Connected Layer</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#7-2-Convolution-Layer"><span class="nav-text">7.2 Convolution Layer</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#7-2-1-%E5%8D%B7%E7%A7%AF%E6%A0%B8-filter"><span class="nav-text">7.2.1 卷积核 (filter)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#7-2-2-%E5%8D%B7%E7%A7%AF%E6%93%8D%E4%BD%9C-Convolve"><span class="nav-text">7.2.2 卷积操作 (Convolve)</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%BE%B9%E7%BC%98%E5%A1%AB%E5%85%85-Padding"><span class="nav-text">边缘填充 (Padding)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%B7%A8%E6%AD%A5%E5%8D%B7%E7%A7%AF-Strided-Convolution"><span class="nav-text">跨步卷积 (Strided Convolution)</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#7-2-3-%E7%89%B9%E5%BE%81%E5%9B%BE-%E6%BF%80%E6%B4%BB%E5%9B%BE-Feature-Map-Activation-Map"><span class="nav-text">7.2.3 特征图&#x2F;激活图 (Feature Map&#x2F;Activation Map)</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%A7%86%E8%A7%921%EF%BC%9A%E5%A4%9A%E4%B8%AA%E5%8D%95%E9%80%9A%E9%81%93-Feature-Map-Activation-Map"><span class="nav-text">视角1：多个单通道 Feature Map&#x2F;Activation Map</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%A7%86%E8%A7%922%EF%BC%9A%E4%B8%80%E4%B8%AA%E5%A4%9A%E9%80%9A%E9%81%93-Feature-Map-Activation-Map"><span class="nav-text">视角2：一个多通道 Feature Map&#x2F;Activation Map</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#7-2-4-%E5%8D%B7%E7%A7%AF%E5%B1%82%E7%9A%84%E8%AE%AD%E7%BB%83%E8%AE%BE%E7%BD%AE"><span class="nav-text">7.2.4 卷积层的训练设置</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%89%B9%E9%87%8F%E8%BE%93%E5%85%A5"><span class="nav-text">批量输入</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%8F%82%E6%95%B0%E9%87%8F%E5%92%8C%E8%AE%A1%E7%AE%97%E9%87%8F"><span class="nav-text">参数量和计算量</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%B6%85%E5%8F%82%E7%9A%84%E4%B8%80%E8%88%AC%E9%80%89%E6%8B%A9"><span class="nav-text">超参的一般选择</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#PyTorch%E5%AE%9E%E7%8E%B0"><span class="nav-text">PyTorch实现</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#7-2-5-%E7%BA%BF%E6%80%A7%E5%8D%B7%E7%A7%AF%E5%B1%82%E7%9A%84%E9%97%AE%E9%A2%98"><span class="nav-text">7.2.5 线性卷积层的问题</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#7-3-Activation-Function"><span class="nav-text">7.3 Activation Function</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#7-4-Pooling-Layer"><span class="nav-text">7.4 Pooling Layer</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#7-4-1-Types-of-Pooling"><span class="nav-text">7.4.1 Types of Pooling</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#7-4-2-%E5%8F%82%E6%95%B0%E9%87%8F-0"><span class="nav-text">7.4.2 参数量 &#x3D; 0</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#7-5-2015-Normalization"><span class="nav-text">7.5 (2015) Normalization</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Batch-Normalization"><span class="nav-text">Batch Normalization</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Layer-Normalization"><span class="nav-text">Layer Normalization</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Instance-Normalization"><span class="nav-text">Instance Normalization</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Group-Normalization"><span class="nav-text">Group Normalization</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#lecture-8-CNN-Architectures%EF%BC%88CNN%E7%BB%8F%E5%85%B8%E7%BB%93%E6%9E%84%EF%BC%89"><span class="nav-text">lecture 8: CNN Architectures（CNN经典结构）</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1989-LeNet"><span class="nav-text">(1989) LeNet</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2012-AlexNet"><span class="nav-text">(2012) AlexNet</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%86%85%E5%AD%98-%E5%8F%82%E6%95%B0%E9%87%8F-%E8%AE%A1%E7%AE%97%E9%87%8F"><span class="nav-text">内存&#x2F;参数量&#x2F;计算量</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2013-ZFNet"><span class="nav-text">(2013) ZFNet</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2014-VGG"><span class="nav-text">(2014) VGG</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#VGG-Design-Rules"><span class="nav-text">VGG Design Rules</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%86%85%E5%AD%98-%E5%8F%82%E6%95%B0%E9%87%8F-%E8%AE%A1%E7%AE%97%E9%87%8F-1"><span class="nav-text">内存&#x2F;参数量&#x2F;计算量</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2014-GoogLeNet"><span class="nav-text">(2014) GoogLeNet</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-Stem-network"><span class="nav-text">1.Stem network</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-Inception-Module"><span class="nav-text">2.Inception Module</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-Global-Average-Pooling"><span class="nav-text">3.Global Average Pooling</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-Auxiliary-Classifier"><span class="nav-text">4.Auxiliary Classifier</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2015-ResNet"><span class="nav-text">(2015) ResNet</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%83%8C%E6%99%AF"><span class="nav-text">背景</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Residual-Block"><span class="nav-text">Residual Block</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Bottleneck-Block"><span class="nav-text">Bottleneck Block</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E2%80%9CPre-Activation%E2%80%9D-CVPR%E2%80%9916"><span class="nav-text">“Pre-Activation” [CVPR’16]</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E2%80%9CResNeXt%E2%80%9D-CVPR%E2%80%9917"><span class="nav-text">“ResNeXt” [CVPR’17]</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2016-Model-Ensembles"><span class="nav-text">(2016) Model Ensembles</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2017-SENet"><span class="nav-text">(2017) SENet</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#lecture-9-Hardware-and-Software%EF%BC%88%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%A1%AC%E4%BB%B6%E4%B8%8E%E8%BD%AF%E4%BB%B6%EF%BC%89"><span class="nav-text">lecture 9: Hardware and Software（深度学习硬件与软件）</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#lecture-10-Training-Neural-Networks-I%EF%BC%88%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E8%AE%AD%E7%BB%83-%E4%B8%8A%EF%BC%89"><span class="nav-text">lecture 10: Training Neural Networks I（神经网络的训练-上）</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#lecture-11-Training-Neural-Networks-II%EF%BC%88%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E8%AE%AD%E7%BB%83-%E4%B8%8B%EF%BC%89"><span class="nav-text">lecture 11: Training Neural Networks II（神经网络的训练-下）</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#lecture-12-Recurrent-Networks%EF%BC%88RNN%EF%BC%89"><span class="nav-text">lecture 12: Recurrent Networks（RNN）</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#lecture-13-Attention%EF%BC%88%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%EF%BC%89"><span class="nav-text">lecture 13: Attention（注意力机制）</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#lecture-14-Visualizing-and-Understanding%EF%BC%88%E5%8F%AF%E8%A7%86%E5%8C%96%E4%B8%8E%E6%A8%A1%E5%9E%8B%E7%90%86%E8%A7%A3%EF%BC%89"><span class="nav-text">lecture 14: Visualizing and Understanding（可视化与模型理解）</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#lecture-15-Object-Detection%EF%BC%88%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%EF%BC%89"><span class="nav-text">lecture 15: Object Detection（目标检测）</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#lecture-16-Image-Segmentation%EF%BC%88%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2%EF%BC%89"><span class="nav-text">lecture 16: Image Segmentation（图像分割）</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#lecture-17-3D-vision%EF%BC%883D%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%EF%BC%89"><span class="nav-text">lecture 17: 3D vision（3D计算机视觉）</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#lecture-18-Videos%EF%BC%88%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E8%A7%86%E9%A2%91%E5%A4%84%E7%90%86%EF%BC%89"><span class="nav-text">lecture 18: Videos（深度学习中的视频处理）</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#lecture-19-Generative-Models-I%EF%BC%88%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B-%E4%B8%8A%EF%BC%89"><span class="nav-text">lecture 19: Generative Models I（生成模型-上）</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#lecture-20-Generative-Models-II%EF%BC%88%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B-%E4%B8%8B%EF%BC%89"><span class="nav-text">lecture 20: Generative Models II（生成模型-下）</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#lecture-21-Reinforcement-Learning%EF%BC%88%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%EF%BC%89"><span class="nav-text">lecture 21: Reinforcement Learning（强化学习）</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#lecture-22-Conclusion%EF%BC%88%E8%AF%BE%E7%A8%8B%E6%80%BB%E7%BB%93%EF%BC%89"><span class="nav-text">lecture 22: Conclusion（课程总结）</span></a></li></ol>

    </div>
</div>
	</div>
	
</div>
			</div>

			
		</div>

		<div class="main-content-footer">
			<footer class="footer mt-5 py-5 h-auto text-base text-third-text-color relative border-t-2 border-t-border-color">
    <div class="info-container py-3 text-center">
        
        <div class="text-center">
            &copy;
            
              <span>2024</span>
              -
            
            2025&nbsp;&nbsp;<i class="fa-solid fa-cog fa-spin" style="--fa-animation-duration:15s"></i>&nbsp;&nbsp;<a href="/">LIU JIAXU (刘家旭)</a>
            
                
                <p class="post-count space-x-0.5">
                    <span>
                        7 posts in total
                    </span>
                    
                        <span>
                            11.8k words in total
                        </span>
                    
                </p>
            
        </div>
        
            <script data-swup-reload-script src="https://cn.vercount.one/js"></script>
            <div class="relative text-center lg:absolute lg:right-[20px] lg:top-1/2 lg:-translate-y-1/2 lg:text-right">
                
                    <span id="busuanzi_container_site_uv" class="lg:!block">
                        <span class="text-sm">VISITOR COUNT</span>
                        <span id="busuanzi_value_site_uv"></span>
                    </span>
                
                
                    <span id="busuanzi_container_site_pv" class="lg:!block">
                        <span class="text-sm">TOTAL PAGE VIEWS</span>
                        <span id="busuanzi_value_site_pv"></span>
                    </span>
                
            </div>
        
        <div class="relative text-center lg:absolute lg:left-[20px] lg:top-1/2 lg:-translate-y-1/2 lg:text-left">
            <span class="lg:block text-sm">POWERED BY <?xml version="1.0" encoding="utf-8"?><!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"><svg class="relative top-[2px] inline-block align-baseline" version="1.1" id="圖層_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" width="1rem" height="1rem" viewBox="0 0 512 512" enable-background="new 0 0 512 512" xml:space="preserve"><path fill="#0E83CD" d="M256.4,25.8l-200,115.5L56,371.5l199.6,114.7l200-115.5l0.4-230.2L256.4,25.8z M349,354.6l-18.4,10.7l-18.6-11V275H200v79.6l-18.4,10.7l-18.6-11v-197l18.5-10.6l18.5,10.8V237h112v-79.6l18.5-10.6l18.5,10.8V354.6z"/></svg><a target="_blank" class="text-base" href="https://hexo.io">Hexo</a></span>
            <span class="text-sm lg:block">THEME&nbsp;<a class="text-base" target="_blank" href="https://github.com/EvanNotFound/hexo-theme-redefine">Redefine v2.8.2</a></span>
        </div>
        
        
            <div>
                Blog up for <span class="odometer" id="runtime_days" ></span> days <span class="odometer" id="runtime_hours"></span> hrs <span class="odometer" id="runtime_minutes"></span> Min <span class="odometer" id="runtime_seconds"></span> Sec
            </div>
        
        
            <script data-swup-reload-script>
                try {
                    function odometer_init() {
                    const elements = document.querySelectorAll('.odometer');
                    elements.forEach(el => {
                        new Odometer({
                            el,
                            format: '( ddd).dd',
                            duration: 200
                        });
                    });
                    }
                    odometer_init();
                } catch (error) {}
            </script>
        
        
            
                
        
                
        
                

                    
                        <script data-swup-reload-script>var url_1736="https://api.cdnorg.cn:666";var token_1736="8d393e3086e1d2d48267460f67b7bf8d1a09f23f231d32de4f3fb3a12f3af020";var cltj_1736=document.createElement("script");cltj_1736.src=url_1736+"/tj/tongji.js?v=2.201";var s_1736=document.getElementsByTagName("script")[0];s_1736.parentNode.insertBefore(cltj_1736,s_1736);</script>
                    
        
                

                    
                        <script data-swup-reload-script type="text/javascript">(function(){var baidu=document.createElement("script");baidu.src="//i.6v6.work/v/?uid=388547";var cnzz=document.getElementsByTagName("script")[0];cnzz.parentNode.insertBefore(baidu,cnzz)})();</script>
                    
        
        
    </div>  
</footer>
		</div>
	</div>

	
	<div class="post-tools">
		<div class="post-tools-container">
	<ul class="article-tools-list">
		<!-- TOC aside toggle -->
		
		<li class="right-bottom-tools page-aside-toggle">
			<i class="fa-regular fa-outdent"></i>
		</li>
		

		<!-- go comment -->
		
	</ul>
</div>
	</div>
	

	<div class="right-side-tools-container">
		<div class="side-tools-container">
	<ul class="hidden-tools-list">
		<li class="right-bottom-tools tool-font-adjust-plus flex justify-center items-center">
			<i class="fa-regular fa-magnifying-glass-plus"></i>
		</li>

		<li class="right-bottom-tools tool-font-adjust-minus flex justify-center items-center">
			<i class="fa-regular fa-magnifying-glass-minus"></i>
		</li>

		<li class="right-bottom-tools tool-dark-light-toggle flex justify-center items-center">
			<i class="fa-regular fa-moon"></i>
		</li>

		<!-- rss -->
		

		

		<li class="right-bottom-tools tool-scroll-to-bottom flex justify-center items-center">
			<i class="fa-regular fa-arrow-down"></i>
		</li>
	</ul>

	<ul class="visible-tools-list">
		<li class="right-bottom-tools toggle-tools-list flex justify-center items-center">
			<i class="fa-regular fa-cog fa-spin"></i>
		</li>
		
		<li class="right-bottom-tools tool-scroll-to-top flex justify-center items-center">
			<i class="arrow-up fas fa-arrow-up"></i>
			<span class="percent"></span>
		</li>
		
		
	</ul>
</div>
	</div>

	<div class="image-viewer-container">
	<img src="">
</div>

	

</main>


<script  src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/js/build/libs/Swup.min.js" ></script><script  src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/js/build/libs/SwupSlideTheme.min.js" ></script><script  src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/js/build/libs/SwupScriptsPlugin.min.js" ></script><script  src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/js/build/libs/SwupProgressPlugin.min.js" ></script><script  src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/js/build/libs/SwupScrollPlugin.min.js" ></script><script  src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/js/build/libs/SwupPreloadPlugin.min.js" ></script>
<script>
    const swup = new Swup({
        plugins: [
            new SwupScriptsPlugin({
                optin: true,
            }),
            new SwupProgressPlugin(),
            new SwupScrollPlugin({
                offset: 80,
            }),
            new SwupSlideTheme({
                mainElement: ".main-content-body",
            }),
            new SwupPreloadPlugin(),
        ],
        containers: ["#swup"],
    });
</script>




	<script type="module" src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/js/build/tools/imageViewer.js" ></script><script type="module" src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/js/build/utils.js" ></script><script type="module" src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/js/build/main.js" ></script><script type="module" src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/js/build/layouts/navbarShrink.js" ></script><script type="module" src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/js/build/tools/scrollTopBottom.js" ></script><script type="module" src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/js/build/tools/lightDarkSwitch.js" ></script><script type="module" src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/js/build/layouts/categoryList.js" ></script>




    <script type="module" src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/js/build/tools/codeBlock.js" ></script>



    <script type="module" src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/js/build/layouts/lazyload.js" ></script>



    <script  src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/js/build/tools/runtime.js" ></script>
    <script  src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/js/build/libs/odometer.min.js" ></script>
    <link rel="stylesheet" href="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/assets/odometer-theme-minimal.css">



  <script  src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/js/build/libs/Typed.min.js" ></script>
  <script type="module" src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/js/build/plugins/typed.js" ></script>







    <script  src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/js/build/libs/anime.min.js" ></script>




    <script type="module" src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/js/build/tools/tocToggle.js" data-swup-reload-script></script><script type="module" src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/js/build/layouts/toc.js" data-swup-reload-script></script><script type="module" src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/js/build/plugins/tabs.js" data-swup-reload-script></script>


<script  src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/js/build/libs/moment-with-locales.min.js" data-swup-reload-script></script>
<script type="module" src="https://registry.npmmirror.com/hexo-theme-redefine/2.8.2/files/source/js/build/layouts/essays.js" data-swup-reload-script></script>




	
</body>

</html>